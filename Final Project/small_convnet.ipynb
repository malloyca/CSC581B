{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small_convnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxG+s0CdDnwxZrWSwM15yo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malloyca/CSC581B/blob/main/Final%20Project/small_convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI3XLmYiD-UJ"
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose # todo: Lambda, Compose not necessary?\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuXW8boJEcrA",
        "outputId": "5b1660be-c81b-43f9-da6c-26c80e71a76f"
      },
      "source": [
        "# Load the training data (CIFAR10 to start)\n",
        "training_data = datasets.CIFAR10(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = datasets.CIFAR10(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2dy9pmEwz6"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE6plIy9E2D_",
        "outputId": "4341e73a-40f5-4455-ad8e-273708cb0189"
      },
      "source": [
        "# Check the data dimensions\n",
        "for X, y in test_dataloader:\n",
        "  print(\"Shape of X batch [Batch size, Channels, Height, Width]: \", X.shape)\n",
        "  print(\"Shape of y batch: \", y.shape, y.dtype)\n",
        "  break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X batch [Batch size, Channels, Height, Width]:  torch.Size([64, 3, 32, 32])\n",
            "Shape of y batch:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGQGFOcoFAeO"
      },
      "source": [
        "# Building basic convolutional neural nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuGLhBqQE_xI",
        "outputId": "eb06a1e4-1098-4968-fe23-d6be546eb79b"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H5TNXTJE4Nd"
      },
      "source": [
        "# Define the model\n",
        "class basicConvNet(nn.Module):\n",
        "  def __init__(self, name):\n",
        "    super(basicConvNet, self).__init__()\n",
        "    self.name = name\n",
        "    self.basic_conv_net = nn.Sequential(\n",
        "        # 1st layer\n",
        "        nn.Conv2d(3, 64, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d((2,2)),\n",
        "\n",
        "        # 2nd layer\n",
        "        nn.Conv2d(64, 32, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d((2,2)),\n",
        "\n",
        "        # 3rd layer\n",
        "        nn.Conv2d(32, 32, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2),\n",
        "\n",
        "        # Last layer\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(32 * 4 * 4, 10),\n",
        "    )\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  # Forward propagation\n",
        "  def forward(self, x):\n",
        "    x = self.basic_conv_net(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "      "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLQYaHdZTnJK"
      },
      "source": [
        "model = basicConvNet('test').to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deD1sei_WLmX"
      },
      "source": [
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGk95EKWan5"
      },
      "source": [
        "# Training loop\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I_S627HXLWz"
      },
      "source": [
        "# Test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "  return test_loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfMapknHYDYO"
      },
      "source": [
        "n_epochs = 5"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uypo30igYE2G"
      },
      "source": [
        "def training_loop(n_epochs, model, train_data, test_data, loss_function,\n",
        "                  optimizer):\n",
        "  \n",
        "  for e in range(n_epochs):\n",
        "    print(f\"Epoch {e+1}\\n------------------------\")\n",
        "    train(train_data, model, loss_function, optimizer)\n",
        "    test_loss = test(test_data, model, loss_function)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6WkrJ5QYgri",
        "outputId": "6b43fe5e-5cfc-458f-97c0-96658ab58fab"
      },
      "source": [
        "training_loop(n_epochs, model, train_dataloader, test_dataloader, loss_fn, optimizer)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------------------\n",
            "loss: 2.301640 [    0/50000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.302561 [ 6400/50000]\n",
            "loss: 2.302672 [12800/50000]\n",
            "loss: 2.301651 [19200/50000]\n",
            "loss: 2.302730 [25600/50000]\n",
            "loss: 2.302497 [32000/50000]\n",
            "loss: 2.302310 [38400/50000]\n",
            "loss: 2.302088 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302449 \n",
            "\n",
            "Epoch 2\n",
            "------------------------\n",
            "loss: 2.301622 [    0/50000]\n",
            "loss: 2.302496 [ 6400/50000]\n",
            "loss: 2.302319 [12800/50000]\n",
            "loss: 2.301740 [19200/50000]\n",
            "loss: 2.302243 [25600/50000]\n",
            "loss: 2.302267 [32000/50000]\n",
            "loss: 2.302129 [38400/50000]\n",
            "loss: 2.302005 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.1%, Avg loss: 2.302175 \n",
            "\n",
            "Epoch 3\n",
            "------------------------\n",
            "loss: 2.301563 [    0/50000]\n",
            "loss: 2.302473 [ 6400/50000]\n",
            "loss: 2.301825 [12800/50000]\n",
            "loss: 2.301808 [19200/50000]\n",
            "loss: 2.301620 [25600/50000]\n",
            "loss: 2.301861 [32000/50000]\n",
            "loss: 2.301940 [38400/50000]\n",
            "loss: 2.301806 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 13.1%, Avg loss: 2.301725 \n",
            "\n",
            "Epoch 4\n",
            "------------------------\n",
            "loss: 2.301477 [    0/50000]\n",
            "loss: 2.302483 [ 6400/50000]\n",
            "loss: 2.300823 [12800/50000]\n",
            "loss: 2.301953 [19200/50000]\n",
            "loss: 2.300474 [25600/50000]\n",
            "loss: 2.300896 [32000/50000]\n",
            "loss: 2.301581 [38400/50000]\n",
            "loss: 2.301478 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.1%, Avg loss: 2.300739 \n",
            "\n",
            "Epoch 5\n",
            "------------------------\n",
            "loss: 2.301605 [    0/50000]\n",
            "loss: 2.302790 [ 6400/50000]\n",
            "loss: 2.298126 [12800/50000]\n",
            "loss: 2.302572 [19200/50000]\n",
            "loss: 2.297475 [25600/50000]\n",
            "loss: 2.297822 [32000/50000]\n",
            "loss: 2.301010 [38400/50000]\n",
            "loss: 2.301208 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.298089 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imBDYEwbYp2V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}