{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small_convnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOW7PAKWr9ce4RVTAKBiOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malloyca/CSC581B/blob/main/Final%20Project/small_convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI3XLmYiD-UJ"
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuXW8boJEcrA",
        "outputId": "597f5e11-c0fc-406c-fc2f-fa76f73c6025"
      },
      "source": [
        "# Load the training data (CIFAR10 to start)\n",
        "training_data = datasets.CIFAR10(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = datasets.CIFAR10(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2dy9pmEwz6"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE6plIy9E2D_",
        "outputId": "629281f0-0aff-40ee-fdfd-5dd41dcb1307"
      },
      "source": [
        "# Check the data dimensions\n",
        "for X, y in test_dataloader:\n",
        "  print(\"Shape of X batch [Batch size, Channels, Height, Width]: \", X.shape)\n",
        "  print(\"Shape of y batch: \", y.shape, y.dtype)\n",
        "  break"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X batch [Batch size, Channels, Height, Width]:  torch.Size([64, 3, 32, 32])\n",
            "Shape of y batch:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGQGFOcoFAeO"
      },
      "source": [
        "# Building basic convolutional neural nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuGLhBqQE_xI",
        "outputId": "8feeeb02-3c7f-4c4a-e79f-ec584f4c744d"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H5TNXTJE4Nd"
      },
      "source": [
        "# Define the model\n",
        "class basicConvNet(nn.Module):\n",
        "  def __init__(self, name):\n",
        "    super(basicConvNet, self).__init__()\n",
        "    self.name = name\n",
        "    self.basic_conv_net = nn.Sequential(\n",
        "        # 1st layer\n",
        "        nn.Conv2d(3, 256, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        # 2nd layer\n",
        "        nn.Conv2d(256, 128, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        # 3rd layer\n",
        "        nn.Conv2d(128, 64, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        # 4th layer\n",
        "        nn.Conv2d(64, 32, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "        # 5th layer\n",
        "        nn.Conv2d(32, 32, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "        # 6th layer\n",
        "        #nn.Conv2d(16, 16, (3,3), padding='same'),\n",
        "        #nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "        # 7th layer\n",
        "        #nn.Conv2d(16, 16, (3,3), padding='same'),\n",
        "        #nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "        # 8th layer\n",
        "        #nn.Conv2d(16, 16, (3,3), padding='same'),\n",
        "        #nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "\n",
        "        # Output layer\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(32 * 4 * 4, 10),\n",
        "    )\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  # Forward propagation\n",
        "  def forward(self, x):\n",
        "    x = self.basic_conv_net(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "      "
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLQYaHdZTnJK"
      },
      "source": [
        "model = basicConvNet('test').to(device)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deD1sei_WLmX"
      },
      "source": [
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGk95EKWan5"
      },
      "source": [
        "# Training loop\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I_S627HXLWz"
      },
      "source": [
        "# Test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "  return test_loss"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfMapknHYDYO"
      },
      "source": [
        "n_epochs = 100"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uypo30igYE2G"
      },
      "source": [
        "def training_loop(n_epochs, model, train_data, test_data, loss_function,\n",
        "                  optimizer, early_stopping=False, patience=10):\n",
        "  current_epoch = 0\n",
        "  best_epoch = 0\n",
        "  best_loss = float('inf')\n",
        "  patience_counter = 0\n",
        "\n",
        "  for e in range(n_epochs):\n",
        "    print(f\"\\nEpoch {e+1}\\n-----------------------------\")\n",
        "    train(train_data, model, loss_function, optimizer)\n",
        "    test_loss = test(test_data, model, loss_function)\n",
        "\n",
        "    # Iterate epoch counter\n",
        "    current_epoch += 1\n",
        "\n",
        "    # If early_stopping check test_loss\n",
        "    if early_stopping:\n",
        "      # case: test loss beats the current best loss\n",
        "      if test_loss < best_loss:\n",
        "        # store loss\n",
        "        best_loss = test_loss\n",
        "\n",
        "        # reset patience counter\n",
        "        patience_counter = 0\n",
        "\n",
        "        # store model and epoch number\n",
        "        print(\"Storing new best model.\")\n",
        "        best_model_state_dict = copy.deepcopy(model.state_dict)\n",
        "        best_epoch = current_epoch\n",
        "\n",
        "      # Case: patience limit not yet reached => iterate patience counter\n",
        "      elif patience_counter < patience - 1:\n",
        "        patience_counter += 1\n",
        "        print(f\"Patience count: {patience_counter}\")\n",
        "\n",
        "      # Case: patience limit reached\n",
        "      else:\n",
        "        print(\"Finished due to early stopping.\")\n",
        "        print(f\"Saving best model: {model.name}_epoch-{best_epoch:03d}\")\n",
        "        torch.save(best_model_state_dict, f'{model.name}_epoch-{best_epoch:03d}')\n",
        "        break\n",
        "\n",
        "  # If we get here, we did not stop early - save best model\n",
        "  if early_stopping:\n",
        "    print(f\"Saving best model: {model.name}_epoch-{best_epoch:03d}\")\n",
        "    torch.save(best_model_state_dict, f'{model.name}_epoch-{best_epoch:03d}')"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6WkrJ5QYgri",
        "outputId": "aa9b215d-dc98-40ca-8629-0dfd267e77d0"
      },
      "source": [
        "training_loop(n_epochs, model, train_dataloader, test_dataloader, loss_fn,\n",
        "              optimizer, early_stopping=True)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "-----------------------------\n",
            "loss: 2.302630 [    0/50000]\n",
            "loss: 2.302453 [ 6400/50000]\n",
            "loss: 2.302819 [12800/50000]\n",
            "loss: 2.302384 [19200/50000]\n",
            "loss: 2.302638 [25600/50000]\n",
            "loss: 2.302563 [32000/50000]\n",
            "loss: 2.302358 [38400/50000]\n",
            "loss: 2.302765 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302594 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 2\n",
            "-----------------------------\n",
            "loss: 2.302614 [    0/50000]\n",
            "loss: 2.302443 [ 6400/50000]\n",
            "loss: 2.302789 [12800/50000]\n",
            "loss: 2.302383 [19200/50000]\n",
            "loss: 2.302608 [25600/50000]\n",
            "loss: 2.302550 [32000/50000]\n",
            "loss: 2.302352 [38400/50000]\n",
            "loss: 2.302747 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302578 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 3\n",
            "-----------------------------\n",
            "loss: 2.302606 [    0/50000]\n",
            "loss: 2.302438 [ 6400/50000]\n",
            "loss: 2.302763 [12800/50000]\n",
            "loss: 2.302384 [19200/50000]\n",
            "loss: 2.302584 [25600/50000]\n",
            "loss: 2.302538 [32000/50000]\n",
            "loss: 2.302346 [38400/50000]\n",
            "loss: 2.302730 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302563 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 4\n",
            "-----------------------------\n",
            "loss: 2.302601 [    0/50000]\n",
            "loss: 2.302435 [ 6400/50000]\n",
            "loss: 2.302735 [12800/50000]\n",
            "loss: 2.302387 [19200/50000]\n",
            "loss: 2.302557 [25600/50000]\n",
            "loss: 2.302527 [32000/50000]\n",
            "loss: 2.302340 [38400/50000]\n",
            "loss: 2.302713 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302546 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 5\n",
            "-----------------------------\n",
            "loss: 2.302598 [    0/50000]\n",
            "loss: 2.302429 [ 6400/50000]\n",
            "loss: 2.302705 [12800/50000]\n",
            "loss: 2.302391 [19200/50000]\n",
            "loss: 2.302527 [25600/50000]\n",
            "loss: 2.302513 [32000/50000]\n",
            "loss: 2.302333 [38400/50000]\n",
            "loss: 2.302697 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302528 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 6\n",
            "-----------------------------\n",
            "loss: 2.302598 [    0/50000]\n",
            "loss: 2.302425 [ 6400/50000]\n",
            "loss: 2.302670 [12800/50000]\n",
            "loss: 2.302390 [19200/50000]\n",
            "loss: 2.302496 [25600/50000]\n",
            "loss: 2.302493 [32000/50000]\n",
            "loss: 2.302323 [38400/50000]\n",
            "loss: 2.302677 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302507 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 7\n",
            "-----------------------------\n",
            "loss: 2.302598 [    0/50000]\n",
            "loss: 2.302421 [ 6400/50000]\n",
            "loss: 2.302631 [12800/50000]\n",
            "loss: 2.302390 [19200/50000]\n",
            "loss: 2.302462 [25600/50000]\n",
            "loss: 2.302471 [32000/50000]\n",
            "loss: 2.302310 [38400/50000]\n",
            "loss: 2.302657 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302483 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 8\n",
            "-----------------------------\n",
            "loss: 2.302598 [    0/50000]\n",
            "loss: 2.302416 [ 6400/50000]\n",
            "loss: 2.302582 [12800/50000]\n",
            "loss: 2.302392 [19200/50000]\n",
            "loss: 2.302420 [25600/50000]\n",
            "loss: 2.302443 [32000/50000]\n",
            "loss: 2.302290 [38400/50000]\n",
            "loss: 2.302633 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.4%, Avg loss: 2.302454 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 9\n",
            "-----------------------------\n",
            "loss: 2.302598 [    0/50000]\n",
            "loss: 2.302410 [ 6400/50000]\n",
            "loss: 2.302523 [12800/50000]\n",
            "loss: 2.302395 [19200/50000]\n",
            "loss: 2.302368 [25600/50000]\n",
            "loss: 2.302406 [32000/50000]\n",
            "loss: 2.302263 [38400/50000]\n",
            "loss: 2.302601 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 12.4%, Avg loss: 2.302418 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 10\n",
            "-----------------------------\n",
            "loss: 2.302598 [    0/50000]\n",
            "loss: 2.302405 [ 6400/50000]\n",
            "loss: 2.302453 [12800/50000]\n",
            "loss: 2.302396 [19200/50000]\n",
            "loss: 2.302305 [25600/50000]\n",
            "loss: 2.302361 [32000/50000]\n",
            "loss: 2.302227 [38400/50000]\n",
            "loss: 2.302567 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 15.0%, Avg loss: 2.302372 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 11\n",
            "-----------------------------\n",
            "loss: 2.302595 [    0/50000]\n",
            "loss: 2.302392 [ 6400/50000]\n",
            "loss: 2.302370 [12800/50000]\n",
            "loss: 2.302394 [19200/50000]\n",
            "loss: 2.302227 [25600/50000]\n",
            "loss: 2.302300 [32000/50000]\n",
            "loss: 2.302177 [38400/50000]\n",
            "loss: 2.302525 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 18.5%, Avg loss: 2.302310 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 12\n",
            "-----------------------------\n",
            "loss: 2.302589 [    0/50000]\n",
            "loss: 2.302374 [ 6400/50000]\n",
            "loss: 2.302258 [12800/50000]\n",
            "loss: 2.302390 [19200/50000]\n",
            "loss: 2.302125 [25600/50000]\n",
            "loss: 2.302215 [32000/50000]\n",
            "loss: 2.302107 [38400/50000]\n",
            "loss: 2.302468 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 20.2%, Avg loss: 2.302221 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 13\n",
            "-----------------------------\n",
            "loss: 2.302579 [    0/50000]\n",
            "loss: 2.302346 [ 6400/50000]\n",
            "loss: 2.302098 [12800/50000]\n",
            "loss: 2.302381 [19200/50000]\n",
            "loss: 2.301980 [25600/50000]\n",
            "loss: 2.302080 [32000/50000]\n",
            "loss: 2.301992 [38400/50000]\n",
            "loss: 2.302374 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 16.8%, Avg loss: 2.302085 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 14\n",
            "-----------------------------\n",
            "loss: 2.302561 [    0/50000]\n",
            "loss: 2.302296 [ 6400/50000]\n",
            "loss: 2.301848 [12800/50000]\n",
            "loss: 2.302361 [19200/50000]\n",
            "loss: 2.301755 [25600/50000]\n",
            "loss: 2.301857 [32000/50000]\n",
            "loss: 2.301807 [38400/50000]\n",
            "loss: 2.302220 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 12.9%, Avg loss: 2.301861 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 15\n",
            "-----------------------------\n",
            "loss: 2.302534 [    0/50000]\n",
            "loss: 2.302209 [ 6400/50000]\n",
            "loss: 2.301422 [12800/50000]\n",
            "loss: 2.302326 [19200/50000]\n",
            "loss: 2.301366 [25600/50000]\n",
            "loss: 2.301451 [32000/50000]\n",
            "loss: 2.301465 [38400/50000]\n",
            "loss: 2.301957 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 11.4%, Avg loss: 2.301428 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 16\n",
            "-----------------------------\n",
            "loss: 2.302487 [    0/50000]\n",
            "loss: 2.302050 [ 6400/50000]\n",
            "loss: 2.300547 [12800/50000]\n",
            "loss: 2.302241 [19200/50000]\n",
            "loss: 2.300530 [25600/50000]\n",
            "loss: 2.300509 [32000/50000]\n",
            "loss: 2.300642 [38400/50000]\n",
            "loss: 2.301359 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.6%, Avg loss: 2.300337 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 17\n",
            "-----------------------------\n",
            "loss: 2.302450 [    0/50000]\n",
            "loss: 2.301674 [ 6400/50000]\n",
            "loss: 2.297984 [12800/50000]\n",
            "loss: 2.301826 [19200/50000]\n",
            "loss: 2.297775 [25600/50000]\n",
            "loss: 2.296646 [32000/50000]\n",
            "loss: 2.297125 [38400/50000]\n",
            "loss: 2.298857 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.3%, Avg loss: 2.294514 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 18\n",
            "-----------------------------\n",
            "loss: 2.303676 [    0/50000]\n",
            "loss: 2.300115 [ 6400/50000]\n",
            "loss: 2.280546 [12800/50000]\n",
            "loss: 2.294341 [19200/50000]\n",
            "loss: 2.275043 [25600/50000]\n",
            "loss: 2.261269 [32000/50000]\n",
            "loss: 2.277719 [38400/50000]\n",
            "loss: 2.275594 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 17.8%, Avg loss: 2.267446 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 19\n",
            "-----------------------------\n",
            "loss: 2.294126 [    0/50000]\n",
            "loss: 2.280869 [ 6400/50000]\n",
            "loss: 2.246729 [12800/50000]\n",
            "loss: 2.273322 [19200/50000]\n",
            "loss: 2.248406 [25600/50000]\n",
            "loss: 2.238013 [32000/50000]\n",
            "loss: 2.226743 [38400/50000]\n",
            "loss: 2.229221 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 22.2%, Avg loss: 2.223938 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 20\n",
            "-----------------------------\n",
            "loss: 2.277869 [    0/50000]\n",
            "loss: 2.223920 [ 6400/50000]\n",
            "loss: 2.188608 [12800/50000]\n",
            "loss: 2.290441 [19200/50000]\n",
            "loss: 2.164615 [25600/50000]\n",
            "loss: 2.215550 [32000/50000]\n",
            "loss: 2.219800 [38400/50000]\n",
            "loss: 2.209584 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 22.9%, Avg loss: 2.218114 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 21\n",
            "-----------------------------\n",
            "loss: 2.248953 [    0/50000]\n",
            "loss: 2.182074 [ 6400/50000]\n",
            "loss: 2.175079 [12800/50000]\n",
            "loss: 2.290652 [19200/50000]\n",
            "loss: 2.130763 [25600/50000]\n",
            "loss: 2.193093 [32000/50000]\n",
            "loss: 2.188291 [38400/50000]\n",
            "loss: 2.208893 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.4%, Avg loss: 2.209334 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 22\n",
            "-----------------------------\n",
            "loss: 2.227665 [    0/50000]\n",
            "loss: 2.172633 [ 6400/50000]\n",
            "loss: 2.144956 [12800/50000]\n",
            "loss: 2.296945 [19200/50000]\n",
            "loss: 2.119147 [25600/50000]\n",
            "loss: 2.168117 [32000/50000]\n",
            "loss: 2.170375 [38400/50000]\n",
            "loss: 2.193093 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 27.4%, Avg loss: 2.172830 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 23\n",
            "-----------------------------\n",
            "loss: 2.198998 [    0/50000]\n",
            "loss: 2.167661 [ 6400/50000]\n",
            "loss: 2.127888 [12800/50000]\n",
            "loss: 2.302193 [19200/50000]\n",
            "loss: 2.117744 [25600/50000]\n",
            "loss: 2.143820 [32000/50000]\n",
            "loss: 2.148009 [38400/50000]\n",
            "loss: 2.162966 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.2%, Avg loss: 2.158768 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 24\n",
            "-----------------------------\n",
            "loss: 2.191534 [    0/50000]\n",
            "loss: 2.161445 [ 6400/50000]\n",
            "loss: 2.108549 [12800/50000]\n",
            "loss: 2.305437 [19200/50000]\n",
            "loss: 2.110667 [25600/50000]\n",
            "loss: 2.131809 [32000/50000]\n",
            "loss: 2.134647 [38400/50000]\n",
            "loss: 2.145773 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 30.3%, Avg loss: 2.147195 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 25\n",
            "-----------------------------\n",
            "loss: 2.192626 [    0/50000]\n",
            "loss: 2.147364 [ 6400/50000]\n",
            "loss: 2.092157 [12800/50000]\n",
            "loss: 2.297087 [19200/50000]\n",
            "loss: 2.106349 [25600/50000]\n",
            "loss: 2.131356 [32000/50000]\n",
            "loss: 2.134666 [38400/50000]\n",
            "loss: 2.132189 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 31.0%, Avg loss: 2.141703 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 26\n",
            "-----------------------------\n",
            "loss: 2.192547 [    0/50000]\n",
            "loss: 2.120009 [ 6400/50000]\n",
            "loss: 2.090790 [12800/50000]\n",
            "loss: 2.287227 [19200/50000]\n",
            "loss: 2.108302 [25600/50000]\n",
            "loss: 2.119356 [32000/50000]\n",
            "loss: 2.131790 [38400/50000]\n",
            "loss: 2.120399 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 2.135482 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 27\n",
            "-----------------------------\n",
            "loss: 2.185619 [    0/50000]\n",
            "loss: 2.106567 [ 6400/50000]\n",
            "loss: 2.090851 [12800/50000]\n",
            "loss: 2.286394 [19200/50000]\n",
            "loss: 2.105071 [25600/50000]\n",
            "loss: 2.112731 [32000/50000]\n",
            "loss: 2.136286 [38400/50000]\n",
            "loss: 2.114734 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 32.0%, Avg loss: 2.133996 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 28\n",
            "-----------------------------\n",
            "loss: 2.150914 [    0/50000]\n",
            "loss: 2.105673 [ 6400/50000]\n",
            "loss: 2.089551 [12800/50000]\n",
            "loss: 2.281121 [19200/50000]\n",
            "loss: 2.104371 [25600/50000]\n",
            "loss: 2.099008 [32000/50000]\n",
            "loss: 2.140138 [38400/50000]\n",
            "loss: 2.113983 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 32.6%, Avg loss: 2.124584 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 29\n",
            "-----------------------------\n",
            "loss: 2.179899 [    0/50000]\n",
            "loss: 2.092421 [ 6400/50000]\n",
            "loss: 2.082583 [12800/50000]\n",
            "loss: 2.277266 [19200/50000]\n",
            "loss: 2.097762 [25600/50000]\n",
            "loss: 2.098561 [32000/50000]\n",
            "loss: 2.135979 [38400/50000]\n",
            "loss: 2.127220 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 30.5%, Avg loss: 2.149237 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 30\n",
            "-----------------------------\n",
            "loss: 2.146857 [    0/50000]\n",
            "loss: 2.089488 [ 6400/50000]\n",
            "loss: 2.080403 [12800/50000]\n",
            "loss: 2.273860 [19200/50000]\n",
            "loss: 2.093900 [25600/50000]\n",
            "loss: 2.091581 [32000/50000]\n",
            "loss: 2.125320 [38400/50000]\n",
            "loss: 2.135518 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.1%, Avg loss: 2.113380 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 31\n",
            "-----------------------------\n",
            "loss: 2.132908 [    0/50000]\n",
            "loss: 2.096435 [ 6400/50000]\n",
            "loss: 2.078650 [12800/50000]\n",
            "loss: 2.271364 [19200/50000]\n",
            "loss: 2.097935 [25600/50000]\n",
            "loss: 2.097539 [32000/50000]\n",
            "loss: 2.118629 [38400/50000]\n",
            "loss: 2.127689 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 30.1%, Avg loss: 2.151427 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 32\n",
            "-----------------------------\n",
            "loss: 2.149921 [    0/50000]\n",
            "loss: 2.096176 [ 6400/50000]\n",
            "loss: 2.074625 [12800/50000]\n",
            "loss: 2.263331 [19200/50000]\n",
            "loss: 2.114038 [25600/50000]\n",
            "loss: 2.091849 [32000/50000]\n",
            "loss: 2.114732 [38400/50000]\n",
            "loss: 2.131202 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 32.7%, Avg loss: 2.123743 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 33\n",
            "-----------------------------\n",
            "loss: 2.139812 [    0/50000]\n",
            "loss: 2.094557 [ 6400/50000]\n",
            "loss: 2.074094 [12800/50000]\n",
            "loss: 2.251282 [19200/50000]\n",
            "loss: 2.109714 [25600/50000]\n",
            "loss: 2.086002 [32000/50000]\n",
            "loss: 2.120521 [38400/50000]\n",
            "loss: 2.134188 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.5%, Avg loss: 2.098381 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 34\n",
            "-----------------------------\n",
            "loss: 2.130241 [    0/50000]\n",
            "loss: 2.095832 [ 6400/50000]\n",
            "loss: 2.080323 [12800/50000]\n",
            "loss: 2.242711 [19200/50000]\n",
            "loss: 2.103039 [25600/50000]\n",
            "loss: 2.087131 [32000/50000]\n",
            "loss: 2.116894 [38400/50000]\n",
            "loss: 2.138877 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 2.088288 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 35\n",
            "-----------------------------\n",
            "loss: 2.117638 [    0/50000]\n",
            "loss: 2.087608 [ 6400/50000]\n",
            "loss: 2.083615 [12800/50000]\n",
            "loss: 2.231226 [19200/50000]\n",
            "loss: 2.092797 [25600/50000]\n",
            "loss: 2.085788 [32000/50000]\n",
            "loss: 2.110966 [38400/50000]\n",
            "loss: 2.142337 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 2.085832 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 36\n",
            "-----------------------------\n",
            "loss: 2.110152 [    0/50000]\n",
            "loss: 2.089582 [ 6400/50000]\n",
            "loss: 2.087266 [12800/50000]\n",
            "loss: 2.225014 [19200/50000]\n",
            "loss: 2.093022 [25600/50000]\n",
            "loss: 2.090628 [32000/50000]\n",
            "loss: 2.115597 [38400/50000]\n",
            "loss: 2.144082 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.3%, Avg loss: 2.082637 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 37\n",
            "-----------------------------\n",
            "loss: 2.103249 [    0/50000]\n",
            "loss: 2.088414 [ 6400/50000]\n",
            "loss: 2.090984 [12800/50000]\n",
            "loss: 2.222752 [19200/50000]\n",
            "loss: 2.091897 [25600/50000]\n",
            "loss: 2.078057 [32000/50000]\n",
            "loss: 2.121295 [38400/50000]\n",
            "loss: 2.142246 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.6%, Avg loss: 2.079470 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 38\n",
            "-----------------------------\n",
            "loss: 2.103134 [    0/50000]\n",
            "loss: 2.086685 [ 6400/50000]\n",
            "loss: 2.087128 [12800/50000]\n",
            "loss: 2.225286 [19200/50000]\n",
            "loss: 2.087526 [25600/50000]\n",
            "loss: 2.073009 [32000/50000]\n",
            "loss: 2.117003 [38400/50000]\n",
            "loss: 2.139635 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.6%, Avg loss: 2.072441 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 39\n",
            "-----------------------------\n",
            "loss: 2.097687 [    0/50000]\n",
            "loss: 2.091132 [ 6400/50000]\n",
            "loss: 2.079832 [12800/50000]\n",
            "loss: 2.227080 [19200/50000]\n",
            "loss: 2.076341 [25600/50000]\n",
            "loss: 2.072377 [32000/50000]\n",
            "loss: 2.107164 [38400/50000]\n",
            "loss: 2.131771 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.0%, Avg loss: 2.068799 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 40\n",
            "-----------------------------\n",
            "loss: 2.091218 [    0/50000]\n",
            "loss: 2.078325 [ 6400/50000]\n",
            "loss: 2.070371 [12800/50000]\n",
            "loss: 2.222652 [19200/50000]\n",
            "loss: 2.070700 [25600/50000]\n",
            "loss: 2.073565 [32000/50000]\n",
            "loss: 2.110863 [38400/50000]\n",
            "loss: 2.122217 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.4%, Avg loss: 2.063408 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 41\n",
            "-----------------------------\n",
            "loss: 2.085599 [    0/50000]\n",
            "loss: 2.094081 [ 6400/50000]\n",
            "loss: 2.064611 [12800/50000]\n",
            "loss: 2.216127 [19200/50000]\n",
            "loss: 2.059231 [25600/50000]\n",
            "loss: 2.073813 [32000/50000]\n",
            "loss: 2.103425 [38400/50000]\n",
            "loss: 2.114023 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.6%, Avg loss: 2.059081 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 42\n",
            "-----------------------------\n",
            "loss: 2.087086 [    0/50000]\n",
            "loss: 2.097367 [ 6400/50000]\n",
            "loss: 2.056910 [12800/50000]\n",
            "loss: 2.219682 [19200/50000]\n",
            "loss: 2.048458 [25600/50000]\n",
            "loss: 2.074331 [32000/50000]\n",
            "loss: 2.106359 [38400/50000]\n",
            "loss: 2.113425 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.0%, Avg loss: 2.054681 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 43\n",
            "-----------------------------\n",
            "loss: 2.085635 [    0/50000]\n",
            "loss: 2.096731 [ 6400/50000]\n",
            "loss: 2.045208 [12800/50000]\n",
            "loss: 2.216679 [19200/50000]\n",
            "loss: 2.033985 [25600/50000]\n",
            "loss: 2.078344 [32000/50000]\n",
            "loss: 2.098999 [38400/50000]\n",
            "loss: 2.111857 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 2.052233 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 44\n",
            "-----------------------------\n",
            "loss: 2.079443 [    0/50000]\n",
            "loss: 2.095882 [ 6400/50000]\n",
            "loss: 2.035848 [12800/50000]\n",
            "loss: 2.210573 [19200/50000]\n",
            "loss: 2.022305 [25600/50000]\n",
            "loss: 2.076170 [32000/50000]\n",
            "loss: 2.095520 [38400/50000]\n",
            "loss: 2.109174 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 41.1%, Avg loss: 2.046040 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 45\n",
            "-----------------------------\n",
            "loss: 2.066652 [    0/50000]\n",
            "loss: 2.092574 [ 6400/50000]\n",
            "loss: 2.032178 [12800/50000]\n",
            "loss: 2.208235 [19200/50000]\n",
            "loss: 2.013235 [25600/50000]\n",
            "loss: 2.064899 [32000/50000]\n",
            "loss: 2.078289 [38400/50000]\n",
            "loss: 2.104703 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.6%, Avg loss: 2.058215 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 46\n",
            "-----------------------------\n",
            "loss: 2.040013 [    0/50000]\n",
            "loss: 2.093975 [ 6400/50000]\n",
            "loss: 2.009955 [12800/50000]\n",
            "loss: 2.204356 [19200/50000]\n",
            "loss: 2.009252 [25600/50000]\n",
            "loss: 2.071071 [32000/50000]\n",
            "loss: 2.072995 [38400/50000]\n",
            "loss: 2.099734 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 2.051731 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 47\n",
            "-----------------------------\n",
            "loss: 2.031700 [    0/50000]\n",
            "loss: 2.086566 [ 6400/50000]\n",
            "loss: 2.001945 [12800/50000]\n",
            "loss: 2.194811 [19200/50000]\n",
            "loss: 2.007141 [25600/50000]\n",
            "loss: 2.063962 [32000/50000]\n",
            "loss: 2.078632 [38400/50000]\n",
            "loss: 2.093042 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 2.045057 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 48\n",
            "-----------------------------\n",
            "loss: 2.021039 [    0/50000]\n",
            "loss: 2.072299 [ 6400/50000]\n",
            "loss: 1.985786 [12800/50000]\n",
            "loss: 2.178096 [19200/50000]\n",
            "loss: 2.005532 [25600/50000]\n",
            "loss: 2.049311 [32000/50000]\n",
            "loss: 2.082790 [38400/50000]\n",
            "loss: 2.095158 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 2.056179 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 49\n",
            "-----------------------------\n",
            "loss: 2.013460 [    0/50000]\n",
            "loss: 2.070237 [ 6400/50000]\n",
            "loss: 1.977682 [12800/50000]\n",
            "loss: 2.168797 [19200/50000]\n",
            "loss: 2.002684 [25600/50000]\n",
            "loss: 2.031909 [32000/50000]\n",
            "loss: 2.070620 [38400/50000]\n",
            "loss: 2.089147 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 2.038725 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 50\n",
            "-----------------------------\n",
            "loss: 2.022874 [    0/50000]\n",
            "loss: 2.058729 [ 6400/50000]\n",
            "loss: 1.956885 [12800/50000]\n",
            "loss: 2.152670 [19200/50000]\n",
            "loss: 1.999094 [25600/50000]\n",
            "loss: 2.012463 [32000/50000]\n",
            "loss: 2.068769 [38400/50000]\n",
            "loss: 2.081477 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.6%, Avg loss: 2.056502 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 51\n",
            "-----------------------------\n",
            "loss: 2.039733 [    0/50000]\n",
            "loss: 2.041269 [ 6400/50000]\n",
            "loss: 1.948241 [12800/50000]\n",
            "loss: 2.122939 [19200/50000]\n",
            "loss: 2.004917 [25600/50000]\n",
            "loss: 2.013853 [32000/50000]\n",
            "loss: 2.068504 [38400/50000]\n",
            "loss: 2.072552 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.6%, Avg loss: 2.105153 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 52\n",
            "-----------------------------\n",
            "loss: 2.064299 [    0/50000]\n",
            "loss: 2.027143 [ 6400/50000]\n",
            "loss: 1.938087 [12800/50000]\n",
            "loss: 2.121274 [19200/50000]\n",
            "loss: 1.992072 [25600/50000]\n",
            "loss: 2.021991 [32000/50000]\n",
            "loss: 2.036056 [38400/50000]\n",
            "loss: 2.075054 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.2%, Avg loss: 2.062884 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 53\n",
            "-----------------------------\n",
            "loss: 2.038282 [    0/50000]\n",
            "loss: 2.026980 [ 6400/50000]\n",
            "loss: 1.923511 [12800/50000]\n",
            "loss: 2.096174 [19200/50000]\n",
            "loss: 1.986223 [25600/50000]\n",
            "loss: 2.016429 [32000/50000]\n",
            "loss: 2.018612 [38400/50000]\n",
            "loss: 2.067471 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 2.092513 \n",
            "\n",
            "Patience count: 4\n",
            "\n",
            "Epoch 54\n",
            "-----------------------------\n",
            "loss: 2.048689 [    0/50000]\n",
            "loss: 2.022774 [ 6400/50000]\n",
            "loss: 1.924281 [12800/50000]\n",
            "loss: 2.097899 [19200/50000]\n",
            "loss: 1.980830 [25600/50000]\n",
            "loss: 2.010669 [32000/50000]\n",
            "loss: 2.010929 [38400/50000]\n",
            "loss: 2.057830 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.9%, Avg loss: 2.074995 \n",
            "\n",
            "Patience count: 5\n",
            "\n",
            "Epoch 55\n",
            "-----------------------------\n",
            "loss: 2.020293 [    0/50000]\n",
            "loss: 2.012921 [ 6400/50000]\n",
            "loss: 1.918167 [12800/50000]\n",
            "loss: 2.094726 [19200/50000]\n",
            "loss: 1.978223 [25600/50000]\n",
            "loss: 2.007892 [32000/50000]\n",
            "loss: 2.037628 [38400/50000]\n",
            "loss: 2.043857 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 41.7%, Avg loss: 2.039568 \n",
            "\n",
            "Patience count: 6\n",
            "\n",
            "Epoch 56\n",
            "-----------------------------\n",
            "loss: 1.977581 [    0/50000]\n",
            "loss: 2.013495 [ 6400/50000]\n",
            "loss: 1.927355 [12800/50000]\n",
            "loss: 2.084986 [19200/50000]\n",
            "loss: 1.981410 [25600/50000]\n",
            "loss: 1.993003 [32000/50000]\n",
            "loss: 2.028763 [38400/50000]\n",
            "loss: 2.042142 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 42.0%, Avg loss: 2.034391 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 57\n",
            "-----------------------------\n",
            "loss: 1.975002 [    0/50000]\n",
            "loss: 1.998603 [ 6400/50000]\n",
            "loss: 1.919390 [12800/50000]\n",
            "loss: 2.069568 [19200/50000]\n",
            "loss: 1.973610 [25600/50000]\n",
            "loss: 1.985472 [32000/50000]\n",
            "loss: 2.018254 [38400/50000]\n",
            "loss: 2.023099 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 41.2%, Avg loss: 2.040375 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 58\n",
            "-----------------------------\n",
            "loss: 1.993158 [    0/50000]\n",
            "loss: 2.000413 [ 6400/50000]\n",
            "loss: 1.919713 [12800/50000]\n",
            "loss: 2.056874 [19200/50000]\n",
            "loss: 1.971737 [25600/50000]\n",
            "loss: 1.980909 [32000/50000]\n",
            "loss: 2.007905 [38400/50000]\n",
            "loss: 2.028677 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 48.4%, Avg loss: 1.974685 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 59\n",
            "-----------------------------\n",
            "loss: 1.926408 [    0/50000]\n",
            "loss: 1.987593 [ 6400/50000]\n",
            "loss: 1.910510 [12800/50000]\n",
            "loss: 2.050658 [19200/50000]\n",
            "loss: 1.969788 [25600/50000]\n",
            "loss: 1.962576 [32000/50000]\n",
            "loss: 2.003117 [38400/50000]\n",
            "loss: 2.015934 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 48.9%, Avg loss: 1.971329 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 60\n",
            "-----------------------------\n",
            "loss: 1.933724 [    0/50000]\n",
            "loss: 1.985300 [ 6400/50000]\n",
            "loss: 1.914868 [12800/50000]\n",
            "loss: 2.056287 [19200/50000]\n",
            "loss: 1.978248 [25600/50000]\n",
            "loss: 1.956996 [32000/50000]\n",
            "loss: 2.010775 [38400/50000]\n",
            "loss: 2.012924 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 49.4%, Avg loss: 1.966869 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 61\n",
            "-----------------------------\n",
            "loss: 1.914681 [    0/50000]\n",
            "loss: 1.985556 [ 6400/50000]\n",
            "loss: 1.885462 [12800/50000]\n",
            "loss: 2.056216 [19200/50000]\n",
            "loss: 1.963503 [25600/50000]\n",
            "loss: 1.956733 [32000/50000]\n",
            "loss: 2.003873 [38400/50000]\n",
            "loss: 1.993452 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.3%, Avg loss: 1.957266 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 62\n",
            "-----------------------------\n",
            "loss: 1.910046 [    0/50000]\n",
            "loss: 1.972551 [ 6400/50000]\n",
            "loss: 1.876262 [12800/50000]\n",
            "loss: 2.057308 [19200/50000]\n",
            "loss: 1.966394 [25600/50000]\n",
            "loss: 1.952690 [32000/50000]\n",
            "loss: 2.003844 [38400/50000]\n",
            "loss: 1.988337 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.8%, Avg loss: 1.953170 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 63\n",
            "-----------------------------\n",
            "loss: 1.909482 [    0/50000]\n",
            "loss: 1.966472 [ 6400/50000]\n",
            "loss: 1.867164 [12800/50000]\n",
            "loss: 2.057926 [19200/50000]\n",
            "loss: 1.952369 [25600/50000]\n",
            "loss: 1.949645 [32000/50000]\n",
            "loss: 1.999895 [38400/50000]\n",
            "loss: 1.999504 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.4%, Avg loss: 1.955707 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 64\n",
            "-----------------------------\n",
            "loss: 1.915965 [    0/50000]\n",
            "loss: 1.962531 [ 6400/50000]\n",
            "loss: 1.854224 [12800/50000]\n",
            "loss: 2.056517 [19200/50000]\n",
            "loss: 1.951394 [25600/50000]\n",
            "loss: 1.947294 [32000/50000]\n",
            "loss: 1.996579 [38400/50000]\n",
            "loss: 2.000058 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 51.3%, Avg loss: 1.946627 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 65\n",
            "-----------------------------\n",
            "loss: 1.910004 [    0/50000]\n",
            "loss: 1.953422 [ 6400/50000]\n",
            "loss: 1.858458 [12800/50000]\n",
            "loss: 2.046156 [19200/50000]\n",
            "loss: 1.960221 [25600/50000]\n",
            "loss: 1.941844 [32000/50000]\n",
            "loss: 1.998138 [38400/50000]\n",
            "loss: 1.996398 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 51.6%, Avg loss: 1.943790 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 66\n",
            "-----------------------------\n",
            "loss: 1.905947 [    0/50000]\n",
            "loss: 1.937956 [ 6400/50000]\n",
            "loss: 1.845579 [12800/50000]\n",
            "loss: 2.032647 [19200/50000]\n",
            "loss: 1.959804 [25600/50000]\n",
            "loss: 1.945794 [32000/50000]\n",
            "loss: 1.990278 [38400/50000]\n",
            "loss: 1.992165 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 51.5%, Avg loss: 1.944507 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 67\n",
            "-----------------------------\n",
            "loss: 1.916098 [    0/50000]\n",
            "loss: 1.937258 [ 6400/50000]\n",
            "loss: 1.837775 [12800/50000]\n",
            "loss: 2.032882 [19200/50000]\n",
            "loss: 1.941105 [25600/50000]\n",
            "loss: 1.939628 [32000/50000]\n",
            "loss: 1.973890 [38400/50000]\n",
            "loss: 1.984778 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 51.6%, Avg loss: 1.942797 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 68\n",
            "-----------------------------\n",
            "loss: 1.915164 [    0/50000]\n",
            "loss: 1.930846 [ 6400/50000]\n",
            "loss: 1.838573 [12800/50000]\n",
            "loss: 2.023621 [19200/50000]\n",
            "loss: 1.931206 [25600/50000]\n",
            "loss: 1.940359 [32000/50000]\n",
            "loss: 1.964110 [38400/50000]\n",
            "loss: 1.990720 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 52.8%, Avg loss: 1.932298 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 69\n",
            "-----------------------------\n",
            "loss: 1.899390 [    0/50000]\n",
            "loss: 1.926103 [ 6400/50000]\n",
            "loss: 1.832783 [12800/50000]\n",
            "loss: 2.009767 [19200/50000]\n",
            "loss: 1.944979 [25600/50000]\n",
            "loss: 1.936873 [32000/50000]\n",
            "loss: 1.961005 [38400/50000]\n",
            "loss: 2.003956 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 53.2%, Avg loss: 1.930119 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 70\n",
            "-----------------------------\n",
            "loss: 1.892696 [    0/50000]\n",
            "loss: 1.920691 [ 6400/50000]\n",
            "loss: 1.821995 [12800/50000]\n",
            "loss: 2.007201 [19200/50000]\n",
            "loss: 1.923447 [25600/50000]\n",
            "loss: 1.936144 [32000/50000]\n",
            "loss: 1.950067 [38400/50000]\n",
            "loss: 2.017914 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.9%, Avg loss: 1.951434 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 71\n",
            "-----------------------------\n",
            "loss: 1.939591 [    0/50000]\n",
            "loss: 1.926748 [ 6400/50000]\n",
            "loss: 1.820511 [12800/50000]\n",
            "loss: 2.001455 [19200/50000]\n",
            "loss: 1.916233 [25600/50000]\n",
            "loss: 1.932066 [32000/50000]\n",
            "loss: 1.945478 [38400/50000]\n",
            "loss: 2.028450 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 51.6%, Avg loss: 1.943867 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 72\n",
            "-----------------------------\n",
            "loss: 1.922549 [    0/50000]\n",
            "loss: 1.923670 [ 6400/50000]\n",
            "loss: 1.826555 [12800/50000]\n",
            "loss: 1.988207 [19200/50000]\n",
            "loss: 1.906019 [25600/50000]\n",
            "loss: 1.922554 [32000/50000]\n",
            "loss: 1.934534 [38400/50000]\n",
            "loss: 2.025084 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 54.0%, Avg loss: 1.923090 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 73\n",
            "-----------------------------\n",
            "loss: 1.886721 [    0/50000]\n",
            "loss: 1.921985 [ 6400/50000]\n",
            "loss: 1.826316 [12800/50000]\n",
            "loss: 1.991940 [19200/50000]\n",
            "loss: 1.896919 [25600/50000]\n",
            "loss: 1.917026 [32000/50000]\n",
            "loss: 1.935502 [38400/50000]\n",
            "loss: 2.015722 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.2%, Avg loss: 1.956102 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 74\n",
            "-----------------------------\n",
            "loss: 1.913020 [    0/50000]\n",
            "loss: 1.919102 [ 6400/50000]\n",
            "loss: 1.825475 [12800/50000]\n",
            "loss: 1.988542 [19200/50000]\n",
            "loss: 1.885994 [25600/50000]\n",
            "loss: 1.915969 [32000/50000]\n",
            "loss: 1.937208 [38400/50000]\n",
            "loss: 2.016850 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 52.6%, Avg loss: 1.934411 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 75\n",
            "-----------------------------\n",
            "loss: 1.898513 [    0/50000]\n",
            "loss: 1.913021 [ 6400/50000]\n",
            "loss: 1.818225 [12800/50000]\n",
            "loss: 1.986540 [19200/50000]\n",
            "loss: 1.884239 [25600/50000]\n",
            "loss: 1.908625 [32000/50000]\n",
            "loss: 1.924295 [38400/50000]\n",
            "loss: 2.002609 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 53.4%, Avg loss: 1.924164 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 76\n",
            "-----------------------------\n",
            "loss: 1.898814 [    0/50000]\n",
            "loss: 1.902427 [ 6400/50000]\n",
            "loss: 1.822783 [12800/50000]\n",
            "loss: 1.985488 [19200/50000]\n",
            "loss: 1.894517 [25600/50000]\n",
            "loss: 1.899414 [32000/50000]\n",
            "loss: 1.921541 [38400/50000]\n",
            "loss: 1.972861 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 53.4%, Avg loss: 1.925936 \n",
            "\n",
            "Patience count: 4\n",
            "\n",
            "Epoch 77\n",
            "-----------------------------\n",
            "loss: 1.901579 [    0/50000]\n",
            "loss: 1.894885 [ 6400/50000]\n",
            "loss: 1.820319 [12800/50000]\n",
            "loss: 1.977973 [19200/50000]\n",
            "loss: 1.885745 [25600/50000]\n",
            "loss: 1.890675 [32000/50000]\n",
            "loss: 1.914496 [38400/50000]\n",
            "loss: 1.948056 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 54.1%, Avg loss: 1.921451 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 78\n",
            "-----------------------------\n",
            "loss: 1.896820 [    0/50000]\n",
            "loss: 1.882103 [ 6400/50000]\n",
            "loss: 1.817870 [12800/50000]\n",
            "loss: 1.973520 [19200/50000]\n",
            "loss: 1.875031 [25600/50000]\n",
            "loss: 1.897668 [32000/50000]\n",
            "loss: 1.910575 [38400/50000]\n",
            "loss: 1.947473 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 53.9%, Avg loss: 1.922459 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 79\n",
            "-----------------------------\n",
            "loss: 1.892957 [    0/50000]\n",
            "loss: 1.869727 [ 6400/50000]\n",
            "loss: 1.809529 [12800/50000]\n",
            "loss: 1.965216 [19200/50000]\n",
            "loss: 1.861858 [25600/50000]\n",
            "loss: 1.900306 [32000/50000]\n",
            "loss: 1.908774 [38400/50000]\n",
            "loss: 1.946749 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 1.924145 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 80\n",
            "-----------------------------\n",
            "loss: 1.887363 [    0/50000]\n",
            "loss: 1.860300 [ 6400/50000]\n",
            "loss: 1.809513 [12800/50000]\n",
            "loss: 1.961313 [19200/50000]\n",
            "loss: 1.856685 [25600/50000]\n",
            "loss: 1.902652 [32000/50000]\n",
            "loss: 1.908946 [38400/50000]\n",
            "loss: 1.943971 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 55.4%, Avg loss: 1.906777 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 81\n",
            "-----------------------------\n",
            "loss: 1.881013 [    0/50000]\n",
            "loss: 1.869696 [ 6400/50000]\n",
            "loss: 1.807083 [12800/50000]\n",
            "loss: 1.953070 [19200/50000]\n",
            "loss: 1.854065 [25600/50000]\n",
            "loss: 1.909307 [32000/50000]\n",
            "loss: 1.902768 [38400/50000]\n",
            "loss: 1.936283 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.4%, Avg loss: 1.898521 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 82\n",
            "-----------------------------\n",
            "loss: 1.880252 [    0/50000]\n",
            "loss: 1.855498 [ 6400/50000]\n",
            "loss: 1.806736 [12800/50000]\n",
            "loss: 1.946570 [19200/50000]\n",
            "loss: 1.845510 [25600/50000]\n",
            "loss: 1.891875 [32000/50000]\n",
            "loss: 1.899278 [38400/50000]\n",
            "loss: 1.939694 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.4%, Avg loss: 1.899107 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 83\n",
            "-----------------------------\n",
            "loss: 1.871001 [    0/50000]\n",
            "loss: 1.847994 [ 6400/50000]\n",
            "loss: 1.793716 [12800/50000]\n",
            "loss: 1.940745 [19200/50000]\n",
            "loss: 1.844112 [25600/50000]\n",
            "loss: 1.890940 [32000/50000]\n",
            "loss: 1.885365 [38400/50000]\n",
            "loss: 1.929447 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 55.9%, Avg loss: 1.904335 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 84\n",
            "-----------------------------\n",
            "loss: 1.878839 [    0/50000]\n",
            "loss: 1.852131 [ 6400/50000]\n",
            "loss: 1.792373 [12800/50000]\n",
            "loss: 1.943560 [19200/50000]\n",
            "loss: 1.837968 [25600/50000]\n",
            "loss: 1.888330 [32000/50000]\n",
            "loss: 1.880632 [38400/50000]\n",
            "loss: 1.920751 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 55.1%, Avg loss: 1.911768 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 85\n",
            "-----------------------------\n",
            "loss: 1.878919 [    0/50000]\n",
            "loss: 1.842592 [ 6400/50000]\n",
            "loss: 1.825333 [12800/50000]\n",
            "loss: 1.931961 [19200/50000]\n",
            "loss: 1.836367 [25600/50000]\n",
            "loss: 1.888000 [32000/50000]\n",
            "loss: 1.872454 [38400/50000]\n",
            "loss: 1.914370 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.6%, Avg loss: 1.895718 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 86\n",
            "-----------------------------\n",
            "loss: 1.867898 [    0/50000]\n",
            "loss: 1.854117 [ 6400/50000]\n",
            "loss: 1.806825 [12800/50000]\n",
            "loss: 1.934015 [19200/50000]\n",
            "loss: 1.841716 [25600/50000]\n",
            "loss: 1.892737 [32000/50000]\n",
            "loss: 1.868048 [38400/50000]\n",
            "loss: 1.913181 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.2%, Avg loss: 1.888493 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 87\n",
            "-----------------------------\n",
            "loss: 1.852813 [    0/50000]\n",
            "loss: 1.855001 [ 6400/50000]\n",
            "loss: 1.823310 [12800/50000]\n",
            "loss: 1.928137 [19200/50000]\n",
            "loss: 1.842451 [25600/50000]\n",
            "loss: 1.897317 [32000/50000]\n",
            "loss: 1.857375 [38400/50000]\n",
            "loss: 1.926498 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.1%, Avg loss: 1.892814 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 88\n",
            "-----------------------------\n",
            "loss: 1.849892 [    0/50000]\n",
            "loss: 1.848886 [ 6400/50000]\n",
            "loss: 1.791509 [12800/50000]\n",
            "loss: 1.921033 [19200/50000]\n",
            "loss: 1.857531 [25600/50000]\n",
            "loss: 1.893693 [32000/50000]\n",
            "loss: 1.852226 [38400/50000]\n",
            "loss: 1.921695 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.0%, Avg loss: 1.900318 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 89\n",
            "-----------------------------\n",
            "loss: 1.848516 [    0/50000]\n",
            "loss: 1.835070 [ 6400/50000]\n",
            "loss: 1.810225 [12800/50000]\n",
            "loss: 1.913462 [19200/50000]\n",
            "loss: 1.844062 [25600/50000]\n",
            "loss: 1.884714 [32000/50000]\n",
            "loss: 1.827299 [38400/50000]\n",
            "loss: 1.927259 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 1.883927 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 90\n",
            "-----------------------------\n",
            "loss: 1.822893 [    0/50000]\n",
            "loss: 1.835997 [ 6400/50000]\n",
            "loss: 1.811989 [12800/50000]\n",
            "loss: 1.892848 [19200/50000]\n",
            "loss: 1.864988 [25600/50000]\n",
            "loss: 1.878059 [32000/50000]\n",
            "loss: 1.823924 [38400/50000]\n",
            "loss: 1.928981 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.880584 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 91\n",
            "-----------------------------\n",
            "loss: 1.819052 [    0/50000]\n",
            "loss: 1.832597 [ 6400/50000]\n",
            "loss: 1.811355 [12800/50000]\n",
            "loss: 1.905290 [19200/50000]\n",
            "loss: 1.847551 [25600/50000]\n",
            "loss: 1.872923 [32000/50000]\n",
            "loss: 1.821204 [38400/50000]\n",
            "loss: 1.935114 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.879781 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 92\n",
            "-----------------------------\n",
            "loss: 1.819756 [    0/50000]\n",
            "loss: 1.834220 [ 6400/50000]\n",
            "loss: 1.792659 [12800/50000]\n",
            "loss: 1.887504 [19200/50000]\n",
            "loss: 1.850242 [25600/50000]\n",
            "loss: 1.881973 [32000/50000]\n",
            "loss: 1.821069 [38400/50000]\n",
            "loss: 1.932755 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 1.878866 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 93\n",
            "-----------------------------\n",
            "loss: 1.822752 [    0/50000]\n",
            "loss: 1.820369 [ 6400/50000]\n",
            "loss: 1.802895 [12800/50000]\n",
            "loss: 1.887474 [19200/50000]\n",
            "loss: 1.867422 [25600/50000]\n",
            "loss: 1.873128 [32000/50000]\n",
            "loss: 1.837022 [38400/50000]\n",
            "loss: 1.924346 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.5%, Avg loss: 1.874831 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 94\n",
            "-----------------------------\n",
            "loss: 1.818351 [    0/50000]\n",
            "loss: 1.817312 [ 6400/50000]\n",
            "loss: 1.813934 [12800/50000]\n",
            "loss: 1.875450 [19200/50000]\n",
            "loss: 1.865816 [25600/50000]\n",
            "loss: 1.869846 [32000/50000]\n",
            "loss: 1.830773 [38400/50000]\n",
            "loss: 1.944300 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.6%, Avg loss: 1.872161 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 95\n",
            "-----------------------------\n",
            "loss: 1.807276 [    0/50000]\n",
            "loss: 1.815981 [ 6400/50000]\n",
            "loss: 1.809380 [12800/50000]\n",
            "loss: 1.877543 [19200/50000]\n",
            "loss: 1.868831 [25600/50000]\n",
            "loss: 1.874181 [32000/50000]\n",
            "loss: 1.817148 [38400/50000]\n",
            "loss: 1.915772 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.3%, Avg loss: 1.874081 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 96\n",
            "-----------------------------\n",
            "loss: 1.800161 [    0/50000]\n",
            "loss: 1.808628 [ 6400/50000]\n",
            "loss: 1.813181 [12800/50000]\n",
            "loss: 1.876208 [19200/50000]\n",
            "loss: 1.869684 [25600/50000]\n",
            "loss: 1.885051 [32000/50000]\n",
            "loss: 1.810491 [38400/50000]\n",
            "loss: 1.905943 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.5%, Avg loss: 1.873737 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 97\n",
            "-----------------------------\n",
            "loss: 1.802160 [    0/50000]\n",
            "loss: 1.799893 [ 6400/50000]\n",
            "loss: 1.771208 [12800/50000]\n",
            "loss: 1.879378 [19200/50000]\n",
            "loss: 1.861250 [25600/50000]\n",
            "loss: 1.871707 [32000/50000]\n",
            "loss: 1.823803 [38400/50000]\n",
            "loss: 1.908322 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 1.877186 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 98\n",
            "-----------------------------\n",
            "loss: 1.800466 [    0/50000]\n",
            "loss: 1.805144 [ 6400/50000]\n",
            "loss: 1.797626 [12800/50000]\n",
            "loss: 1.870246 [19200/50000]\n",
            "loss: 1.857694 [25600/50000]\n",
            "loss: 1.872204 [32000/50000]\n",
            "loss: 1.816533 [38400/50000]\n",
            "loss: 1.916872 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 59.4%, Avg loss: 1.864717 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 99\n",
            "-----------------------------\n",
            "loss: 1.789733 [    0/50000]\n",
            "loss: 1.796000 [ 6400/50000]\n",
            "loss: 1.755597 [12800/50000]\n",
            "loss: 1.865609 [19200/50000]\n",
            "loss: 1.861859 [25600/50000]\n",
            "loss: 1.880780 [32000/50000]\n",
            "loss: 1.811974 [38400/50000]\n",
            "loss: 1.924024 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 59.7%, Avg loss: 1.861486 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 100\n",
            "-----------------------------\n",
            "loss: 1.784886 [    0/50000]\n",
            "loss: 1.798137 [ 6400/50000]\n",
            "loss: 1.758707 [12800/50000]\n",
            "loss: 1.855640 [19200/50000]\n",
            "loss: 1.860137 [25600/50000]\n",
            "loss: 1.882195 [32000/50000]\n",
            "loss: 1.799466 [38400/50000]\n",
            "loss: 1.909767 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 59.2%, Avg loss: 1.864915 \n",
            "\n",
            "Patience count: 1\n",
            "Saving best model: test_epoch-099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imBDYEwbYp2V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}