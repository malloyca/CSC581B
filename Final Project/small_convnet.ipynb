{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small_convnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPD4djDbWZLuo2nr5P1FgPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9813a1d4af554b498ba05c2a5c2efef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0921af42230e45d5ab62c59b3c5babdd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_644bbf7464ee473d91707ecef71a1d0f",
              "IPY_MODEL_68ad19e27e3645e486c9a9a3066f3de4",
              "IPY_MODEL_114b6cd072a94a55bfc28ef5d010ecaa"
            ]
          }
        },
        "0921af42230e45d5ab62c59b3c5babdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "644bbf7464ee473d91707ecef71a1d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_289f3bbcba294ee19f32893093d51cee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ba525a082fa47099049f2206c74005a"
          }
        },
        "68ad19e27e3645e486c9a9a3066f3de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9c85c5f6de54f49b524980b03399357",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25485fbe0dab4ac68b46a7372b410fd9"
          }
        },
        "114b6cd072a94a55bfc28ef5d010ecaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c7713573c41c4fe19ad7a7504b97d9c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 48941515.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2f98f45a3314e018864278e9855f518"
          }
        },
        "289f3bbcba294ee19f32893093d51cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ba525a082fa47099049f2206c74005a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9c85c5f6de54f49b524980b03399357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25485fbe0dab4ac68b46a7372b410fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7713573c41c4fe19ad7a7504b97d9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2f98f45a3314e018864278e9855f518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malloyca/CSC581B/blob/main/Final%20Project/small_convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI3XLmYiD-UJ"
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "9813a1d4af554b498ba05c2a5c2efef7",
            "0921af42230e45d5ab62c59b3c5babdd",
            "644bbf7464ee473d91707ecef71a1d0f",
            "68ad19e27e3645e486c9a9a3066f3de4",
            "114b6cd072a94a55bfc28ef5d010ecaa",
            "289f3bbcba294ee19f32893093d51cee",
            "4ba525a082fa47099049f2206c74005a",
            "a9c85c5f6de54f49b524980b03399357",
            "25485fbe0dab4ac68b46a7372b410fd9",
            "c7713573c41c4fe19ad7a7504b97d9c6",
            "a2f98f45a3314e018864278e9855f518"
          ]
        },
        "id": "BuXW8boJEcrA",
        "outputId": "e2d87c4f-b3fe-4326-b0ce-f95d18d86cb1"
      },
      "source": [
        "# Load the training data (CIFAR10 to start)\n",
        "training_data = datasets.CIFAR10(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = datasets.CIFAR10(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9813a1d4af554b498ba05c2a5c2efef7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ2dy9pmEwz6"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE6plIy9E2D_",
        "outputId": "48e94cbc-3d56-4328-af16-443bc492fa25"
      },
      "source": [
        "# Check the data dimensions\n",
        "for X, y in test_dataloader:\n",
        "  print(\"Shape of X batch [Batch size, Channels, Height, Width]: \", X.shape)\n",
        "  print(\"Shape of y batch: \", y.shape, y.dtype)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X batch [Batch size, Channels, Height, Width]:  torch.Size([64, 3, 32, 32])\n",
            "Shape of y batch:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGQGFOcoFAeO"
      },
      "source": [
        "# Building basic convolutional neural nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuGLhBqQE_xI",
        "outputId": "ecb1e0a0-4495-44cf-8ae7-c633bb59557f"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H5TNXTJE4Nd"
      },
      "source": [
        "# Define the model\n",
        "class basicConvNet(nn.Module):\n",
        "  def __init__(self, name):\n",
        "    super(basicConvNet, self).__init__()\n",
        "    self.name = name\n",
        "    self.basic_conv_net = nn.Sequential(\n",
        "        # 1st layer\n",
        "        nn.Conv2d(3, 256, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        # 2nd layer\n",
        "        nn.Conv2d(256, 128, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        # 3rd layer\n",
        "        nn.Conv2d(128, 64, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        # 4th layer\n",
        "        nn.Conv2d(64, 32, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "        # 5th layer\n",
        "        nn.Conv2d(32, 32, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "        # 6th layer\n",
        "        nn.Conv2d(32, 16, (3,3), padding='same'),\n",
        "        nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "        # 7th layer\n",
        "        #nn.Conv2d(16, 16, (3,3), padding='same'),\n",
        "        #nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "        # 8th layer\n",
        "        #nn.Conv2d(16, 16, (3,3), padding='same'),\n",
        "        #nn.ReLU(),\n",
        "        #nn.MaxPool2d((2,2)),\n",
        "\n",
        "        # Output layer # todo - move the flatten -> linear layer out of sequential\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(16 * 4 * 4, 10),\n",
        "    )\n",
        "\n",
        "  # Forward propagation\n",
        "  def forward(self, x):\n",
        "    x = self.basic_conv_net(x)\n",
        "    return x\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLQYaHdZTnJK"
      },
      "source": [
        "model = basicConvNet('test').to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deD1sei_WLmX"
      },
      "source": [
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=5e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGk95EKWan5"
      },
      "source": [
        "# Training loop\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I_S627HXLWz"
      },
      "source": [
        "# Test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "  return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfMapknHYDYO"
      },
      "source": [
        "n_epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uypo30igYE2G"
      },
      "source": [
        "def training_loop(n_epochs, model, train_data, test_data, loss_function,\n",
        "                  optimizer, early_stopping=False, patience=10):\n",
        "  current_epoch = 0\n",
        "  best_epoch = 0\n",
        "  best_loss = float('inf')\n",
        "  patience_counter = 0\n",
        "\n",
        "  for e in range(n_epochs):\n",
        "    print(f\"\\nEpoch {e+1}\\n----------------------------\")\n",
        "    train(train_data, model, loss_function, optimizer)\n",
        "    test_loss = test(test_data, model, loss_function)\n",
        "\n",
        "    # Iterate epoch counter\n",
        "    current_epoch += 1\n",
        "\n",
        "    # If early_stopping check test_loss\n",
        "    if early_stopping:\n",
        "      # case: test loss beats the current best loss\n",
        "      if test_loss < best_loss:\n",
        "        # store loss\n",
        "        best_loss = test_loss\n",
        "\n",
        "        # reset patience counter\n",
        "        patience_counter = 0\n",
        "\n",
        "        # store model and epoch number\n",
        "        print(\"Storing new best model.\")\n",
        "        best_model_state_dict = copy.deepcopy(model.state_dict)\n",
        "        best_epoch = current_epoch\n",
        "\n",
        "      # Case: patience limit not yet reached => iterate patience counter\n",
        "      elif patience_counter < patience - 1:\n",
        "        patience_counter += 1\n",
        "        print(f\"Patience count: {patience_counter}\")\n",
        "\n",
        "      # Case: patience limit reached\n",
        "      else:\n",
        "        print(\"Finished due to early stopping.\")\n",
        "        print(f\"Saving best model: {model.name}_epoch-{best_epoch:03d}\")\n",
        "        torch.save(best_model_state_dict, f'{model.name}_epoch-{best_epoch:03d}')\n",
        "        break\n",
        "\n",
        "  # If we get here, we did not stop early - save best model\n",
        "  if early_stopping:\n",
        "    print(f\"Saving best model: {model.name}_epoch-{best_epoch:03d}\")\n",
        "    torch.save(best_model_state_dict, f'{model.name}_epoch-{best_epoch:03d}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6WkrJ5QYgri",
        "outputId": "b0595db0-801b-4e97-8fb2-ca7c6b995771"
      },
      "source": [
        "training_loop(n_epochs, model, train_dataloader, test_dataloader, loss_fn,\n",
        "              optimizer, early_stopping=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "----------------------------\n",
            "loss: 2.302304 [    0/50000]\n",
            "loss: 2.302722 [ 6400/50000]\n",
            "loss: 2.302268 [12800/50000]\n",
            "loss: 2.302091 [19200/50000]\n",
            "loss: 2.303095 [25600/50000]\n",
            "loss: 2.302198 [32000/50000]\n",
            "loss: 2.302834 [38400/50000]\n",
            "loss: 2.302462 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302579 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 2\n",
            "----------------------------\n",
            "loss: 2.302303 [    0/50000]\n",
            "loss: 2.302712 [ 6400/50000]\n",
            "loss: 2.302271 [12800/50000]\n",
            "loss: 2.302099 [19200/50000]\n",
            "loss: 2.303060 [25600/50000]\n",
            "loss: 2.302203 [32000/50000]\n",
            "loss: 2.302818 [38400/50000]\n",
            "loss: 2.302465 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302569 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 3\n",
            "----------------------------\n",
            "loss: 2.302308 [    0/50000]\n",
            "loss: 2.302705 [ 6400/50000]\n",
            "loss: 2.302273 [12800/50000]\n",
            "loss: 2.302111 [19200/50000]\n",
            "loss: 2.303025 [25600/50000]\n",
            "loss: 2.302208 [32000/50000]\n",
            "loss: 2.302803 [38400/50000]\n",
            "loss: 2.302465 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302560 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 4\n",
            "----------------------------\n",
            "loss: 2.302310 [    0/50000]\n",
            "loss: 2.302695 [ 6400/50000]\n",
            "loss: 2.302275 [12800/50000]\n",
            "loss: 2.302123 [19200/50000]\n",
            "loss: 2.302991 [25600/50000]\n",
            "loss: 2.302210 [32000/50000]\n",
            "loss: 2.302788 [38400/50000]\n",
            "loss: 2.302462 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.0%, Avg loss: 2.302549 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 5\n",
            "----------------------------\n",
            "loss: 2.302305 [    0/50000]\n",
            "loss: 2.302680 [ 6400/50000]\n",
            "loss: 2.302271 [12800/50000]\n",
            "loss: 2.302132 [19200/50000]\n",
            "loss: 2.302953 [25600/50000]\n",
            "loss: 2.302210 [32000/50000]\n",
            "loss: 2.302767 [38400/50000]\n",
            "loss: 2.302455 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 10.6%, Avg loss: 2.302534 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 6\n",
            "----------------------------\n",
            "loss: 2.302301 [    0/50000]\n",
            "loss: 2.302663 [ 6400/50000]\n",
            "loss: 2.302264 [12800/50000]\n",
            "loss: 2.302136 [19200/50000]\n",
            "loss: 2.302914 [25600/50000]\n",
            "loss: 2.302201 [32000/50000]\n",
            "loss: 2.302735 [38400/50000]\n",
            "loss: 2.302444 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 13.8%, Avg loss: 2.302513 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 7\n",
            "----------------------------\n",
            "loss: 2.302292 [    0/50000]\n",
            "loss: 2.302638 [ 6400/50000]\n",
            "loss: 2.302247 [12800/50000]\n",
            "loss: 2.302129 [19200/50000]\n",
            "loss: 2.302861 [25600/50000]\n",
            "loss: 2.302178 [32000/50000]\n",
            "loss: 2.302689 [38400/50000]\n",
            "loss: 2.302415 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 14.9%, Avg loss: 2.302478 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 8\n",
            "----------------------------\n",
            "loss: 2.302269 [    0/50000]\n",
            "loss: 2.302593 [ 6400/50000]\n",
            "loss: 2.302209 [12800/50000]\n",
            "loss: 2.302105 [19200/50000]\n",
            "loss: 2.302797 [25600/50000]\n",
            "loss: 2.302132 [32000/50000]\n",
            "loss: 2.302628 [38400/50000]\n",
            "loss: 2.302358 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 15.6%, Avg loss: 2.302421 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 9\n",
            "----------------------------\n",
            "loss: 2.302236 [    0/50000]\n",
            "loss: 2.302526 [ 6400/50000]\n",
            "loss: 2.302136 [12800/50000]\n",
            "loss: 2.302069 [19200/50000]\n",
            "loss: 2.302693 [25600/50000]\n",
            "loss: 2.302037 [32000/50000]\n",
            "loss: 2.302531 [38400/50000]\n",
            "loss: 2.302241 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 16.1%, Avg loss: 2.302302 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 10\n",
            "----------------------------\n",
            "loss: 2.302156 [    0/50000]\n",
            "loss: 2.302387 [ 6400/50000]\n",
            "loss: 2.301952 [12800/50000]\n",
            "loss: 2.301979 [19200/50000]\n",
            "loss: 2.302456 [25600/50000]\n",
            "loss: 2.301769 [32000/50000]\n",
            "loss: 2.302281 [38400/50000]\n",
            "loss: 2.301881 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 16.3%, Avg loss: 2.301929 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 11\n",
            "----------------------------\n",
            "loss: 2.301921 [    0/50000]\n",
            "loss: 2.301967 [ 6400/50000]\n",
            "loss: 2.301247 [12800/50000]\n",
            "loss: 2.301620 [19200/50000]\n",
            "loss: 2.301570 [25600/50000]\n",
            "loss: 2.300412 [32000/50000]\n",
            "loss: 2.300628 [38400/50000]\n",
            "loss: 2.299552 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 16.6%, Avg loss: 2.298326 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 12\n",
            "----------------------------\n",
            "loss: 2.299777 [    0/50000]\n",
            "loss: 2.296307 [ 6400/50000]\n",
            "loss: 2.259887 [12800/50000]\n",
            "loss: 2.271748 [19200/50000]\n",
            "loss: 2.231113 [25600/50000]\n",
            "loss: 2.272516 [32000/50000]\n",
            "loss: 2.199072 [38400/50000]\n",
            "loss: 2.211525 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 23.5%, Avg loss: 2.206262 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 13\n",
            "----------------------------\n",
            "loss: 2.265645 [    0/50000]\n",
            "loss: 2.209252 [ 6400/50000]\n",
            "loss: 2.164852 [12800/50000]\n",
            "loss: 2.309207 [19200/50000]\n",
            "loss: 2.117680 [25600/50000]\n",
            "loss: 2.219971 [32000/50000]\n",
            "loss: 2.171757 [38400/50000]\n",
            "loss: 2.176867 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 26.5%, Avg loss: 2.183602 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 14\n",
            "----------------------------\n",
            "loss: 2.207655 [    0/50000]\n",
            "loss: 2.190259 [ 6400/50000]\n",
            "loss: 2.135341 [12800/50000]\n",
            "loss: 2.321178 [19200/50000]\n",
            "loss: 2.122319 [25600/50000]\n",
            "loss: 2.209620 [32000/50000]\n",
            "loss: 2.165605 [38400/50000]\n",
            "loss: 2.174356 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 2.165680 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 15\n",
            "----------------------------\n",
            "loss: 2.201224 [    0/50000]\n",
            "loss: 2.156039 [ 6400/50000]\n",
            "loss: 2.136737 [12800/50000]\n",
            "loss: 2.313401 [19200/50000]\n",
            "loss: 2.131610 [25600/50000]\n",
            "loss: 2.140086 [32000/50000]\n",
            "loss: 2.141620 [38400/50000]\n",
            "loss: 2.072067 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 32.4%, Avg loss: 2.124845 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 16\n",
            "----------------------------\n",
            "loss: 2.151973 [    0/50000]\n",
            "loss: 2.097318 [ 6400/50000]\n",
            "loss: 2.063450 [12800/50000]\n",
            "loss: 2.233448 [19200/50000]\n",
            "loss: 2.084840 [25600/50000]\n",
            "loss: 2.115974 [32000/50000]\n",
            "loss: 2.136382 [38400/50000]\n",
            "loss: 2.037375 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.0%, Avg loss: 2.110359 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 17\n",
            "----------------------------\n",
            "loss: 2.155805 [    0/50000]\n",
            "loss: 2.109066 [ 6400/50000]\n",
            "loss: 1.990554 [12800/50000]\n",
            "loss: 2.156028 [19200/50000]\n",
            "loss: 2.054772 [25600/50000]\n",
            "loss: 2.088461 [32000/50000]\n",
            "loss: 2.141869 [38400/50000]\n",
            "loss: 2.034230 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.9%, Avg loss: 2.152937 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 18\n",
            "----------------------------\n",
            "loss: 2.154936 [    0/50000]\n",
            "loss: 2.120529 [ 6400/50000]\n",
            "loss: 2.002012 [12800/50000]\n",
            "loss: 2.139400 [19200/50000]\n",
            "loss: 1.993233 [25600/50000]\n",
            "loss: 2.116492 [32000/50000]\n",
            "loss: 2.113229 [38400/50000]\n",
            "loss: 2.028404 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 33.1%, Avg loss: 2.121254 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 19\n",
            "----------------------------\n",
            "loss: 2.184215 [    0/50000]\n",
            "loss: 2.090079 [ 6400/50000]\n",
            "loss: 1.922747 [12800/50000]\n",
            "loss: 2.138063 [19200/50000]\n",
            "loss: 1.978263 [25600/50000]\n",
            "loss: 2.094740 [32000/50000]\n",
            "loss: 2.144230 [38400/50000]\n",
            "loss: 2.036138 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.2%, Avg loss: 2.083257 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 20\n",
            "----------------------------\n",
            "loss: 2.087483 [    0/50000]\n",
            "loss: 2.119582 [ 6400/50000]\n",
            "loss: 1.981186 [12800/50000]\n",
            "loss: 2.126108 [19200/50000]\n",
            "loss: 1.948916 [25600/50000]\n",
            "loss: 2.041833 [32000/50000]\n",
            "loss: 2.121621 [38400/50000]\n",
            "loss: 2.039325 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 2.102102 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 21\n",
            "----------------------------\n",
            "loss: 2.048108 [    0/50000]\n",
            "loss: 2.030846 [ 6400/50000]\n",
            "loss: 1.952175 [12800/50000]\n",
            "loss: 2.101845 [19200/50000]\n",
            "loss: 1.959401 [25600/50000]\n",
            "loss: 2.024679 [32000/50000]\n",
            "loss: 2.124937 [38400/50000]\n",
            "loss: 2.041548 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 2.043599 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 22\n",
            "----------------------------\n",
            "loss: 2.031772 [    0/50000]\n",
            "loss: 2.049281 [ 6400/50000]\n",
            "loss: 1.947072 [12800/50000]\n",
            "loss: 2.067894 [19200/50000]\n",
            "loss: 1.921749 [25600/50000]\n",
            "loss: 1.977719 [32000/50000]\n",
            "loss: 2.097437 [38400/50000]\n",
            "loss: 2.025774 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 48.0%, Avg loss: 1.978535 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 23\n",
            "----------------------------\n",
            "loss: 2.008035 [    0/50000]\n",
            "loss: 2.001346 [ 6400/50000]\n",
            "loss: 1.856234 [12800/50000]\n",
            "loss: 2.084464 [19200/50000]\n",
            "loss: 1.979218 [25600/50000]\n",
            "loss: 1.969425 [32000/50000]\n",
            "loss: 2.088003 [38400/50000]\n",
            "loss: 2.004874 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 48.9%, Avg loss: 1.969251 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 24\n",
            "----------------------------\n",
            "loss: 2.018142 [    0/50000]\n",
            "loss: 1.969716 [ 6400/50000]\n",
            "loss: 1.843763 [12800/50000]\n",
            "loss: 2.063286 [19200/50000]\n",
            "loss: 1.934491 [25600/50000]\n",
            "loss: 1.972589 [32000/50000]\n",
            "loss: 2.030993 [38400/50000]\n",
            "loss: 1.961843 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.4%, Avg loss: 1.953315 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 25\n",
            "----------------------------\n",
            "loss: 1.985090 [    0/50000]\n",
            "loss: 2.012379 [ 6400/50000]\n",
            "loss: 1.856103 [12800/50000]\n",
            "loss: 2.069077 [19200/50000]\n",
            "loss: 1.970309 [25600/50000]\n",
            "loss: 1.905495 [32000/50000]\n",
            "loss: 1.991577 [38400/50000]\n",
            "loss: 1.980196 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 1.946373 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 26\n",
            "----------------------------\n",
            "loss: 2.016652 [    0/50000]\n",
            "loss: 1.996172 [ 6400/50000]\n",
            "loss: 1.799968 [12800/50000]\n",
            "loss: 2.092177 [19200/50000]\n",
            "loss: 1.871540 [25600/50000]\n",
            "loss: 1.920302 [32000/50000]\n",
            "loss: 2.006674 [38400/50000]\n",
            "loss: 1.942405 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 49.5%, Avg loss: 1.964140 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 27\n",
            "----------------------------\n",
            "loss: 1.955652 [    0/50000]\n",
            "loss: 1.949000 [ 6400/50000]\n",
            "loss: 1.871535 [12800/50000]\n",
            "loss: 2.061466 [19200/50000]\n",
            "loss: 1.948947 [25600/50000]\n",
            "loss: 1.910168 [32000/50000]\n",
            "loss: 1.990220 [38400/50000]\n",
            "loss: 1.934095 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 52.2%, Avg loss: 1.934918 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 28\n",
            "----------------------------\n",
            "loss: 1.953739 [    0/50000]\n",
            "loss: 2.008158 [ 6400/50000]\n",
            "loss: 1.786403 [12800/50000]\n",
            "loss: 2.008335 [19200/50000]\n",
            "loss: 1.926288 [25600/50000]\n",
            "loss: 1.875566 [32000/50000]\n",
            "loss: 1.921549 [38400/50000]\n",
            "loss: 1.938734 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 55.7%, Avg loss: 1.900781 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 29\n",
            "----------------------------\n",
            "loss: 1.923977 [    0/50000]\n",
            "loss: 1.929730 [ 6400/50000]\n",
            "loss: 1.823093 [12800/50000]\n",
            "loss: 1.986133 [19200/50000]\n",
            "loss: 1.854000 [25600/50000]\n",
            "loss: 1.878931 [32000/50000]\n",
            "loss: 1.956231 [38400/50000]\n",
            "loss: 1.917305 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.5%, Avg loss: 1.892935 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 30\n",
            "----------------------------\n",
            "loss: 1.936411 [    0/50000]\n",
            "loss: 1.959398 [ 6400/50000]\n",
            "loss: 1.817920 [12800/50000]\n",
            "loss: 1.945218 [19200/50000]\n",
            "loss: 1.811535 [25600/50000]\n",
            "loss: 1.904903 [32000/50000]\n",
            "loss: 1.954921 [38400/50000]\n",
            "loss: 1.929110 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.8%, Avg loss: 1.949465 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 31\n",
            "----------------------------\n",
            "loss: 1.966499 [    0/50000]\n",
            "loss: 1.904129 [ 6400/50000]\n",
            "loss: 1.797608 [12800/50000]\n",
            "loss: 1.916197 [19200/50000]\n",
            "loss: 1.837951 [25600/50000]\n",
            "loss: 1.917298 [32000/50000]\n",
            "loss: 1.886909 [38400/50000]\n",
            "loss: 1.912753 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.9%, Avg loss: 1.888582 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 32\n",
            "----------------------------\n",
            "loss: 1.958152 [    0/50000]\n",
            "loss: 1.891228 [ 6400/50000]\n",
            "loss: 1.800313 [12800/50000]\n",
            "loss: 1.885993 [19200/50000]\n",
            "loss: 1.849737 [25600/50000]\n",
            "loss: 1.882153 [32000/50000]\n",
            "loss: 1.843721 [38400/50000]\n",
            "loss: 1.905104 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 55.3%, Avg loss: 1.902531 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 33\n",
            "----------------------------\n",
            "loss: 1.948102 [    0/50000]\n",
            "loss: 1.848056 [ 6400/50000]\n",
            "loss: 1.774744 [12800/50000]\n",
            "loss: 1.860715 [19200/50000]\n",
            "loss: 1.805154 [25600/50000]\n",
            "loss: 1.925178 [32000/50000]\n",
            "loss: 1.832969 [38400/50000]\n",
            "loss: 1.879517 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 50.7%, Avg loss: 1.950993 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 34\n",
            "----------------------------\n",
            "loss: 2.054068 [    0/50000]\n",
            "loss: 1.860997 [ 6400/50000]\n",
            "loss: 1.729819 [12800/50000]\n",
            "loss: 1.874041 [19200/50000]\n",
            "loss: 1.760232 [25600/50000]\n",
            "loss: 1.887824 [32000/50000]\n",
            "loss: 1.852852 [38400/50000]\n",
            "loss: 1.861244 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 59.4%, Avg loss: 1.865460 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 35\n",
            "----------------------------\n",
            "loss: 1.938294 [    0/50000]\n",
            "loss: 1.851776 [ 6400/50000]\n",
            "loss: 1.728841 [12800/50000]\n",
            "loss: 1.858829 [19200/50000]\n",
            "loss: 1.811089 [25600/50000]\n",
            "loss: 1.875370 [32000/50000]\n",
            "loss: 1.820801 [38400/50000]\n",
            "loss: 1.862166 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 56.4%, Avg loss: 1.894783 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 36\n",
            "----------------------------\n",
            "loss: 1.987019 [    0/50000]\n",
            "loss: 1.817581 [ 6400/50000]\n",
            "loss: 1.753489 [12800/50000]\n",
            "loss: 1.861042 [19200/50000]\n",
            "loss: 1.783395 [25600/50000]\n",
            "loss: 1.884134 [32000/50000]\n",
            "loss: 1.830071 [38400/50000]\n",
            "loss: 1.842269 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 61.6%, Avg loss: 1.843422 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 37\n",
            "----------------------------\n",
            "loss: 1.863354 [    0/50000]\n",
            "loss: 1.829346 [ 6400/50000]\n",
            "loss: 1.767003 [12800/50000]\n",
            "loss: 1.848300 [19200/50000]\n",
            "loss: 1.753839 [25600/50000]\n",
            "loss: 1.899033 [32000/50000]\n",
            "loss: 1.810718 [38400/50000]\n",
            "loss: 1.827993 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 57.5%, Avg loss: 1.885667 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 38\n",
            "----------------------------\n",
            "loss: 1.937356 [    0/50000]\n",
            "loss: 1.854432 [ 6400/50000]\n",
            "loss: 1.731294 [12800/50000]\n",
            "loss: 1.829196 [19200/50000]\n",
            "loss: 1.740512 [25600/50000]\n",
            "loss: 1.819364 [32000/50000]\n",
            "loss: 1.802518 [38400/50000]\n",
            "loss: 1.773342 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 62.8%, Avg loss: 1.830587 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 39\n",
            "----------------------------\n",
            "loss: 1.875237 [    0/50000]\n",
            "loss: 1.798583 [ 6400/50000]\n",
            "loss: 1.707895 [12800/50000]\n",
            "loss: 1.825411 [19200/50000]\n",
            "loss: 1.749991 [25600/50000]\n",
            "loss: 1.850246 [32000/50000]\n",
            "loss: 1.776206 [38400/50000]\n",
            "loss: 1.804736 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 58.5%, Avg loss: 1.875884 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 40\n",
            "----------------------------\n",
            "loss: 1.919422 [    0/50000]\n",
            "loss: 1.757843 [ 6400/50000]\n",
            "loss: 1.685379 [12800/50000]\n",
            "loss: 1.832700 [19200/50000]\n",
            "loss: 1.785152 [25600/50000]\n",
            "loss: 1.910119 [32000/50000]\n",
            "loss: 1.784040 [38400/50000]\n",
            "loss: 1.796851 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 54.7%, Avg loss: 1.911287 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 41\n",
            "----------------------------\n",
            "loss: 1.960971 [    0/50000]\n",
            "loss: 1.737371 [ 6400/50000]\n",
            "loss: 1.660102 [12800/50000]\n",
            "loss: 1.854967 [19200/50000]\n",
            "loss: 1.764119 [25600/50000]\n",
            "loss: 1.800894 [32000/50000]\n",
            "loss: 1.826362 [38400/50000]\n",
            "loss: 1.803037 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 61.4%, Avg loss: 1.845552 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 42\n",
            "----------------------------\n",
            "loss: 1.882947 [    0/50000]\n",
            "loss: 1.742680 [ 6400/50000]\n",
            "loss: 1.638660 [12800/50000]\n",
            "loss: 1.838338 [19200/50000]\n",
            "loss: 1.737818 [25600/50000]\n",
            "loss: 1.824662 [32000/50000]\n",
            "loss: 1.786697 [38400/50000]\n",
            "loss: 1.799713 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.837195 \n",
            "\n",
            "Patience count: 4\n",
            "\n",
            "Epoch 43\n",
            "----------------------------\n",
            "loss: 1.862585 [    0/50000]\n",
            "loss: 1.732682 [ 6400/50000]\n",
            "loss: 1.681188 [12800/50000]\n",
            "loss: 1.834632 [19200/50000]\n",
            "loss: 1.735049 [25600/50000]\n",
            "loss: 1.823712 [32000/50000]\n",
            "loss: 1.745559 [38400/50000]\n",
            "loss: 1.781605 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 61.4%, Avg loss: 1.847081 \n",
            "\n",
            "Patience count: 5\n",
            "\n",
            "Epoch 44\n",
            "----------------------------\n",
            "loss: 1.798917 [    0/50000]\n",
            "loss: 1.807801 [ 6400/50000]\n",
            "loss: 1.689783 [12800/50000]\n",
            "loss: 1.838339 [19200/50000]\n",
            "loss: 1.685119 [25600/50000]\n",
            "loss: 1.797295 [32000/50000]\n",
            "loss: 1.786649 [38400/50000]\n",
            "loss: 1.788688 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 60.4%, Avg loss: 1.852999 \n",
            "\n",
            "Patience count: 6\n",
            "\n",
            "Epoch 45\n",
            "----------------------------\n",
            "loss: 1.890775 [    0/50000]\n",
            "loss: 1.701258 [ 6400/50000]\n",
            "loss: 1.644842 [12800/50000]\n",
            "loss: 1.853338 [19200/50000]\n",
            "loss: 1.690197 [25600/50000]\n",
            "loss: 1.833032 [32000/50000]\n",
            "loss: 1.804869 [38400/50000]\n",
            "loss: 1.809799 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 64.5%, Avg loss: 1.815176 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 46\n",
            "----------------------------\n",
            "loss: 1.773651 [    0/50000]\n",
            "loss: 1.757925 [ 6400/50000]\n",
            "loss: 1.684413 [12800/50000]\n",
            "loss: 1.842573 [19200/50000]\n",
            "loss: 1.704961 [25600/50000]\n",
            "loss: 1.807810 [32000/50000]\n",
            "loss: 1.727920 [38400/50000]\n",
            "loss: 1.796068 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 64.5%, Avg loss: 1.814962 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 47\n",
            "----------------------------\n",
            "loss: 1.785475 [    0/50000]\n",
            "loss: 1.701674 [ 6400/50000]\n",
            "loss: 1.636098 [12800/50000]\n",
            "loss: 1.892465 [19200/50000]\n",
            "loss: 1.690991 [25600/50000]\n",
            "loss: 1.801986 [32000/50000]\n",
            "loss: 1.767682 [38400/50000]\n",
            "loss: 1.775165 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 63.7%, Avg loss: 1.822107 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 48\n",
            "----------------------------\n",
            "loss: 1.837922 [    0/50000]\n",
            "loss: 1.740687 [ 6400/50000]\n",
            "loss: 1.651661 [12800/50000]\n",
            "loss: 1.834067 [19200/50000]\n",
            "loss: 1.757517 [25600/50000]\n",
            "loss: 1.808052 [32000/50000]\n",
            "loss: 1.759550 [38400/50000]\n",
            "loss: 1.754323 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 65.8%, Avg loss: 1.800324 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 49\n",
            "----------------------------\n",
            "loss: 1.787303 [    0/50000]\n",
            "loss: 1.699617 [ 6400/50000]\n",
            "loss: 1.622921 [12800/50000]\n",
            "loss: 1.828007 [19200/50000]\n",
            "loss: 1.712060 [25600/50000]\n",
            "loss: 1.767215 [32000/50000]\n",
            "loss: 1.730481 [38400/50000]\n",
            "loss: 1.773470 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 65.1%, Avg loss: 1.808277 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 50\n",
            "----------------------------\n",
            "loss: 1.760422 [    0/50000]\n",
            "loss: 1.707659 [ 6400/50000]\n",
            "loss: 1.713093 [12800/50000]\n",
            "loss: 1.746688 [19200/50000]\n",
            "loss: 1.738184 [25600/50000]\n",
            "loss: 1.833200 [32000/50000]\n",
            "loss: 1.763387 [38400/50000]\n",
            "loss: 1.733247 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 66.8%, Avg loss: 1.791053 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 51\n",
            "----------------------------\n",
            "loss: 1.749240 [    0/50000]\n",
            "loss: 1.760774 [ 6400/50000]\n",
            "loss: 1.673924 [12800/50000]\n",
            "loss: 1.777120 [19200/50000]\n",
            "loss: 1.759749 [25600/50000]\n",
            "loss: 1.818416 [32000/50000]\n",
            "loss: 1.702555 [38400/50000]\n",
            "loss: 1.752856 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 54.0%, Avg loss: 1.915539 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 52\n",
            "----------------------------\n",
            "loss: 1.933854 [    0/50000]\n",
            "loss: 1.713279 [ 6400/50000]\n",
            "loss: 1.647850 [12800/50000]\n",
            "loss: 1.767950 [19200/50000]\n",
            "loss: 1.704883 [25600/50000]\n",
            "loss: 1.760981 [32000/50000]\n",
            "loss: 1.664852 [38400/50000]\n",
            "loss: 1.730933 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 66.9%, Avg loss: 1.789809 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 53\n",
            "----------------------------\n",
            "loss: 1.700522 [    0/50000]\n",
            "loss: 1.636639 [ 6400/50000]\n",
            "loss: 1.594817 [12800/50000]\n",
            "loss: 1.800048 [19200/50000]\n",
            "loss: 1.696339 [25600/50000]\n",
            "loss: 1.816925 [32000/50000]\n",
            "loss: 1.703271 [38400/50000]\n",
            "loss: 1.735298 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 66.3%, Avg loss: 1.797392 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 54\n",
            "----------------------------\n",
            "loss: 1.713166 [    0/50000]\n",
            "loss: 1.687293 [ 6400/50000]\n",
            "loss: 1.632346 [12800/50000]\n",
            "loss: 1.776421 [19200/50000]\n",
            "loss: 1.668490 [25600/50000]\n",
            "loss: 1.805277 [32000/50000]\n",
            "loss: 1.697680 [38400/50000]\n",
            "loss: 1.738151 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 65.5%, Avg loss: 1.805195 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 55\n",
            "----------------------------\n",
            "loss: 1.744833 [    0/50000]\n",
            "loss: 1.729494 [ 6400/50000]\n",
            "loss: 1.629699 [12800/50000]\n",
            "loss: 1.736360 [19200/50000]\n",
            "loss: 1.664243 [25600/50000]\n",
            "loss: 1.783554 [32000/50000]\n",
            "loss: 1.617875 [38400/50000]\n",
            "loss: 1.702448 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 66.9%, Avg loss: 1.790348 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 56\n",
            "----------------------------\n",
            "loss: 1.668771 [    0/50000]\n",
            "loss: 1.648396 [ 6400/50000]\n",
            "loss: 1.669420 [12800/50000]\n",
            "loss: 1.748693 [19200/50000]\n",
            "loss: 1.684479 [25600/50000]\n",
            "loss: 1.747422 [32000/50000]\n",
            "loss: 1.676446 [38400/50000]\n",
            "loss: 1.794127 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 65.3%, Avg loss: 1.804854 \n",
            "\n",
            "Patience count: 4\n",
            "\n",
            "Epoch 57\n",
            "----------------------------\n",
            "loss: 1.732948 [    0/50000]\n",
            "loss: 1.706563 [ 6400/50000]\n",
            "loss: 1.666784 [12800/50000]\n",
            "loss: 1.724897 [19200/50000]\n",
            "loss: 1.680377 [25600/50000]\n",
            "loss: 1.772243 [32000/50000]\n",
            "loss: 1.710498 [38400/50000]\n",
            "loss: 1.763768 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 61.7%, Avg loss: 1.841278 \n",
            "\n",
            "Patience count: 5\n",
            "\n",
            "Epoch 58\n",
            "----------------------------\n",
            "loss: 1.800591 [    0/50000]\n",
            "loss: 1.635610 [ 6400/50000]\n",
            "loss: 1.671647 [12800/50000]\n",
            "loss: 1.722092 [19200/50000]\n",
            "loss: 1.659940 [25600/50000]\n",
            "loss: 1.774064 [32000/50000]\n",
            "loss: 1.703667 [38400/50000]\n",
            "loss: 1.766120 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 65.5%, Avg loss: 1.803461 \n",
            "\n",
            "Patience count: 6\n",
            "\n",
            "Epoch 59\n",
            "----------------------------\n",
            "loss: 1.733445 [    0/50000]\n",
            "loss: 1.649733 [ 6400/50000]\n",
            "loss: 1.651459 [12800/50000]\n",
            "loss: 1.668983 [19200/50000]\n",
            "loss: 1.691279 [25600/50000]\n",
            "loss: 1.807817 [32000/50000]\n",
            "loss: 1.660296 [38400/50000]\n",
            "loss: 1.709358 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 67.6%, Avg loss: 1.783187 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 60\n",
            "----------------------------\n",
            "loss: 1.717369 [    0/50000]\n",
            "loss: 1.643378 [ 6400/50000]\n",
            "loss: 1.638621 [12800/50000]\n",
            "loss: 1.664213 [19200/50000]\n",
            "loss: 1.680954 [25600/50000]\n",
            "loss: 1.777825 [32000/50000]\n",
            "loss: 1.658268 [38400/50000]\n",
            "loss: 1.723511 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 67.9%, Avg loss: 1.779787 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 61\n",
            "----------------------------\n",
            "loss: 1.644569 [    0/50000]\n",
            "loss: 1.671342 [ 6400/50000]\n",
            "loss: 1.607594 [12800/50000]\n",
            "loss: 1.701981 [19200/50000]\n",
            "loss: 1.719903 [25600/50000]\n",
            "loss: 1.802841 [32000/50000]\n",
            "loss: 1.620575 [38400/50000]\n",
            "loss: 1.741300 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 69.0%, Avg loss: 1.768735 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 62\n",
            "----------------------------\n",
            "loss: 1.633384 [    0/50000]\n",
            "loss: 1.668708 [ 6400/50000]\n",
            "loss: 1.688964 [12800/50000]\n",
            "loss: 1.712674 [19200/50000]\n",
            "loss: 1.688355 [25600/50000]\n",
            "loss: 1.760120 [32000/50000]\n",
            "loss: 1.663487 [38400/50000]\n",
            "loss: 1.729177 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 67.9%, Avg loss: 1.779952 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 63\n",
            "----------------------------\n",
            "loss: 1.595518 [    0/50000]\n",
            "loss: 1.602503 [ 6400/50000]\n",
            "loss: 1.623150 [12800/50000]\n",
            "loss: 1.730058 [19200/50000]\n",
            "loss: 1.658350 [25600/50000]\n",
            "loss: 1.767737 [32000/50000]\n",
            "loss: 1.745952 [38400/50000]\n",
            "loss: 1.726800 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 67.3%, Avg loss: 1.787355 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 64\n",
            "----------------------------\n",
            "loss: 1.681765 [    0/50000]\n",
            "loss: 1.692560 [ 6400/50000]\n",
            "loss: 1.640376 [12800/50000]\n",
            "loss: 1.681857 [19200/50000]\n",
            "loss: 1.710428 [25600/50000]\n",
            "loss: 1.790360 [32000/50000]\n",
            "loss: 1.639610 [38400/50000]\n",
            "loss: 1.706620 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 67.9%, Avg loss: 1.781983 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 65\n",
            "----------------------------\n",
            "loss: 1.606530 [    0/50000]\n",
            "loss: 1.662897 [ 6400/50000]\n",
            "loss: 1.655777 [12800/50000]\n",
            "loss: 1.663797 [19200/50000]\n",
            "loss: 1.709211 [25600/50000]\n",
            "loss: 1.774995 [32000/50000]\n",
            "loss: 1.642209 [38400/50000]\n",
            "loss: 1.682706 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 64.4%, Avg loss: 1.815312 \n",
            "\n",
            "Patience count: 4\n",
            "\n",
            "Epoch 66\n",
            "----------------------------\n",
            "loss: 1.730602 [    0/50000]\n",
            "loss: 1.676101 [ 6400/50000]\n",
            "loss: 1.652071 [12800/50000]\n",
            "loss: 1.644428 [19200/50000]\n",
            "loss: 1.694873 [25600/50000]\n",
            "loss: 1.790440 [32000/50000]\n",
            "loss: 1.615873 [38400/50000]\n",
            "loss: 1.783426 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 70.1%, Avg loss: 1.758250 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 67\n",
            "----------------------------\n",
            "loss: 1.628775 [    0/50000]\n",
            "loss: 1.559990 [ 6400/50000]\n",
            "loss: 1.605969 [12800/50000]\n",
            "loss: 1.664998 [19200/50000]\n",
            "loss: 1.705172 [25600/50000]\n",
            "loss: 1.836874 [32000/50000]\n",
            "loss: 1.664795 [38400/50000]\n",
            "loss: 1.694067 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 70.4%, Avg loss: 1.757018 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 68\n",
            "----------------------------\n",
            "loss: 1.618614 [    0/50000]\n",
            "loss: 1.670274 [ 6400/50000]\n",
            "loss: 1.588917 [12800/50000]\n",
            "loss: 1.666239 [19200/50000]\n",
            "loss: 1.720239 [25600/50000]\n",
            "loss: 1.761694 [32000/50000]\n",
            "loss: 1.621335 [38400/50000]\n",
            "loss: 1.711451 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 68.6%, Avg loss: 1.775290 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 69\n",
            "----------------------------\n",
            "loss: 1.586725 [    0/50000]\n",
            "loss: 1.624421 [ 6400/50000]\n",
            "loss: 1.626252 [12800/50000]\n",
            "loss: 1.728740 [19200/50000]\n",
            "loss: 1.675092 [25600/50000]\n",
            "loss: 1.767849 [32000/50000]\n",
            "loss: 1.602760 [38400/50000]\n",
            "loss: 1.678041 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.1%, Avg loss: 1.749820 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 70\n",
            "----------------------------\n",
            "loss: 1.620905 [    0/50000]\n",
            "loss: 1.654094 [ 6400/50000]\n",
            "loss: 1.615517 [12800/50000]\n",
            "loss: 1.622254 [19200/50000]\n",
            "loss: 1.731643 [25600/50000]\n",
            "loss: 1.747933 [32000/50000]\n",
            "loss: 1.677625 [38400/50000]\n",
            "loss: 1.726112 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 70.1%, Avg loss: 1.759946 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 71\n",
            "----------------------------\n",
            "loss: 1.669314 [    0/50000]\n",
            "loss: 1.660300 [ 6400/50000]\n",
            "loss: 1.602137 [12800/50000]\n",
            "loss: 1.639340 [19200/50000]\n",
            "loss: 1.696121 [25600/50000]\n",
            "loss: 1.719522 [32000/50000]\n",
            "loss: 1.635040 [38400/50000]\n",
            "loss: 1.703735 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 70.2%, Avg loss: 1.757358 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 72\n",
            "----------------------------\n",
            "loss: 1.637930 [    0/50000]\n",
            "loss: 1.679831 [ 6400/50000]\n",
            "loss: 1.617969 [12800/50000]\n",
            "loss: 1.650633 [19200/50000]\n",
            "loss: 1.653948 [25600/50000]\n",
            "loss: 1.683146 [32000/50000]\n",
            "loss: 1.651517 [38400/50000]\n",
            "loss: 1.652818 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 69.6%, Avg loss: 1.764251 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 73\n",
            "----------------------------\n",
            "loss: 1.642646 [    0/50000]\n",
            "loss: 1.627342 [ 6400/50000]\n",
            "loss: 1.567729 [12800/50000]\n",
            "loss: 1.642233 [19200/50000]\n",
            "loss: 1.673745 [25600/50000]\n",
            "loss: 1.721683 [32000/50000]\n",
            "loss: 1.662088 [38400/50000]\n",
            "loss: 1.658722 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 70.5%, Avg loss: 1.754324 \n",
            "\n",
            "Patience count: 4\n",
            "\n",
            "Epoch 74\n",
            "----------------------------\n",
            "loss: 1.588715 [    0/50000]\n",
            "loss: 1.645489 [ 6400/50000]\n",
            "loss: 1.641723 [12800/50000]\n",
            "loss: 1.697427 [19200/50000]\n",
            "loss: 1.650705 [25600/50000]\n",
            "loss: 1.753923 [32000/50000]\n",
            "loss: 1.648358 [38400/50000]\n",
            "loss: 1.665835 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 1.747817 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 75\n",
            "----------------------------\n",
            "loss: 1.621529 [    0/50000]\n",
            "loss: 1.617437 [ 6400/50000]\n",
            "loss: 1.628360 [12800/50000]\n",
            "loss: 1.668567 [19200/50000]\n",
            "loss: 1.640608 [25600/50000]\n",
            "loss: 1.739651 [32000/50000]\n",
            "loss: 1.743038 [38400/50000]\n",
            "loss: 1.652742 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 70.8%, Avg loss: 1.752217 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 76\n",
            "----------------------------\n",
            "loss: 1.594909 [    0/50000]\n",
            "loss: 1.613136 [ 6400/50000]\n",
            "loss: 1.645253 [12800/50000]\n",
            "loss: 1.647118 [19200/50000]\n",
            "loss: 1.619330 [25600/50000]\n",
            "loss: 1.745025 [32000/50000]\n",
            "loss: 1.632805 [38400/50000]\n",
            "loss: 1.677428 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 1.745085 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 77\n",
            "----------------------------\n",
            "loss: 1.563860 [    0/50000]\n",
            "loss: 1.599067 [ 6400/50000]\n",
            "loss: 1.614486 [12800/50000]\n",
            "loss: 1.692588 [19200/50000]\n",
            "loss: 1.646425 [25600/50000]\n",
            "loss: 1.728397 [32000/50000]\n",
            "loss: 1.653672 [38400/50000]\n",
            "loss: 1.628710 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 1.747614 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 78\n",
            "----------------------------\n",
            "loss: 1.593774 [    0/50000]\n",
            "loss: 1.610575 [ 6400/50000]\n",
            "loss: 1.619935 [12800/50000]\n",
            "loss: 1.718636 [19200/50000]\n",
            "loss: 1.640893 [25600/50000]\n",
            "loss: 1.671305 [32000/50000]\n",
            "loss: 1.602734 [38400/50000]\n",
            "loss: 1.704464 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 64.8%, Avg loss: 1.811871 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 79\n",
            "----------------------------\n",
            "loss: 1.766454 [    0/50000]\n",
            "loss: 1.588484 [ 6400/50000]\n",
            "loss: 1.596130 [12800/50000]\n",
            "loss: 1.667750 [19200/50000]\n",
            "loss: 1.648895 [25600/50000]\n",
            "loss: 1.696228 [32000/50000]\n",
            "loss: 1.602743 [38400/50000]\n",
            "loss: 1.705686 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 1.748037 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 80\n",
            "----------------------------\n",
            "loss: 1.639538 [    0/50000]\n",
            "loss: 1.679115 [ 6400/50000]\n",
            "loss: 1.649613 [12800/50000]\n",
            "loss: 1.601648 [19200/50000]\n",
            "loss: 1.685348 [25600/50000]\n",
            "loss: 1.759134 [32000/50000]\n",
            "loss: 1.664210 [38400/50000]\n",
            "loss: 1.681237 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.5%, Avg loss: 1.745850 \n",
            "\n",
            "Patience count: 4\n",
            "\n",
            "Epoch 81\n",
            "----------------------------\n",
            "loss: 1.640229 [    0/50000]\n",
            "loss: 1.642202 [ 6400/50000]\n",
            "loss: 1.668177 [12800/50000]\n",
            "loss: 1.667996 [19200/50000]\n",
            "loss: 1.637159 [25600/50000]\n",
            "loss: 1.763932 [32000/50000]\n",
            "loss: 1.627423 [38400/50000]\n",
            "loss: 1.699310 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 1.748280 \n",
            "\n",
            "Patience count: 5\n",
            "\n",
            "Epoch 82\n",
            "----------------------------\n",
            "loss: 1.617854 [    0/50000]\n",
            "loss: 1.625899 [ 6400/50000]\n",
            "loss: 1.597647 [12800/50000]\n",
            "loss: 1.633086 [19200/50000]\n",
            "loss: 1.642594 [25600/50000]\n",
            "loss: 1.699935 [32000/50000]\n",
            "loss: 1.658818 [38400/50000]\n",
            "loss: 1.665085 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 70.4%, Avg loss: 1.755609 \n",
            "\n",
            "Patience count: 6\n",
            "\n",
            "Epoch 83\n",
            "----------------------------\n",
            "loss: 1.629178 [    0/50000]\n",
            "loss: 1.588292 [ 6400/50000]\n",
            "loss: 1.591168 [12800/50000]\n",
            "loss: 1.627866 [19200/50000]\n",
            "loss: 1.681349 [25600/50000]\n",
            "loss: 1.688559 [32000/50000]\n",
            "loss: 1.635913 [38400/50000]\n",
            "loss: 1.666691 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.0%, Avg loss: 1.750565 \n",
            "\n",
            "Patience count: 7\n",
            "\n",
            "Epoch 84\n",
            "----------------------------\n",
            "loss: 1.601413 [    0/50000]\n",
            "loss: 1.696728 [ 6400/50000]\n",
            "loss: 1.574293 [12800/50000]\n",
            "loss: 1.671341 [19200/50000]\n",
            "loss: 1.649881 [25600/50000]\n",
            "loss: 1.696508 [32000/50000]\n",
            "loss: 1.671244 [38400/50000]\n",
            "loss: 1.657074 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.9%, Avg loss: 1.741011 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 85\n",
            "----------------------------\n",
            "loss: 1.619258 [    0/50000]\n",
            "loss: 1.601170 [ 6400/50000]\n",
            "loss: 1.665677 [12800/50000]\n",
            "loss: 1.585780 [19200/50000]\n",
            "loss: 1.617941 [25600/50000]\n",
            "loss: 1.713972 [32000/50000]\n",
            "loss: 1.624925 [38400/50000]\n",
            "loss: 1.694780 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.6%, Avg loss: 1.744311 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 86\n",
            "----------------------------\n",
            "loss: 1.613516 [    0/50000]\n",
            "loss: 1.691731 [ 6400/50000]\n",
            "loss: 1.585739 [12800/50000]\n",
            "loss: 1.614370 [19200/50000]\n",
            "loss: 1.655800 [25600/50000]\n",
            "loss: 1.694156 [32000/50000]\n",
            "loss: 1.614393 [38400/50000]\n",
            "loss: 1.662195 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 72.7%, Avg loss: 1.733851 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 87\n",
            "----------------------------\n",
            "loss: 1.590479 [    0/50000]\n",
            "loss: 1.616973 [ 6400/50000]\n",
            "loss: 1.581995 [12800/50000]\n",
            "loss: 1.594198 [19200/50000]\n",
            "loss: 1.612403 [25600/50000]\n",
            "loss: 1.694452 [32000/50000]\n",
            "loss: 1.685121 [38400/50000]\n",
            "loss: 1.699317 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 1.746059 \n",
            "\n",
            "Patience count: 1\n",
            "\n",
            "Epoch 88\n",
            "----------------------------\n",
            "loss: 1.635737 [    0/50000]\n",
            "loss: 1.628573 [ 6400/50000]\n",
            "loss: 1.633557 [12800/50000]\n",
            "loss: 1.630607 [19200/50000]\n",
            "loss: 1.634525 [25600/50000]\n",
            "loss: 1.741858 [32000/50000]\n",
            "loss: 1.632340 [38400/50000]\n",
            "loss: 1.669533 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 69.0%, Avg loss: 1.770807 \n",
            "\n",
            "Patience count: 2\n",
            "\n",
            "Epoch 89\n",
            "----------------------------\n",
            "loss: 1.664059 [    0/50000]\n",
            "loss: 1.614475 [ 6400/50000]\n",
            "loss: 1.614227 [12800/50000]\n",
            "loss: 1.629828 [19200/50000]\n",
            "loss: 1.641414 [25600/50000]\n",
            "loss: 1.725297 [32000/50000]\n",
            "loss: 1.628082 [38400/50000]\n",
            "loss: 1.679229 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.1%, Avg loss: 1.748940 \n",
            "\n",
            "Patience count: 3\n",
            "\n",
            "Epoch 90\n",
            "----------------------------\n",
            "loss: 1.631795 [    0/50000]\n",
            "loss: 1.646161 [ 6400/50000]\n",
            "loss: 1.634342 [12800/50000]\n",
            "loss: 1.639398 [19200/50000]\n",
            "loss: 1.633593 [25600/50000]\n",
            "loss: 1.696673 [32000/50000]\n",
            "loss: 1.637298 [38400/50000]\n",
            "loss: 1.710753 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.3%, Avg loss: 1.747217 \n",
            "\n",
            "Patience count: 4\n",
            "\n",
            "Epoch 91\n",
            "----------------------------\n",
            "loss: 1.632031 [    0/50000]\n",
            "loss: 1.629574 [ 6400/50000]\n",
            "loss: 1.598898 [12800/50000]\n",
            "loss: 1.641265 [19200/50000]\n",
            "loss: 1.626835 [25600/50000]\n",
            "loss: 1.693563 [32000/50000]\n",
            "loss: 1.635087 [38400/50000]\n",
            "loss: 1.666102 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.5%, Avg loss: 1.746428 \n",
            "\n",
            "Patience count: 5\n",
            "\n",
            "Epoch 92\n",
            "----------------------------\n",
            "loss: 1.584519 [    0/50000]\n",
            "loss: 1.602057 [ 6400/50000]\n",
            "loss: 1.577093 [12800/50000]\n",
            "loss: 1.648406 [19200/50000]\n",
            "loss: 1.645827 [25600/50000]\n",
            "loss: 1.721820 [32000/50000]\n",
            "loss: 1.588057 [38400/50000]\n",
            "loss: 1.648352 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 1.745519 \n",
            "\n",
            "Patience count: 6\n",
            "\n",
            "Epoch 93\n",
            "----------------------------\n",
            "loss: 1.634605 [    0/50000]\n",
            "loss: 1.625614 [ 6400/50000]\n",
            "loss: 1.617341 [12800/50000]\n",
            "loss: 1.581680 [19200/50000]\n",
            "loss: 1.648342 [25600/50000]\n",
            "loss: 1.762119 [32000/50000]\n",
            "loss: 1.598912 [38400/50000]\n",
            "loss: 1.712620 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 67.7%, Avg loss: 1.781883 \n",
            "\n",
            "Patience count: 7\n",
            "\n",
            "Epoch 94\n",
            "----------------------------\n",
            "loss: 1.649227 [    0/50000]\n",
            "loss: 1.642428 [ 6400/50000]\n",
            "loss: 1.545307 [12800/50000]\n",
            "loss: 1.565701 [19200/50000]\n",
            "loss: 1.632439 [25600/50000]\n",
            "loss: 1.703026 [32000/50000]\n",
            "loss: 1.607684 [38400/50000]\n",
            "loss: 1.695289 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 70.7%, Avg loss: 1.753612 \n",
            "\n",
            "Patience count: 8\n",
            "\n",
            "Epoch 95\n",
            "----------------------------\n",
            "loss: 1.662195 [    0/50000]\n",
            "loss: 1.606413 [ 6400/50000]\n",
            "loss: 1.584981 [12800/50000]\n",
            "loss: 1.648310 [19200/50000]\n",
            "loss: 1.632428 [25600/50000]\n",
            "loss: 1.707276 [32000/50000]\n",
            "loss: 1.662859 [38400/50000]\n",
            "loss: 1.697016 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 1.748181 \n",
            "\n",
            "Patience count: 9\n",
            "\n",
            "Epoch 96\n",
            "----------------------------\n",
            "loss: 1.606972 [    0/50000]\n",
            "loss: 1.575336 [ 6400/50000]\n",
            "loss: 1.624613 [12800/50000]\n",
            "loss: 1.616659 [19200/50000]\n",
            "loss: 1.694942 [25600/50000]\n",
            "loss: 1.789656 [32000/50000]\n",
            "loss: 1.663912 [38400/50000]\n",
            "loss: 1.658796 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 68.7%, Avg loss: 1.773739 \n",
            "\n",
            "Finished due to early stopping.\n",
            "Saving best model: test_epoch-086\n",
            "Saving best model: test_epoch-086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK31_tvQLkRo"
      },
      "source": [
        "# Results on CIFAR10:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53YZcWbELoEm"
      },
      "source": [
        "## Six layer model (current best)\n",
        "- Test accuracy: 72.7%\n",
        "- Avg loss: 1.733851\n",
        "\n",
        "Architecture:\n",
        "- 32 x 32 x 3 conv, ReLU - (3,3), 256\n",
        "- Maxpool (2,2)\n",
        "- 16 x 16 x 256 conv, ReLU - (3,3), 128\n",
        "- Maxpool (2,2)\n",
        "- 8 x 8 x 128 conv, ReLU - (3,3), 64\n",
        "- Maxpool (2,2)\n",
        "- 4 x 4 x 64 conv, ReLU - (3,3), 32\n",
        "- 4 x 4 x 32 conv, ReLU - (3,3), 16\n",
        "- Flatten\n",
        "- Fully connect layer (256, 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imBDYEwbYp2V"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}