{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLNi63lzjPRpFYYrhwpSmY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malloyca/CSC581B/blob/main/Final%20Project/linear_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwLHFQDMPHFV"
      },
      "source": [
        "# CSC581B - Introduction to Deep Learning for Image Classification\n",
        "# Final Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qROMWFFMPGZZ"
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Compose, Normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mWOoFAqRy5c"
      },
      "source": [
        "First we need to load the training and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfml-mHmP4Z7",
        "outputId": "c907f85c-3976-450c-8973-d0b7ef73e266"
      },
      "source": [
        "# Load the training data\n",
        "training_data = datasets.CIFAR100(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        "    #transform = Compose([ToTensor(),\n",
        "    #                    Normalize([0.5071, 0.4867, 0.4408],\n",
        "    #                              [0.2675, 0.2565, 0.2761])])\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = datasets.CIFAR100(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Ti21sdu9vB"
      },
      "source": [
        "training_targets = training_data.targets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz-hejWHu9nb"
      },
      "source": [
        "train_split_index, valid_split_index = train_test_split(\n",
        "    np.arange(len(training_targets)), test_size=0.2, stratify=training_targets\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJgFLmWPQ-rU"
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size,\n",
        "                              sampler=SubsetRandomSampler(train_split_index))\n",
        "valid_dataloader = DataLoader(training_data, batch_size=batch_size,\n",
        "                              sampler=SubsetRandomSampler(valid_split_index))\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoIkbJTtRad9",
        "outputId": "b0809f1e-e8cc-4565-9af4-e04e279e3698"
      },
      "source": [
        "# Check that it is splitting the data properly\n",
        "train_length = 0\n",
        "for _, y in train_dataloader:\n",
        "  train_length += len(y)\n",
        "print(f\"Length of training split: {train_length}\")\n",
        "\n",
        "valid_length = 0\n",
        "for _, y in valid_dataloader:\n",
        "  valid_length += len(y)\n",
        "print(f\"Length of validation split: {valid_length}\")\n",
        "\n",
        "test_length = 0\n",
        "for _, y in test_dataloader:\n",
        "  test_length += len(y)\n",
        "print(f\"Length of test split: {test_length}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training split: 40000\n",
            "Length of validation split: 10000\n",
            "Length of test split: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvwjwC3Rv8_X",
        "outputId": "553aaa93-d4ee-4496-a44e-af49b628780d"
      },
      "source": [
        "# Check that there are 100 instances of each class in the validation set\n",
        "count = 0\n",
        "for _, y in valid_dataloader:\n",
        "  for target in y:\n",
        "    if int(target.numpy()) == 0:\n",
        "      count += 1\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od9dSB59eV4g"
      },
      "source": [
        "mean: 'cifar100': (0.5071, 0.4867, 0.4408),\n",
        "\n",
        "std: 'cifar100': (0.2675, 0.2565, 0.2761),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0Hhp8VR-AG"
      },
      "source": [
        "## Building some linear models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h9ROBxpRnuq",
        "outputId": "a375aaf9-b0ec-4cf7-8fdd-afda75204e9a"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvTQcnbXSPHf"
      },
      "source": [
        "# Define the model\n",
        "class LinearModel(nn.Module):\n",
        "  def __init__(self, n_neurons):\n",
        "    super(LinearModel, self).__init__()\n",
        "    self.name = f'model_{n_neurons}'\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_model = nn.Sequential(\n",
        "        nn.Linear(32*32*3, n_neurons),\n",
        "        nn.Linear(n_neurons, n_neurons),\n",
        "        nn.Linear(n_neurons, 100),\n",
        "    )\n",
        "\n",
        "  # Forward propagation function\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear_model(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC6gSZZ9TsEo"
      },
      "source": [
        "# Define training loop function\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = 40000\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9joI7v5Ucpm"
      },
      "source": [
        "# Define the test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "  return test_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPYeNOb1VN65"
      },
      "source": [
        "n_epochs = 50"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQFhFtxVgi7D"
      },
      "source": [
        "def training_loop(n_epochs, model, train_data, test_data, loss_function,\n",
        "                  optimizer, scheduler=None, early_stopping=False, patience=10):\n",
        "  current_epoch = 0\n",
        "  best_epoch = 0\n",
        "  best_loss = float('inf')\n",
        "  patience_counter = 0\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    # Iterate epoch counter\n",
        "    current_epoch += 1\n",
        "    print()\n",
        "    print(f\"Epoch {current_epoch}\\n----------------------------\")\n",
        "\n",
        "    train(train_data, model, loss_function, optimizer)\n",
        "    test_loss = test(test_data, model, loss_function)\n",
        "\n",
        "    # Iterate LR scheduler\n",
        "    if scheduler is not None:\n",
        "      scheduler.step()\n",
        "\n",
        "    # Check test_loss for early stopping\n",
        "    if early_stopping:\n",
        "      if test_loss < best_loss:\n",
        "        # store loss\n",
        "        best_loss = test_loss\n",
        "\n",
        "        # reset patience counter\n",
        "        patience_counter = 0\n",
        "\n",
        "        # store model and epoch number\n",
        "        print(\"Storing new best model.\")\n",
        "        best_model_state_dict = copy.deepcopy(model.state_dict())\n",
        "        best_epoch = current_epoch\n",
        "        \n",
        "      # If patience limit not yet reached, iterate patience counter\n",
        "      elif patience_counter < patience - 1:\n",
        "        patience_counter += 1\n",
        "        print(f\"Patience counter: {patience_counter}\")\n",
        "      \n",
        "      # If patience limit reached, store model and break the loop\n",
        "      else:\n",
        "        print(\"Finished due to early stopping.\")\n",
        "        print(f\"Saving best model: {model.name}_epoch-{best_epoch:03d}\")\n",
        "        torch.save(best_model_state_dict, f'{model.name}_epoch-{best_epoch:03d}')\n",
        "        break\n",
        "\n",
        "  # If we get here, we did not stop early - save best model\n",
        "  if early_stopping:\n",
        "    print(f\"Saving best model: {model.name}-epoch:{best_epoch:03d}\")\n",
        "    torch.save(best_model_state_dict, f'{model.name}-epoch:{best_epoch:03d}')\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjdHv7tMcmhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7e8881-aa5e-4585-ed1c-e48cb6ff6ae1"
      },
      "source": [
        "model_100 = LinearModel(n_neurons=100).to(device)\n",
        "print(model_100)\n",
        "\n",
        "model_500 = LinearModel(n_neurons=500).to(device)\n",
        "print(model_500)\n",
        "\n",
        "model_1000 = LinearModel(n_neurons=1000).to(device)\n",
        "print(model_1000)\n",
        "\n",
        "model_2500 = LinearModel(n_neurons=2000).to(device)\n",
        "print(model_2500)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
            "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  )\n",
            ")\n",
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=500, bias=True)\n",
            "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
            "    (2): Linear(in_features=500, out_features=100, bias=True)\n",
            "  )\n",
            ")\n",
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=1000, bias=True)\n",
            "    (1): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "    (2): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  )\n",
            ")\n",
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=2000, bias=True)\n",
            "    (1): Linear(in_features=2000, out_features=2000, bias=True)\n",
            "    (2): Linear(in_features=2000, out_features=100, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om2XSgK8TO7i"
      },
      "source": [
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer_100 = torch.optim.SGD(model_100.parameters(), lr=1e-1)\n",
        "optimizer_500 = torch.optim.SGD(model_500.parameters(), lr=1e-1)\n",
        "optimizer_1000 = torch.optim.SGD(model_1000.parameters(), lr=5e-2)\n",
        "optimizer_2500 = torch.optim.SGD(model_2500.parameters(), lr=1e-1)\n",
        "\n",
        "# Learning rate schedulers\n",
        "scheduler_100 = StepLR(optimizer_100, step_size=15, gamma=0.1)\n",
        "scheduler_500 = StepLR(optimizer_500, step_size=15, gamma=0.1)\n",
        "scheduler_1000 = StepLR(optimizer_1000, step_size=20, gamma=0.25)\n",
        "scheduler_2500 = StepLR(optimizer_2500, step_size=15, gamma=0.1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlN7IdWWlXCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "53faa53a-064d-46c8-c35d-0e694f0d36a9"
      },
      "source": [
        "training_loop(n_epochs, model_100, train_dataloader, valid_dataloader,\n",
        "              loss_fn, optimizer_100, scheduler=scheduler_100, early_stopping=False, patience=10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "----------------------------\n",
            "loss: 4.599590 [    0/40000]\n",
            "loss: 4.195426 [10000/40000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-399de6bc14c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m training_loop(n_epochs, model_100, train_dataloader, valid_dataloader,\n\u001b[0;32m----> 2\u001b[0;31m               loss_fn, optimizer_100, scheduler=scheduler_100, early_stopping=False, patience=10)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-0a30f2890798>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, model, train_data, test_data, loss_function, optimizer, scheduler, early_stopping, patience)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {current_epoch}\\n----------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c7d39f231952>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "262-Gta2aIUD"
      },
      "source": [
        "training_loop(n_epochs, model_500, train_dataloader, valid_dataloader,\n",
        "              loss_fn, optimizer_500, scheduler=scheduler_500, early_stopping=False, patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EARFi7nyCjOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30adb6b-2212-405b-ea34-61c29e8be726"
      },
      "source": [
        "training_loop(n_epochs, model_1000, train_dataloader, valid_dataloader,\n",
        "              loss_fn, optimizer_1000, scheduler=scheduler_1000, early_stopping=False, patience=10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "----------------------------\n",
            "loss: 4.627542 [    0/40000]\n",
            "loss: 4.462950 [10000/40000]\n",
            "loss: 4.256098 [20000/40000]\n",
            "loss: 3.947877 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 2.0%, Avg loss: 3.993850 \n",
            "\n",
            "\n",
            "Epoch 2\n",
            "----------------------------\n",
            "loss: 3.953144 [    0/40000]\n",
            "loss: 3.753744 [10000/40000]\n",
            "loss: 3.752641 [20000/40000]\n",
            "loss: 3.708488 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 2.4%, Avg loss: 3.856921 \n",
            "\n",
            "\n",
            "Epoch 3\n",
            "----------------------------\n",
            "loss: 3.947703 [    0/40000]\n",
            "loss: 4.088981 [10000/40000]\n",
            "loss: 3.892617 [20000/40000]\n",
            "loss: 3.756453 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 2.9%, Avg loss: 3.769571 \n",
            "\n",
            "\n",
            "Epoch 4\n",
            "----------------------------\n",
            "loss: 3.425246 [    0/40000]\n",
            "loss: 3.935998 [10000/40000]\n",
            "loss: 3.888884 [20000/40000]\n",
            "loss: 3.740047 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 2.7%, Avg loss: 3.805315 \n",
            "\n",
            "\n",
            "Epoch 5\n",
            "----------------------------\n",
            "loss: 4.044482 [    0/40000]\n",
            "loss: 3.699428 [10000/40000]\n",
            "loss: 3.784934 [20000/40000]\n",
            "loss: 3.707857 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.1%, Avg loss: 3.730360 \n",
            "\n",
            "\n",
            "Epoch 6\n",
            "----------------------------\n",
            "loss: 3.892279 [    0/40000]\n",
            "loss: 3.750241 [10000/40000]\n",
            "loss: 3.713996 [20000/40000]\n",
            "loss: 3.699202 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.0%, Avg loss: 3.732297 \n",
            "\n",
            "\n",
            "Epoch 7\n",
            "----------------------------\n",
            "loss: 3.704239 [    0/40000]\n",
            "loss: 3.526299 [10000/40000]\n",
            "loss: 3.546630 [20000/40000]\n",
            "loss: 3.717514 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.3%, Avg loss: 3.684219 \n",
            "\n",
            "\n",
            "Epoch 8\n",
            "----------------------------\n",
            "loss: 3.881510 [    0/40000]\n",
            "loss: 3.728667 [10000/40000]\n",
            "loss: 3.641596 [20000/40000]\n",
            "loss: 3.329364 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.2%, Avg loss: 3.705926 \n",
            "\n",
            "\n",
            "Epoch 9\n",
            "----------------------------\n",
            "loss: 3.493699 [    0/40000]\n",
            "loss: 3.820245 [10000/40000]\n",
            "loss: 3.831080 [20000/40000]\n",
            "loss: 3.758403 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.2%, Avg loss: 3.699930 \n",
            "\n",
            "\n",
            "Epoch 10\n",
            "----------------------------\n",
            "loss: 3.438702 [    0/40000]\n",
            "loss: 3.674974 [10000/40000]\n",
            "loss: 3.668889 [20000/40000]\n",
            "loss: 3.746086 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.4%, Avg loss: 3.658616 \n",
            "\n",
            "\n",
            "Epoch 11\n",
            "----------------------------\n",
            "loss: 3.755841 [    0/40000]\n",
            "loss: 3.597160 [10000/40000]\n",
            "loss: 3.619592 [20000/40000]\n",
            "loss: 3.568338 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.4%, Avg loss: 3.672053 \n",
            "\n",
            "\n",
            "Epoch 12\n",
            "----------------------------\n",
            "loss: 3.605977 [    0/40000]\n",
            "loss: 3.383169 [10000/40000]\n",
            "loss: 3.430723 [20000/40000]\n",
            "loss: 3.594745 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.1%, Avg loss: 3.728379 \n",
            "\n",
            "\n",
            "Epoch 13\n",
            "----------------------------\n",
            "loss: 3.399997 [    0/40000]\n",
            "loss: 3.460642 [10000/40000]\n",
            "loss: 3.674428 [20000/40000]\n",
            "loss: 3.581581 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.3%, Avg loss: 3.694303 \n",
            "\n",
            "\n",
            "Epoch 14\n",
            "----------------------------\n",
            "loss: 3.409815 [    0/40000]\n",
            "loss: 3.561011 [10000/40000]\n",
            "loss: 3.566642 [20000/40000]\n",
            "loss: 3.564054 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.5%, Avg loss: 3.645861 \n",
            "\n",
            "\n",
            "Epoch 15\n",
            "----------------------------\n",
            "loss: 3.320645 [    0/40000]\n",
            "loss: 3.651606 [10000/40000]\n",
            "loss: 3.739908 [20000/40000]\n",
            "loss: 3.455880 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.4%, Avg loss: 3.675430 \n",
            "\n",
            "\n",
            "Epoch 16\n",
            "----------------------------\n",
            "loss: 3.473298 [    0/40000]\n",
            "loss: 3.610259 [10000/40000]\n",
            "loss: 3.758456 [20000/40000]\n",
            "loss: 3.475229 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.5%, Avg loss: 3.675929 \n",
            "\n",
            "\n",
            "Epoch 17\n",
            "----------------------------\n",
            "loss: 3.485158 [    0/40000]\n",
            "loss: 3.694229 [10000/40000]\n",
            "loss: 3.342248 [20000/40000]\n",
            "loss: 3.720055 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.4%, Avg loss: 3.692771 \n",
            "\n",
            "\n",
            "Epoch 18\n",
            "----------------------------\n",
            "loss: 3.493878 [    0/40000]\n",
            "loss: 3.214425 [10000/40000]\n",
            "loss: 3.553705 [20000/40000]\n",
            "loss: 3.442070 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.4%, Avg loss: 3.665284 \n",
            "\n",
            "\n",
            "Epoch 19\n",
            "----------------------------\n",
            "loss: 3.807335 [    0/40000]\n",
            "loss: 3.490564 [10000/40000]\n",
            "loss: 3.458379 [20000/40000]\n",
            "loss: 3.232434 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.5%, Avg loss: 3.660974 \n",
            "\n",
            "\n",
            "Epoch 20\n",
            "----------------------------\n",
            "loss: 3.323589 [    0/40000]\n",
            "loss: 3.671429 [10000/40000]\n",
            "loss: 3.771463 [20000/40000]\n",
            "loss: 3.515601 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.3%, Avg loss: 3.708297 \n",
            "\n",
            "\n",
            "Epoch 21\n",
            "----------------------------\n",
            "loss: 3.888423 [    0/40000]\n",
            "loss: 3.612306 [10000/40000]\n",
            "loss: 3.415527 [20000/40000]\n",
            "loss: 3.182747 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.9%, Avg loss: 3.585767 \n",
            "\n",
            "\n",
            "Epoch 22\n",
            "----------------------------\n",
            "loss: 3.333051 [    0/40000]\n",
            "loss: 3.523278 [10000/40000]\n",
            "loss: 3.426411 [20000/40000]\n",
            "loss: 3.378243 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.587946 \n",
            "\n",
            "\n",
            "Epoch 23\n",
            "----------------------------\n",
            "loss: 3.203588 [    0/40000]\n",
            "loss: 3.551724 [10000/40000]\n",
            "loss: 3.256038 [20000/40000]\n",
            "loss: 3.098948 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.592530 \n",
            "\n",
            "\n",
            "Epoch 24\n",
            "----------------------------\n",
            "loss: 3.391988 [    0/40000]\n",
            "loss: 3.028739 [10000/40000]\n",
            "loss: 3.525635 [20000/40000]\n",
            "loss: 3.401347 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.593691 \n",
            "\n",
            "\n",
            "Epoch 25\n",
            "----------------------------\n",
            "loss: 3.282839 [    0/40000]\n",
            "loss: 3.125205 [10000/40000]\n",
            "loss: 3.224996 [20000/40000]\n",
            "loss: 3.298129 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.594758 \n",
            "\n",
            "\n",
            "Epoch 26\n",
            "----------------------------\n",
            "loss: 3.419700 [    0/40000]\n",
            "loss: 3.150807 [10000/40000]\n",
            "loss: 3.282313 [20000/40000]\n",
            "loss: 3.563678 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.9%, Avg loss: 3.592913 \n",
            "\n",
            "\n",
            "Epoch 27\n",
            "----------------------------\n",
            "loss: 3.156880 [    0/40000]\n",
            "loss: 3.288873 [10000/40000]\n",
            "loss: 3.365180 [20000/40000]\n",
            "loss: 3.452181 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.7%, Avg loss: 3.608432 \n",
            "\n",
            "\n",
            "Epoch 28\n",
            "----------------------------\n",
            "loss: 3.560317 [    0/40000]\n",
            "loss: 3.499139 [10000/40000]\n",
            "loss: 3.132977 [20000/40000]\n",
            "loss: 3.345193 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.597473 \n",
            "\n",
            "\n",
            "Epoch 29\n",
            "----------------------------\n",
            "loss: 3.179982 [    0/40000]\n",
            "loss: 3.188560 [10000/40000]\n",
            "loss: 3.248583 [20000/40000]\n",
            "loss: 3.175903 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.606029 \n",
            "\n",
            "\n",
            "Epoch 30\n",
            "----------------------------\n",
            "loss: 3.317561 [    0/40000]\n",
            "loss: 3.514184 [10000/40000]\n",
            "loss: 3.423106 [20000/40000]\n",
            "loss: 3.053569 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.603409 \n",
            "\n",
            "\n",
            "Epoch 31\n",
            "----------------------------\n",
            "loss: 3.415525 [    0/40000]\n",
            "loss: 2.872567 [10000/40000]\n",
            "loss: 3.405797 [20000/40000]\n",
            "loss: 3.246190 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.615700 \n",
            "\n",
            "\n",
            "Epoch 32\n",
            "----------------------------\n",
            "loss: 3.325371 [    0/40000]\n",
            "loss: 3.561394 [10000/40000]\n",
            "loss: 3.353637 [20000/40000]\n",
            "loss: 3.259463 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.616648 \n",
            "\n",
            "\n",
            "Epoch 33\n",
            "----------------------------\n",
            "loss: 3.347397 [    0/40000]\n",
            "loss: 3.394275 [10000/40000]\n",
            "loss: 3.177364 [20000/40000]\n",
            "loss: 3.239374 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.608857 \n",
            "\n",
            "\n",
            "Epoch 34\n",
            "----------------------------\n",
            "loss: 3.081566 [    0/40000]\n",
            "loss: 3.583891 [10000/40000]\n",
            "loss: 2.982551 [20000/40000]\n",
            "loss: 3.497931 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.623891 \n",
            "\n",
            "\n",
            "Epoch 35\n",
            "----------------------------\n",
            "loss: 3.416633 [    0/40000]\n",
            "loss: 3.346086 [10000/40000]\n",
            "loss: 3.212551 [20000/40000]\n",
            "loss: 3.479498 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.618490 \n",
            "\n",
            "\n",
            "Epoch 36\n",
            "----------------------------\n",
            "loss: 3.456350 [    0/40000]\n",
            "loss: 3.085679 [10000/40000]\n",
            "loss: 3.132994 [20000/40000]\n",
            "loss: 3.233508 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.617588 \n",
            "\n",
            "\n",
            "Epoch 37\n",
            "----------------------------\n",
            "loss: 3.325011 [    0/40000]\n",
            "loss: 3.142509 [10000/40000]\n",
            "loss: 3.472936 [20000/40000]\n",
            "loss: 3.348012 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.624722 \n",
            "\n",
            "\n",
            "Epoch 38\n",
            "----------------------------\n",
            "loss: 3.190458 [    0/40000]\n",
            "loss: 3.329111 [10000/40000]\n",
            "loss: 3.187814 [20000/40000]\n",
            "loss: 3.343087 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.7%, Avg loss: 3.622628 \n",
            "\n",
            "\n",
            "Epoch 39\n",
            "----------------------------\n",
            "loss: 3.313960 [    0/40000]\n",
            "loss: 3.185138 [10000/40000]\n",
            "loss: 3.290696 [20000/40000]\n",
            "loss: 3.494497 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.7%, Avg loss: 3.623133 \n",
            "\n",
            "\n",
            "Epoch 40\n",
            "----------------------------\n",
            "loss: 3.262470 [    0/40000]\n",
            "loss: 3.389241 [10000/40000]\n",
            "loss: 3.436305 [20000/40000]\n",
            "loss: 3.247644 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.612501 \n",
            "\n",
            "\n",
            "Epoch 41\n",
            "----------------------------\n",
            "loss: 3.221516 [    0/40000]\n",
            "loss: 3.009100 [10000/40000]\n",
            "loss: 3.037204 [20000/40000]\n",
            "loss: 3.282346 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.606185 \n",
            "\n",
            "\n",
            "Epoch 42\n",
            "----------------------------\n",
            "loss: 2.946715 [    0/40000]\n",
            "loss: 3.189056 [10000/40000]\n",
            "loss: 3.005139 [20000/40000]\n",
            "loss: 3.515666 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.603527 \n",
            "\n",
            "\n",
            "Epoch 43\n",
            "----------------------------\n",
            "loss: 3.374439 [    0/40000]\n",
            "loss: 3.292366 [10000/40000]\n",
            "loss: 3.260993 [20000/40000]\n",
            "loss: 3.449604 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.605515 \n",
            "\n",
            "\n",
            "Epoch 44\n",
            "----------------------------\n",
            "loss: 3.242627 [    0/40000]\n",
            "loss: 3.424178 [10000/40000]\n",
            "loss: 3.407982 [20000/40000]\n",
            "loss: 3.548303 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.604940 \n",
            "\n",
            "\n",
            "Epoch 45\n",
            "----------------------------\n",
            "loss: 3.243378 [    0/40000]\n",
            "loss: 3.615887 [10000/40000]\n",
            "loss: 3.706599 [20000/40000]\n",
            "loss: 3.165993 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.604807 \n",
            "\n",
            "\n",
            "Epoch 46\n",
            "----------------------------\n",
            "loss: 3.125653 [    0/40000]\n",
            "loss: 2.970628 [10000/40000]\n",
            "loss: 3.423277 [20000/40000]\n",
            "loss: 3.405950 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.607182 \n",
            "\n",
            "\n",
            "Epoch 47\n",
            "----------------------------\n",
            "loss: 3.545416 [    0/40000]\n",
            "loss: 3.445135 [10000/40000]\n",
            "loss: 3.211331 [20000/40000]\n",
            "loss: 3.316398 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.607415 \n",
            "\n",
            "\n",
            "Epoch 48\n",
            "----------------------------\n",
            "loss: 3.181695 [    0/40000]\n",
            "loss: 2.901839 [10000/40000]\n",
            "loss: 3.301884 [20000/40000]\n",
            "loss: 3.391324 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.607282 \n",
            "\n",
            "\n",
            "Epoch 49\n",
            "----------------------------\n",
            "loss: 3.165882 [    0/40000]\n",
            "loss: 3.266201 [10000/40000]\n",
            "loss: 3.305050 [20000/40000]\n",
            "loss: 3.433543 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.607966 \n",
            "\n",
            "\n",
            "Epoch 50\n",
            "----------------------------\n",
            "loss: 3.269222 [    0/40000]\n",
            "loss: 3.548389 [10000/40000]\n",
            "loss: 3.563611 [20000/40000]\n",
            "loss: 3.251238 [30000/40000]\n",
            "Validation Error: \n",
            " Accuracy: 3.8%, Avg loss: 3.609227 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5Iif5xCjtx"
      },
      "source": [
        "training_loop(n_epochs, model_2500, train_dataloader, valid_dataloader,\n",
        "              loss_fn, optimizer_2500, scheduler=scheduler_2500, early_stopping=False, patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zG7XJvFJiIZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}