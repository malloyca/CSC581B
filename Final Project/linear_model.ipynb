{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+2JviUNIj7prd1rKgs7KC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malloyca/CSC581B/blob/main/Final%20Project/linear_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwLHFQDMPHFV"
      },
      "source": [
        "# CSC581B - Introduction to Deep Learning for Image Classification\n",
        "# Final Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qROMWFFMPGZZ"
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mWOoFAqRy5c"
      },
      "source": [
        "First we need to load the training and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfml-mHmP4Z7",
        "outputId": "0c072777-46ef-4bcf-9c52-a1b53985c305"
      },
      "source": [
        "# Load the training data (CIFAR10 to start)\n",
        "training_data = datasets.CIFAR10(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = datasets.CIFAR10(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJgFLmWPQ-rU"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoIkbJTtRad9",
        "outputId": "17d129ac-54ef-4c54-b6ea-e1edfb6f5ae7"
      },
      "source": [
        "# Check the data dimensions\n",
        "for X, y in test_dataloader:\n",
        "  print(\"Shape of X batch [Batch size, Channels, Height, Width]: \", X.shape)\n",
        "  print(\"Shape of y batch: \", y.shape, y.dtype)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X batch [Batch size, Channels, Height, Width]:  torch.Size([64, 3, 32, 32])\n",
            "Shape of y batch:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0Hhp8VR-AG"
      },
      "source": [
        "## Building some linear models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h9ROBxpRnuq",
        "outputId": "6d6b1682-f34e-4bb6-8889-7b74545bcd18"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvTQcnbXSPHf"
      },
      "source": [
        "# Define the model\n",
        "class LinearModel(nn.Module):\n",
        "  def __init__(self, n_neurons):\n",
        "    super(LinearModel, self).__init__()\n",
        "    self.name = f'model_{n_neurons}'\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_model = nn.Sequential(\n",
        "        nn.Linear(32*32*3, n_neurons),\n",
        "        nn.Linear(n_neurons, n_neurons),\n",
        "        nn.Linear(n_neurons, 10),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  # Forward propagation function\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear_model(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjdHv7tMcmhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ef5659-d977-4b17-c94e-bd3066d29320"
      },
      "source": [
        "model_100 = LinearModel(n_neurons=100).to(device)\n",
        "print(model_100)\n",
        "\n",
        "model_500 = LinearModel(n_neurons=500).to(device)\n",
        "print(model_500)\n",
        "\n",
        "model_1000 = LinearModel(n_neurons=1000).to(device)\n",
        "print(model_1000)\n",
        "\n",
        "model_5000 = LinearModel(n_neurons=5000).to(device)\n",
        "print(model_5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=100, bias=True)\n",
            "    (1): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=500, bias=True)\n",
            "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
            "    (2): Linear(in_features=500, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=1000, bias=True)\n",
            "    (1): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "    (2): Linear(in_features=1000, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "LinearModel(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_model): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=5000, bias=True)\n",
            "    (1): Linear(in_features=5000, out_features=5000, bias=True)\n",
            "    (2): Linear(in_features=5000, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om2XSgK8TO7i"
      },
      "source": [
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer_100 = torch.optim.SGD(model_100.parameters(), lr=1e-3)\n",
        "optimizer_500 = torch.optim.SGD(model_500.parameters(), lr=1e-2)\n",
        "optimizer_1000 = torch.optim.SGD(model_1000.parameters(), lr=1e-2)\n",
        "optimizer_5000 = torch.optim.SGD(model_5000.parameters(), lr=1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC6gSZZ9TsEo"
      },
      "source": [
        "# Define training loop function\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9joI7v5Ucpm"
      },
      "source": [
        "# Define the test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "  return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPYeNOb1VN65"
      },
      "source": [
        "n_epochs = 250"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQFhFtxVgi7D"
      },
      "source": [
        "def training_loop(n_epochs, model, train_data, test_data, loss_function,\n",
        "                  optimizer, early_stopping=False, patience=10):\n",
        "  current_epoch = 0\n",
        "  best_epoch = 0\n",
        "  best_loss = float('inf')\n",
        "  patience_counter = 0\n",
        "\n",
        "  for e in range(n_epochs):\n",
        "    print()\n",
        "    print(f\"Epoch {e+1}\\n----------------------------\")\n",
        "    train(train_data, model, loss_function, optimizer)\n",
        "    test_loss = test(test_data, model, loss_function)\n",
        "    \n",
        "    # Iterate epoch counter\n",
        "    current_epoch += 1\n",
        "\n",
        "    # Check test_loss for early stopping\n",
        "    if early_stopping:\n",
        "      if test_loss < best_loss:\n",
        "        # store loss\n",
        "        best_loss = test_loss\n",
        "\n",
        "        # reset patience counter\n",
        "        patience_counter = 0\n",
        "\n",
        "        # store model and epoch number\n",
        "        print(\"Storing new best model.\")\n",
        "        best_model_state_dict = copy.deepcopy(model.state_dict())\n",
        "        best_epoch = current_epoch\n",
        "        \n",
        "      # If patience limit not yet reached, iterate patience counter\n",
        "      elif patience_counter < patience - 1:\n",
        "        patience_counter += 1\n",
        "        print(f\"Patience counter: {patience_counter}\")\n",
        "      \n",
        "      # If patience limit reached, store model and break the loop\n",
        "      else:\n",
        "        print(\"Finished due to early stopping.\")\n",
        "        print(f\"Saving best model: {model.name}_epoch-{best_epoch:03d}\")\n",
        "        torch.save(best_model_state_dict, f'{model.name}_epoch-{best_epoch:03d}')\n",
        "        break\n",
        "\n",
        "  # If we get here, we did not stop early - save best model\n",
        "  if early_stopping:\n",
        "    print(f\"Saving best model: {model.name}-epoch:{best_epoch:03d}\")\n",
        "    torch.save(best_model_state_dict, f'{model.name}-epoch:{best_epoch:03d}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlN7IdWWlXCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380281a2-c410-4a2d-cbf1-1fcae8afeb71"
      },
      "source": [
        "training_loop(n_epochs, model_100, train_dataloader, test_dataloader,\n",
        "              loss_fn, optimizer_100, early_stopping=True, patience=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "----------------------------\n",
            "loss: 2.329694 [    0/50000]\n",
            "loss: 2.306764 [ 6400/50000]\n",
            "loss: 2.272973 [12800/50000]\n",
            "loss: 2.285583 [19200/50000]\n",
            "loss: 2.256721 [25600/50000]\n",
            "loss: 2.262734 [32000/50000]\n",
            "loss: 2.273457 [38400/50000]\n",
            "loss: 2.255854 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 19.5%, Avg loss: 2.237885 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 2\n",
            "----------------------------\n",
            "loss: 2.264606 [    0/50000]\n",
            "loss: 2.251604 [ 6400/50000]\n",
            "loss: 2.184141 [12800/50000]\n",
            "loss: 2.244247 [19200/50000]\n",
            "loss: 2.179899 [25600/50000]\n",
            "loss: 2.193682 [32000/50000]\n",
            "loss: 2.232801 [38400/50000]\n",
            "loss: 2.186459 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 22.6%, Avg loss: 2.167875 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 3\n",
            "----------------------------\n",
            "loss: 2.207867 [    0/50000]\n",
            "loss: 2.188828 [ 6400/50000]\n",
            "loss: 2.083544 [12800/50000]\n",
            "loss: 2.196449 [19200/50000]\n",
            "loss: 2.108332 [25600/50000]\n",
            "loss: 2.120863 [32000/50000]\n",
            "loss: 2.200187 [38400/50000]\n",
            "loss: 2.114206 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 25.7%, Avg loss: 2.101939 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 4\n",
            "----------------------------\n",
            "loss: 2.159226 [    0/50000]\n",
            "loss: 2.133517 [ 6400/50000]\n",
            "loss: 1.995990 [12800/50000]\n",
            "loss: 2.149507 [19200/50000]\n",
            "loss: 2.062281 [25600/50000]\n",
            "loss: 2.064165 [32000/50000]\n",
            "loss: 2.176570 [38400/50000]\n",
            "loss: 2.058067 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 2.050638 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 5\n",
            "----------------------------\n",
            "loss: 2.121673 [    0/50000]\n",
            "loss: 2.091896 [ 6400/50000]\n",
            "loss: 1.927447 [12800/50000]\n",
            "loss: 2.107241 [19200/50000]\n",
            "loss: 2.037822 [25600/50000]\n",
            "loss: 2.025573 [32000/50000]\n",
            "loss: 2.151670 [38400/50000]\n",
            "loss: 2.017344 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.4%, Avg loss: 2.010600 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 6\n",
            "----------------------------\n",
            "loss: 2.090361 [    0/50000]\n",
            "loss: 2.059024 [ 6400/50000]\n",
            "loss: 1.870894 [12800/50000]\n",
            "loss: 2.071512 [19200/50000]\n",
            "loss: 2.024094 [25600/50000]\n",
            "loss: 2.000278 [32000/50000]\n",
            "loss: 2.124841 [38400/50000]\n",
            "loss: 1.986947 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 29.9%, Avg loss: 1.979588 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 7\n",
            "----------------------------\n",
            "loss: 2.063406 [    0/50000]\n",
            "loss: 2.032884 [ 6400/50000]\n",
            "loss: 1.824733 [12800/50000]\n",
            "loss: 2.043168 [19200/50000]\n",
            "loss: 2.015581 [25600/50000]\n",
            "loss: 1.983575 [32000/50000]\n",
            "loss: 2.099647 [38400/50000]\n",
            "loss: 1.963193 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 30.6%, Avg loss: 1.955914 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 8\n",
            "----------------------------\n",
            "loss: 2.038975 [    0/50000]\n",
            "loss: 2.012118 [ 6400/50000]\n",
            "loss: 1.787775 [12800/50000]\n",
            "loss: 2.020144 [19200/50000]\n",
            "loss: 2.008917 [25600/50000]\n",
            "loss: 1.970882 [32000/50000]\n",
            "loss: 2.077649 [38400/50000]\n",
            "loss: 1.943524 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 31.3%, Avg loss: 1.937311 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 9\n",
            "----------------------------\n",
            "loss: 2.015300 [    0/50000]\n",
            "loss: 1.994659 [ 6400/50000]\n",
            "loss: 1.757607 [12800/50000]\n",
            "loss: 1.999953 [19200/50000]\n",
            "loss: 2.002101 [25600/50000]\n",
            "loss: 1.959278 [32000/50000]\n",
            "loss: 2.058917 [38400/50000]\n",
            "loss: 1.926457 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 1.922018 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 10\n",
            "----------------------------\n",
            "loss: 1.991900 [    0/50000]\n",
            "loss: 1.978841 [ 6400/50000]\n",
            "loss: 1.732161 [12800/50000]\n",
            "loss: 1.981461 [19200/50000]\n",
            "loss: 1.994482 [25600/50000]\n",
            "loss: 1.947660 [32000/50000]\n",
            "loss: 2.043147 [38400/50000]\n",
            "loss: 1.911180 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 32.6%, Avg loss: 1.908998 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 11\n",
            "----------------------------\n",
            "loss: 1.969165 [    0/50000]\n",
            "loss: 1.963745 [ 6400/50000]\n",
            "loss: 1.710166 [12800/50000]\n",
            "loss: 1.964514 [19200/50000]\n",
            "loss: 1.986162 [25600/50000]\n",
            "loss: 1.935887 [32000/50000]\n",
            "loss: 2.029896 [38400/50000]\n",
            "loss: 1.897166 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 33.1%, Avg loss: 1.897596 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 12\n",
            "----------------------------\n",
            "loss: 1.947537 [    0/50000]\n",
            "loss: 1.948898 [ 6400/50000]\n",
            "loss: 1.690821 [12800/50000]\n",
            "loss: 1.949139 [19200/50000]\n",
            "loss: 1.977445 [25600/50000]\n",
            "loss: 1.924118 [32000/50000]\n",
            "loss: 2.018610 [38400/50000]\n",
            "loss: 1.884029 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 33.6%, Avg loss: 1.887324 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 13\n",
            "----------------------------\n",
            "loss: 1.927216 [    0/50000]\n",
            "loss: 1.934060 [ 6400/50000]\n",
            "loss: 1.673516 [12800/50000]\n",
            "loss: 1.935210 [19200/50000]\n",
            "loss: 1.968604 [25600/50000]\n",
            "loss: 1.912538 [32000/50000]\n",
            "loss: 2.008741 [38400/50000]\n",
            "loss: 1.871508 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.1%, Avg loss: 1.877834 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 14\n",
            "----------------------------\n",
            "loss: 1.908230 [    0/50000]\n",
            "loss: 1.919164 [ 6400/50000]\n",
            "loss: 1.657768 [12800/50000]\n",
            "loss: 1.922462 [19200/50000]\n",
            "loss: 1.959829 [25600/50000]\n",
            "loss: 1.901306 [32000/50000]\n",
            "loss: 1.999856 [38400/50000]\n",
            "loss: 1.859455 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.6%, Avg loss: 1.868906 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 15\n",
            "----------------------------\n",
            "loss: 1.890560 [    0/50000]\n",
            "loss: 1.904283 [ 6400/50000]\n",
            "loss: 1.643220 [12800/50000]\n",
            "loss: 1.910596 [19200/50000]\n",
            "loss: 1.951237 [25600/50000]\n",
            "loss: 1.890558 [32000/50000]\n",
            "loss: 1.991670 [38400/50000]\n",
            "loss: 1.847813 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 1.860431 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 16\n",
            "----------------------------\n",
            "loss: 1.874199 [    0/50000]\n",
            "loss: 1.889584 [ 6400/50000]\n",
            "loss: 1.629636 [12800/50000]\n",
            "loss: 1.899348 [19200/50000]\n",
            "loss: 1.942896 [25600/50000]\n",
            "loss: 1.880414 [32000/50000]\n",
            "loss: 1.984010 [38400/50000]\n",
            "loss: 1.836584 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 1.852370 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 17\n",
            "----------------------------\n",
            "loss: 1.859142 [    0/50000]\n",
            "loss: 1.875268 [ 6400/50000]\n",
            "loss: 1.616885 [12800/50000]\n",
            "loss: 1.888528 [19200/50000]\n",
            "loss: 1.934843 [25600/50000]\n",
            "loss: 1.870971 [32000/50000]\n",
            "loss: 1.976776 [38400/50000]\n",
            "loss: 1.825803 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.3%, Avg loss: 1.844724 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 18\n",
            "----------------------------\n",
            "loss: 1.845369 [    0/50000]\n",
            "loss: 1.861533 [ 6400/50000]\n",
            "loss: 1.604905 [12800/50000]\n",
            "loss: 1.878018 [19200/50000]\n",
            "loss: 1.927094 [25600/50000]\n",
            "loss: 1.862305 [32000/50000]\n",
            "loss: 1.969899 [38400/50000]\n",
            "loss: 1.815518 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.5%, Avg loss: 1.837506 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 19\n",
            "----------------------------\n",
            "loss: 1.832830 [    0/50000]\n",
            "loss: 1.848541 [ 6400/50000]\n",
            "loss: 1.593670 [12800/50000]\n",
            "loss: 1.867767 [19200/50000]\n",
            "loss: 1.919647 [25600/50000]\n",
            "loss: 1.854458 [32000/50000]\n",
            "loss: 1.963327 [38400/50000]\n",
            "loss: 1.805773 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.7%, Avg loss: 1.830726 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 20\n",
            "----------------------------\n",
            "loss: 1.821448 [    0/50000]\n",
            "loss: 1.836406 [ 6400/50000]\n",
            "loss: 1.583172 [12800/50000]\n",
            "loss: 1.857776 [19200/50000]\n",
            "loss: 1.912496 [25600/50000]\n",
            "loss: 1.847441 [32000/50000]\n",
            "loss: 1.957008 [38400/50000]\n",
            "loss: 1.796596 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 1.824385 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 21\n",
            "----------------------------\n",
            "loss: 1.811125 [    0/50000]\n",
            "loss: 1.825186 [ 6400/50000]\n",
            "loss: 1.573399 [12800/50000]\n",
            "loss: 1.848078 [19200/50000]\n",
            "loss: 1.905632 [25600/50000]\n",
            "loss: 1.841233 [32000/50000]\n",
            "loss: 1.950898 [38400/50000]\n",
            "loss: 1.787995 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 1.818472 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 22\n",
            "----------------------------\n",
            "loss: 1.801760 [    0/50000]\n",
            "loss: 1.814890 [ 6400/50000]\n",
            "loss: 1.564335 [12800/50000]\n",
            "loss: 1.838719 [19200/50000]\n",
            "loss: 1.899050 [25600/50000]\n",
            "loss: 1.835789 [32000/50000]\n",
            "loss: 1.944956 [38400/50000]\n",
            "loss: 1.779957 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 1.812966 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 23\n",
            "----------------------------\n",
            "loss: 1.793255 [    0/50000]\n",
            "loss: 1.805492 [ 6400/50000]\n",
            "loss: 1.555956 [12800/50000]\n",
            "loss: 1.829746 [19200/50000]\n",
            "loss: 1.892753 [25600/50000]\n",
            "loss: 1.831049 [32000/50000]\n",
            "loss: 1.939151 [38400/50000]\n",
            "loss: 1.772456 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.6%, Avg loss: 1.807843 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 24\n",
            "----------------------------\n",
            "loss: 1.785524 [    0/50000]\n",
            "loss: 1.796930 [ 6400/50000]\n",
            "loss: 1.548233 [12800/50000]\n",
            "loss: 1.821195 [19200/50000]\n",
            "loss: 1.886750 [25600/50000]\n",
            "loss: 1.826940 [32000/50000]\n",
            "loss: 1.933460 [38400/50000]\n",
            "loss: 1.765450 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 1.803072 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 25\n",
            "----------------------------\n",
            "loss: 1.778494 [    0/50000]\n",
            "loss: 1.789135 [ 6400/50000]\n",
            "loss: 1.541130 [12800/50000]\n",
            "loss: 1.813084 [19200/50000]\n",
            "loss: 1.881058 [25600/50000]\n",
            "loss: 1.823392 [32000/50000]\n",
            "loss: 1.927874 [38400/50000]\n",
            "loss: 1.758900 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 1.798625 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 26\n",
            "----------------------------\n",
            "loss: 1.772103 [    0/50000]\n",
            "loss: 1.782025 [ 6400/50000]\n",
            "loss: 1.534611 [12800/50000]\n",
            "loss: 1.805418 [19200/50000]\n",
            "loss: 1.875695 [25600/50000]\n",
            "loss: 1.820333 [32000/50000]\n",
            "loss: 1.922390 [38400/50000]\n",
            "loss: 1.752764 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.2%, Avg loss: 1.794475 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 27\n",
            "----------------------------\n",
            "loss: 1.766300 [    0/50000]\n",
            "loss: 1.775519 [ 6400/50000]\n",
            "loss: 1.528638 [12800/50000]\n",
            "loss: 1.798182 [19200/50000]\n",
            "loss: 1.870679 [25600/50000]\n",
            "loss: 1.817697 [32000/50000]\n",
            "loss: 1.917016 [38400/50000]\n",
            "loss: 1.747004 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.3%, Avg loss: 1.790596 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 28\n",
            "----------------------------\n",
            "loss: 1.761039 [    0/50000]\n",
            "loss: 1.769542 [ 6400/50000]\n",
            "loss: 1.523175 [12800/50000]\n",
            "loss: 1.791353 [19200/50000]\n",
            "loss: 1.866023 [25600/50000]\n",
            "loss: 1.815420 [32000/50000]\n",
            "loss: 1.911760 [38400/50000]\n",
            "loss: 1.741587 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.4%, Avg loss: 1.786967 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 29\n",
            "----------------------------\n",
            "loss: 1.756277 [    0/50000]\n",
            "loss: 1.764019 [ 6400/50000]\n",
            "loss: 1.518185 [12800/50000]\n",
            "loss: 1.784899 [19200/50000]\n",
            "loss: 1.861733 [25600/50000]\n",
            "loss: 1.813447 [32000/50000]\n",
            "loss: 1.906635 [38400/50000]\n",
            "loss: 1.736485 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.5%, Avg loss: 1.783566 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 30\n",
            "----------------------------\n",
            "loss: 1.751973 [    0/50000]\n",
            "loss: 1.758889 [ 6400/50000]\n",
            "loss: 1.513633 [12800/50000]\n",
            "loss: 1.778783 [19200/50000]\n",
            "loss: 1.857806 [25600/50000]\n",
            "loss: 1.811726 [32000/50000]\n",
            "loss: 1.901654 [38400/50000]\n",
            "loss: 1.731671 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.6%, Avg loss: 1.780376 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 31\n",
            "----------------------------\n",
            "loss: 1.748085 [    0/50000]\n",
            "loss: 1.754093 [ 6400/50000]\n",
            "loss: 1.509483 [12800/50000]\n",
            "loss: 1.772971 [19200/50000]\n",
            "loss: 1.854234 [25600/50000]\n",
            "loss: 1.810210 [32000/50000]\n",
            "loss: 1.896829 [38400/50000]\n",
            "loss: 1.727126 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 1.777379 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 32\n",
            "----------------------------\n",
            "loss: 1.744573 [    0/50000]\n",
            "loss: 1.749582 [ 6400/50000]\n",
            "loss: 1.505701 [12800/50000]\n",
            "loss: 1.767424 [19200/50000]\n",
            "loss: 1.850998 [25600/50000]\n",
            "loss: 1.808860 [32000/50000]\n",
            "loss: 1.892169 [38400/50000]\n",
            "loss: 1.722827 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 37.9%, Avg loss: 1.774559 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 33\n",
            "----------------------------\n",
            "loss: 1.741398 [    0/50000]\n",
            "loss: 1.745314 [ 6400/50000]\n",
            "loss: 1.502257 [12800/50000]\n",
            "loss: 1.762113 [19200/50000]\n",
            "loss: 1.848077 [25600/50000]\n",
            "loss: 1.807639 [32000/50000]\n",
            "loss: 1.887681 [38400/50000]\n",
            "loss: 1.718759 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.1%, Avg loss: 1.771902 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 34\n",
            "----------------------------\n",
            "loss: 1.738520 [    0/50000]\n",
            "loss: 1.741251 [ 6400/50000]\n",
            "loss: 1.499120 [12800/50000]\n",
            "loss: 1.757008 [19200/50000]\n",
            "loss: 1.845447 [25600/50000]\n",
            "loss: 1.806520 [32000/50000]\n",
            "loss: 1.883371 [38400/50000]\n",
            "loss: 1.714904 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.3%, Avg loss: 1.769395 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 35\n",
            "----------------------------\n",
            "loss: 1.735905 [    0/50000]\n",
            "loss: 1.737366 [ 6400/50000]\n",
            "loss: 1.496259 [12800/50000]\n",
            "loss: 1.752087 [19200/50000]\n",
            "loss: 1.843081 [25600/50000]\n",
            "loss: 1.805475 [32000/50000]\n",
            "loss: 1.879241 [38400/50000]\n",
            "loss: 1.711247 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.4%, Avg loss: 1.767026 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 36\n",
            "----------------------------\n",
            "loss: 1.733520 [    0/50000]\n",
            "loss: 1.733632 [ 6400/50000]\n",
            "loss: 1.493649 [12800/50000]\n",
            "loss: 1.747327 [19200/50000]\n",
            "loss: 1.840954 [25600/50000]\n",
            "loss: 1.804488 [32000/50000]\n",
            "loss: 1.875292 [38400/50000]\n",
            "loss: 1.707774 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 1.764784 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 37\n",
            "----------------------------\n",
            "loss: 1.731336 [    0/50000]\n",
            "loss: 1.730031 [ 6400/50000]\n",
            "loss: 1.491264 [12800/50000]\n",
            "loss: 1.742716 [19200/50000]\n",
            "loss: 1.839037 [25600/50000]\n",
            "loss: 1.803542 [32000/50000]\n",
            "loss: 1.871523 [38400/50000]\n",
            "loss: 1.704472 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.6%, Avg loss: 1.762660 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 38\n",
            "----------------------------\n",
            "loss: 1.729329 [    0/50000]\n",
            "loss: 1.726548 [ 6400/50000]\n",
            "loss: 1.489082 [12800/50000]\n",
            "loss: 1.738240 [19200/50000]\n",
            "loss: 1.837307 [25600/50000]\n",
            "loss: 1.802626 [32000/50000]\n",
            "loss: 1.867933 [38400/50000]\n",
            "loss: 1.701330 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.7%, Avg loss: 1.760645 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 39\n",
            "----------------------------\n",
            "loss: 1.727475 [    0/50000]\n",
            "loss: 1.723169 [ 6400/50000]\n",
            "loss: 1.487080 [12800/50000]\n",
            "loss: 1.733889 [19200/50000]\n",
            "loss: 1.835740 [25600/50000]\n",
            "loss: 1.801732 [32000/50000]\n",
            "loss: 1.864516 [38400/50000]\n",
            "loss: 1.698337 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.8%, Avg loss: 1.758731 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 40\n",
            "----------------------------\n",
            "loss: 1.725757 [    0/50000]\n",
            "loss: 1.719886 [ 6400/50000]\n",
            "loss: 1.485239 [12800/50000]\n",
            "loss: 1.729658 [19200/50000]\n",
            "loss: 1.834314 [25600/50000]\n",
            "loss: 1.800855 [32000/50000]\n",
            "loss: 1.861269 [38400/50000]\n",
            "loss: 1.695483 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 38.9%, Avg loss: 1.756912 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 41\n",
            "----------------------------\n",
            "loss: 1.724159 [    0/50000]\n",
            "loss: 1.716692 [ 6400/50000]\n",
            "loss: 1.483543 [12800/50000]\n",
            "loss: 1.725539 [19200/50000]\n",
            "loss: 1.833011 [25600/50000]\n",
            "loss: 1.799991 [32000/50000]\n",
            "loss: 1.858186 [38400/50000]\n",
            "loss: 1.692761 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.0%, Avg loss: 1.755182 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 42\n",
            "----------------------------\n",
            "loss: 1.722669 [    0/50000]\n",
            "loss: 1.713582 [ 6400/50000]\n",
            "loss: 1.481975 [12800/50000]\n",
            "loss: 1.721530 [19200/50000]\n",
            "loss: 1.831812 [25600/50000]\n",
            "loss: 1.799139 [32000/50000]\n",
            "loss: 1.855261 [38400/50000]\n",
            "loss: 1.690161 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.1%, Avg loss: 1.753534 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 43\n",
            "----------------------------\n",
            "loss: 1.721276 [    0/50000]\n",
            "loss: 1.710550 [ 6400/50000]\n",
            "loss: 1.480521 [12800/50000]\n",
            "loss: 1.717628 [19200/50000]\n",
            "loss: 1.830701 [25600/50000]\n",
            "loss: 1.798299 [32000/50000]\n",
            "loss: 1.852489 [38400/50000]\n",
            "loss: 1.687678 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.1%, Avg loss: 1.751965 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 44\n",
            "----------------------------\n",
            "loss: 1.719973 [    0/50000]\n",
            "loss: 1.707595 [ 6400/50000]\n",
            "loss: 1.479169 [12800/50000]\n",
            "loss: 1.713830 [19200/50000]\n",
            "loss: 1.829666 [25600/50000]\n",
            "loss: 1.797470 [32000/50000]\n",
            "loss: 1.849862 [38400/50000]\n",
            "loss: 1.685303 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.2%, Avg loss: 1.750470 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 45\n",
            "----------------------------\n",
            "loss: 1.718751 [    0/50000]\n",
            "loss: 1.704713 [ 6400/50000]\n",
            "loss: 1.477908 [12800/50000]\n",
            "loss: 1.710135 [19200/50000]\n",
            "loss: 1.828692 [25600/50000]\n",
            "loss: 1.796652 [32000/50000]\n",
            "loss: 1.847375 [38400/50000]\n",
            "loss: 1.683032 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.3%, Avg loss: 1.749044 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 46\n",
            "----------------------------\n",
            "loss: 1.717606 [    0/50000]\n",
            "loss: 1.701904 [ 6400/50000]\n",
            "loss: 1.476729 [12800/50000]\n",
            "loss: 1.706541 [19200/50000]\n",
            "loss: 1.827770 [25600/50000]\n",
            "loss: 1.795846 [32000/50000]\n",
            "loss: 1.845019 [38400/50000]\n",
            "loss: 1.680858 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.3%, Avg loss: 1.747685 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 47\n",
            "----------------------------\n",
            "loss: 1.716533 [    0/50000]\n",
            "loss: 1.699166 [ 6400/50000]\n",
            "loss: 1.475622 [12800/50000]\n",
            "loss: 1.703046 [19200/50000]\n",
            "loss: 1.826890 [25600/50000]\n",
            "loss: 1.795055 [32000/50000]\n",
            "loss: 1.842789 [38400/50000]\n",
            "loss: 1.678775 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.4%, Avg loss: 1.746389 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 48\n",
            "----------------------------\n",
            "loss: 1.715528 [    0/50000]\n",
            "loss: 1.696498 [ 6400/50000]\n",
            "loss: 1.474582 [12800/50000]\n",
            "loss: 1.699650 [19200/50000]\n",
            "loss: 1.826045 [25600/50000]\n",
            "loss: 1.794277 [32000/50000]\n",
            "loss: 1.840679 [38400/50000]\n",
            "loss: 1.676781 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.4%, Avg loss: 1.745153 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 49\n",
            "----------------------------\n",
            "loss: 1.714586 [    0/50000]\n",
            "loss: 1.693899 [ 6400/50000]\n",
            "loss: 1.473600 [12800/50000]\n",
            "loss: 1.696350 [19200/50000]\n",
            "loss: 1.825226 [25600/50000]\n",
            "loss: 1.793514 [32000/50000]\n",
            "loss: 1.838681 [38400/50000]\n",
            "loss: 1.674867 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.5%, Avg loss: 1.743973 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 50\n",
            "----------------------------\n",
            "loss: 1.713707 [    0/50000]\n",
            "loss: 1.691368 [ 6400/50000]\n",
            "loss: 1.472673 [12800/50000]\n",
            "loss: 1.693146 [19200/50000]\n",
            "loss: 1.824430 [25600/50000]\n",
            "loss: 1.792766 [32000/50000]\n",
            "loss: 1.836790 [38400/50000]\n",
            "loss: 1.673032 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.6%, Avg loss: 1.742848 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 51\n",
            "----------------------------\n",
            "loss: 1.712885 [    0/50000]\n",
            "loss: 1.688905 [ 6400/50000]\n",
            "loss: 1.471794 [12800/50000]\n",
            "loss: 1.690035 [19200/50000]\n",
            "loss: 1.823650 [25600/50000]\n",
            "loss: 1.792033 [32000/50000]\n",
            "loss: 1.835000 [38400/50000]\n",
            "loss: 1.671269 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.7%, Avg loss: 1.741774 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 52\n",
            "----------------------------\n",
            "loss: 1.712117 [    0/50000]\n",
            "loss: 1.686509 [ 6400/50000]\n",
            "loss: 1.470960 [12800/50000]\n",
            "loss: 1.687015 [19200/50000]\n",
            "loss: 1.822883 [25600/50000]\n",
            "loss: 1.791315 [32000/50000]\n",
            "loss: 1.833304 [38400/50000]\n",
            "loss: 1.669576 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.7%, Avg loss: 1.740750 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 53\n",
            "----------------------------\n",
            "loss: 1.711402 [    0/50000]\n",
            "loss: 1.684178 [ 6400/50000]\n",
            "loss: 1.470168 [12800/50000]\n",
            "loss: 1.684085 [19200/50000]\n",
            "loss: 1.822126 [25600/50000]\n",
            "loss: 1.790612 [32000/50000]\n",
            "loss: 1.831698 [38400/50000]\n",
            "loss: 1.667946 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 1.739772 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 54\n",
            "----------------------------\n",
            "loss: 1.710737 [    0/50000]\n",
            "loss: 1.681913 [ 6400/50000]\n",
            "loss: 1.469415 [12800/50000]\n",
            "loss: 1.681241 [19200/50000]\n",
            "loss: 1.821376 [25600/50000]\n",
            "loss: 1.789925 [32000/50000]\n",
            "loss: 1.830176 [38400/50000]\n",
            "loss: 1.666379 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 1.738838 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 55\n",
            "----------------------------\n",
            "loss: 1.710119 [    0/50000]\n",
            "loss: 1.679710 [ 6400/50000]\n",
            "loss: 1.468698 [12800/50000]\n",
            "loss: 1.678483 [19200/50000]\n",
            "loss: 1.820631 [25600/50000]\n",
            "loss: 1.789252 [32000/50000]\n",
            "loss: 1.828733 [38400/50000]\n",
            "loss: 1.664868 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 1.737946 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 56\n",
            "----------------------------\n",
            "loss: 1.709545 [    0/50000]\n",
            "loss: 1.677570 [ 6400/50000]\n",
            "loss: 1.468015 [12800/50000]\n",
            "loss: 1.675807 [19200/50000]\n",
            "loss: 1.819891 [25600/50000]\n",
            "loss: 1.788592 [32000/50000]\n",
            "loss: 1.827365 [38400/50000]\n",
            "loss: 1.663412 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.7%, Avg loss: 1.737094 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 57\n",
            "----------------------------\n",
            "loss: 1.709012 [    0/50000]\n",
            "loss: 1.675491 [ 6400/50000]\n",
            "loss: 1.467363 [12800/50000]\n",
            "loss: 1.673210 [19200/50000]\n",
            "loss: 1.819152 [25600/50000]\n",
            "loss: 1.787946 [32000/50000]\n",
            "loss: 1.826066 [38400/50000]\n",
            "loss: 1.662006 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 1.736280 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 58\n",
            "----------------------------\n",
            "loss: 1.708518 [    0/50000]\n",
            "loss: 1.673471 [ 6400/50000]\n",
            "loss: 1.466742 [12800/50000]\n",
            "loss: 1.670689 [19200/50000]\n",
            "loss: 1.818415 [25600/50000]\n",
            "loss: 1.787312 [32000/50000]\n",
            "loss: 1.824834 [38400/50000]\n",
            "loss: 1.660648 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 1.735502 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 59\n",
            "----------------------------\n",
            "loss: 1.708058 [    0/50000]\n",
            "loss: 1.671510 [ 6400/50000]\n",
            "loss: 1.466151 [12800/50000]\n",
            "loss: 1.668244 [19200/50000]\n",
            "loss: 1.817680 [25600/50000]\n",
            "loss: 1.786690 [32000/50000]\n",
            "loss: 1.823663 [38400/50000]\n",
            "loss: 1.659335 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 1.734757 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 60\n",
            "----------------------------\n",
            "loss: 1.707633 [    0/50000]\n",
            "loss: 1.669604 [ 6400/50000]\n",
            "loss: 1.465587 [12800/50000]\n",
            "loss: 1.665869 [19200/50000]\n",
            "loss: 1.816946 [25600/50000]\n",
            "loss: 1.786079 [32000/50000]\n",
            "loss: 1.822552 [38400/50000]\n",
            "loss: 1.658064 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 1.734044 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 61\n",
            "----------------------------\n",
            "loss: 1.707238 [    0/50000]\n",
            "loss: 1.667753 [ 6400/50000]\n",
            "loss: 1.465051 [12800/50000]\n",
            "loss: 1.663562 [19200/50000]\n",
            "loss: 1.816212 [25600/50000]\n",
            "loss: 1.785478 [32000/50000]\n",
            "loss: 1.821495 [38400/50000]\n",
            "loss: 1.656833 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 39.9%, Avg loss: 1.733362 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 62\n",
            "----------------------------\n",
            "loss: 1.706872 [    0/50000]\n",
            "loss: 1.665955 [ 6400/50000]\n",
            "loss: 1.464541 [12800/50000]\n",
            "loss: 1.661321 [19200/50000]\n",
            "loss: 1.815480 [25600/50000]\n",
            "loss: 1.784887 [32000/50000]\n",
            "loss: 1.820490 [38400/50000]\n",
            "loss: 1.655639 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.0%, Avg loss: 1.732707 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 63\n",
            "----------------------------\n",
            "loss: 1.706532 [    0/50000]\n",
            "loss: 1.664207 [ 6400/50000]\n",
            "loss: 1.464056 [12800/50000]\n",
            "loss: 1.659142 [19200/50000]\n",
            "loss: 1.814749 [25600/50000]\n",
            "loss: 1.784306 [32000/50000]\n",
            "loss: 1.819535 [38400/50000]\n",
            "loss: 1.654480 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.1%, Avg loss: 1.732080 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 64\n",
            "----------------------------\n",
            "loss: 1.706215 [    0/50000]\n",
            "loss: 1.662508 [ 6400/50000]\n",
            "loss: 1.463596 [12800/50000]\n",
            "loss: 1.657023 [19200/50000]\n",
            "loss: 1.814019 [25600/50000]\n",
            "loss: 1.783733 [32000/50000]\n",
            "loss: 1.818625 [38400/50000]\n",
            "loss: 1.653354 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.1%, Avg loss: 1.731477 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 65\n",
            "----------------------------\n",
            "loss: 1.705919 [    0/50000]\n",
            "loss: 1.660856 [ 6400/50000]\n",
            "loss: 1.463159 [12800/50000]\n",
            "loss: 1.654961 [19200/50000]\n",
            "loss: 1.813293 [25600/50000]\n",
            "loss: 1.783167 [32000/50000]\n",
            "loss: 1.817760 [38400/50000]\n",
            "loss: 1.652259 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.1%, Avg loss: 1.730898 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 66\n",
            "----------------------------\n",
            "loss: 1.705642 [    0/50000]\n",
            "loss: 1.659249 [ 6400/50000]\n",
            "loss: 1.462747 [12800/50000]\n",
            "loss: 1.652953 [19200/50000]\n",
            "loss: 1.812568 [25600/50000]\n",
            "loss: 1.782609 [32000/50000]\n",
            "loss: 1.816936 [38400/50000]\n",
            "loss: 1.651195 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.1%, Avg loss: 1.730342 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 67\n",
            "----------------------------\n",
            "loss: 1.705382 [    0/50000]\n",
            "loss: 1.657686 [ 6400/50000]\n",
            "loss: 1.462357 [12800/50000]\n",
            "loss: 1.650995 [19200/50000]\n",
            "loss: 1.811847 [25600/50000]\n",
            "loss: 1.782058 [32000/50000]\n",
            "loss: 1.816152 [38400/50000]\n",
            "loss: 1.650157 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.1%, Avg loss: 1.729806 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 68\n",
            "----------------------------\n",
            "loss: 1.705139 [    0/50000]\n",
            "loss: 1.656165 [ 6400/50000]\n",
            "loss: 1.461989 [12800/50000]\n",
            "loss: 1.649088 [19200/50000]\n",
            "loss: 1.811130 [25600/50000]\n",
            "loss: 1.781513 [32000/50000]\n",
            "loss: 1.815405 [38400/50000]\n",
            "loss: 1.649146 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.729290 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 69\n",
            "----------------------------\n",
            "loss: 1.704908 [    0/50000]\n",
            "loss: 1.654684 [ 6400/50000]\n",
            "loss: 1.461643 [12800/50000]\n",
            "loss: 1.647226 [19200/50000]\n",
            "loss: 1.810417 [25600/50000]\n",
            "loss: 1.780975 [32000/50000]\n",
            "loss: 1.814694 [38400/50000]\n",
            "loss: 1.648160 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.728793 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 70\n",
            "----------------------------\n",
            "loss: 1.704690 [    0/50000]\n",
            "loss: 1.653241 [ 6400/50000]\n",
            "loss: 1.461318 [12800/50000]\n",
            "loss: 1.645408 [19200/50000]\n",
            "loss: 1.809710 [25600/50000]\n",
            "loss: 1.780442 [32000/50000]\n",
            "loss: 1.814017 [38400/50000]\n",
            "loss: 1.647198 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.728314 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 71\n",
            "----------------------------\n",
            "loss: 1.704483 [    0/50000]\n",
            "loss: 1.651834 [ 6400/50000]\n",
            "loss: 1.461013 [12800/50000]\n",
            "loss: 1.643632 [19200/50000]\n",
            "loss: 1.809010 [25600/50000]\n",
            "loss: 1.779915 [32000/50000]\n",
            "loss: 1.813373 [38400/50000]\n",
            "loss: 1.646258 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.727852 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 72\n",
            "----------------------------\n",
            "loss: 1.704285 [    0/50000]\n",
            "loss: 1.650464 [ 6400/50000]\n",
            "loss: 1.460729 [12800/50000]\n",
            "loss: 1.641896 [19200/50000]\n",
            "loss: 1.808315 [25600/50000]\n",
            "loss: 1.779394 [32000/50000]\n",
            "loss: 1.812759 [38400/50000]\n",
            "loss: 1.645339 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.727405 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 73\n",
            "----------------------------\n",
            "loss: 1.704096 [    0/50000]\n",
            "loss: 1.649127 [ 6400/50000]\n",
            "loss: 1.460464 [12800/50000]\n",
            "loss: 1.640197 [19200/50000]\n",
            "loss: 1.807628 [25600/50000]\n",
            "loss: 1.778877 [32000/50000]\n",
            "loss: 1.812176 [38400/50000]\n",
            "loss: 1.644441 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.1%, Avg loss: 1.726973 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 74\n",
            "----------------------------\n",
            "loss: 1.703913 [    0/50000]\n",
            "loss: 1.647822 [ 6400/50000]\n",
            "loss: 1.460219 [12800/50000]\n",
            "loss: 1.638533 [19200/50000]\n",
            "loss: 1.806948 [25600/50000]\n",
            "loss: 1.778366 [32000/50000]\n",
            "loss: 1.811620 [38400/50000]\n",
            "loss: 1.643562 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.1%, Avg loss: 1.726556 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 75\n",
            "----------------------------\n",
            "loss: 1.703737 [    0/50000]\n",
            "loss: 1.646550 [ 6400/50000]\n",
            "loss: 1.459991 [12800/50000]\n",
            "loss: 1.636903 [19200/50000]\n",
            "loss: 1.806278 [25600/50000]\n",
            "loss: 1.777858 [32000/50000]\n",
            "loss: 1.811092 [38400/50000]\n",
            "loss: 1.642701 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.726152 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 76\n",
            "----------------------------\n",
            "loss: 1.703566 [    0/50000]\n",
            "loss: 1.645307 [ 6400/50000]\n",
            "loss: 1.459782 [12800/50000]\n",
            "loss: 1.635304 [19200/50000]\n",
            "loss: 1.805616 [25600/50000]\n",
            "loss: 1.777356 [32000/50000]\n",
            "loss: 1.810591 [38400/50000]\n",
            "loss: 1.641858 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.725762 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 77\n",
            "----------------------------\n",
            "loss: 1.703398 [    0/50000]\n",
            "loss: 1.644093 [ 6400/50000]\n",
            "loss: 1.459590 [12800/50000]\n",
            "loss: 1.633737 [19200/50000]\n",
            "loss: 1.804964 [25600/50000]\n",
            "loss: 1.776857 [32000/50000]\n",
            "loss: 1.810115 [38400/50000]\n",
            "loss: 1.641031 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.725383 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 78\n",
            "----------------------------\n",
            "loss: 1.703235 [    0/50000]\n",
            "loss: 1.642907 [ 6400/50000]\n",
            "loss: 1.459415 [12800/50000]\n",
            "loss: 1.632198 [19200/50000]\n",
            "loss: 1.804322 [25600/50000]\n",
            "loss: 1.776364 [32000/50000]\n",
            "loss: 1.809665 [38400/50000]\n",
            "loss: 1.640221 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.725017 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 79\n",
            "----------------------------\n",
            "loss: 1.703075 [    0/50000]\n",
            "loss: 1.641748 [ 6400/50000]\n",
            "loss: 1.459255 [12800/50000]\n",
            "loss: 1.630686 [19200/50000]\n",
            "loss: 1.803691 [25600/50000]\n",
            "loss: 1.775874 [32000/50000]\n",
            "loss: 1.809237 [38400/50000]\n",
            "loss: 1.639425 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.724662 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 80\n",
            "----------------------------\n",
            "loss: 1.702917 [    0/50000]\n",
            "loss: 1.640615 [ 6400/50000]\n",
            "loss: 1.459112 [12800/50000]\n",
            "loss: 1.629200 [19200/50000]\n",
            "loss: 1.803071 [25600/50000]\n",
            "loss: 1.775388 [32000/50000]\n",
            "loss: 1.808833 [38400/50000]\n",
            "loss: 1.638644 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 1.724318 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 81\n",
            "----------------------------\n",
            "loss: 1.702760 [    0/50000]\n",
            "loss: 1.639508 [ 6400/50000]\n",
            "loss: 1.458984 [12800/50000]\n",
            "loss: 1.627739 [19200/50000]\n",
            "loss: 1.802463 [25600/50000]\n",
            "loss: 1.774906 [32000/50000]\n",
            "loss: 1.808451 [38400/50000]\n",
            "loss: 1.637877 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 1.723984 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 82\n",
            "----------------------------\n",
            "loss: 1.702605 [    0/50000]\n",
            "loss: 1.638424 [ 6400/50000]\n",
            "loss: 1.458871 [12800/50000]\n",
            "loss: 1.626302 [19200/50000]\n",
            "loss: 1.801866 [25600/50000]\n",
            "loss: 1.774429 [32000/50000]\n",
            "loss: 1.808091 [38400/50000]\n",
            "loss: 1.637124 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 1.723661 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 83\n",
            "----------------------------\n",
            "loss: 1.702451 [    0/50000]\n",
            "loss: 1.637364 [ 6400/50000]\n",
            "loss: 1.458771 [12800/50000]\n",
            "loss: 1.624888 [19200/50000]\n",
            "loss: 1.801283 [25600/50000]\n",
            "loss: 1.773955 [32000/50000]\n",
            "loss: 1.807751 [38400/50000]\n",
            "loss: 1.636383 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 1.723348 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 84\n",
            "----------------------------\n",
            "loss: 1.702297 [    0/50000]\n",
            "loss: 1.636328 [ 6400/50000]\n",
            "loss: 1.458686 [12800/50000]\n",
            "loss: 1.623495 [19200/50000]\n",
            "loss: 1.800711 [25600/50000]\n",
            "loss: 1.773484 [32000/50000]\n",
            "loss: 1.807433 [38400/50000]\n",
            "loss: 1.635655 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 1.723044 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 85\n",
            "----------------------------\n",
            "loss: 1.702144 [    0/50000]\n",
            "loss: 1.635313 [ 6400/50000]\n",
            "loss: 1.458613 [12800/50000]\n",
            "loss: 1.622123 [19200/50000]\n",
            "loss: 1.800153 [25600/50000]\n",
            "loss: 1.773017 [32000/50000]\n",
            "loss: 1.807134 [38400/50000]\n",
            "loss: 1.634938 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 1.722749 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 86\n",
            "----------------------------\n",
            "loss: 1.701991 [    0/50000]\n",
            "loss: 1.634321 [ 6400/50000]\n",
            "loss: 1.458553 [12800/50000]\n",
            "loss: 1.620770 [19200/50000]\n",
            "loss: 1.799608 [25600/50000]\n",
            "loss: 1.772554 [32000/50000]\n",
            "loss: 1.806855 [38400/50000]\n",
            "loss: 1.634234 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.722464 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 87\n",
            "----------------------------\n",
            "loss: 1.701837 [    0/50000]\n",
            "loss: 1.633349 [ 6400/50000]\n",
            "loss: 1.458505 [12800/50000]\n",
            "loss: 1.619438 [19200/50000]\n",
            "loss: 1.799077 [25600/50000]\n",
            "loss: 1.772094 [32000/50000]\n",
            "loss: 1.806594 [38400/50000]\n",
            "loss: 1.633539 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.722187 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 88\n",
            "----------------------------\n",
            "loss: 1.701683 [    0/50000]\n",
            "loss: 1.632397 [ 6400/50000]\n",
            "loss: 1.458469 [12800/50000]\n",
            "loss: 1.618123 [19200/50000]\n",
            "loss: 1.798559 [25600/50000]\n",
            "loss: 1.771637 [32000/50000]\n",
            "loss: 1.806353 [38400/50000]\n",
            "loss: 1.632856 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.721919 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 89\n",
            "----------------------------\n",
            "loss: 1.701527 [    0/50000]\n",
            "loss: 1.631466 [ 6400/50000]\n",
            "loss: 1.458443 [12800/50000]\n",
            "loss: 1.616826 [19200/50000]\n",
            "loss: 1.798054 [25600/50000]\n",
            "loss: 1.771184 [32000/50000]\n",
            "loss: 1.806129 [38400/50000]\n",
            "loss: 1.632183 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.721659 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 90\n",
            "----------------------------\n",
            "loss: 1.701372 [    0/50000]\n",
            "loss: 1.630555 [ 6400/50000]\n",
            "loss: 1.458428 [12800/50000]\n",
            "loss: 1.615547 [19200/50000]\n",
            "loss: 1.797564 [25600/50000]\n",
            "loss: 1.770734 [32000/50000]\n",
            "loss: 1.805923 [38400/50000]\n",
            "loss: 1.631519 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.721408 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 91\n",
            "----------------------------\n",
            "loss: 1.701215 [    0/50000]\n",
            "loss: 1.629662 [ 6400/50000]\n",
            "loss: 1.458423 [12800/50000]\n",
            "loss: 1.614285 [19200/50000]\n",
            "loss: 1.797088 [25600/50000]\n",
            "loss: 1.770286 [32000/50000]\n",
            "loss: 1.805735 [38400/50000]\n",
            "loss: 1.630865 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.721164 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 92\n",
            "----------------------------\n",
            "loss: 1.701057 [    0/50000]\n",
            "loss: 1.628788 [ 6400/50000]\n",
            "loss: 1.458428 [12800/50000]\n",
            "loss: 1.613038 [19200/50000]\n",
            "loss: 1.796626 [25600/50000]\n",
            "loss: 1.769841 [32000/50000]\n",
            "loss: 1.805563 [38400/50000]\n",
            "loss: 1.630221 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 1.720928 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 93\n",
            "----------------------------\n",
            "loss: 1.700897 [    0/50000]\n",
            "loss: 1.627933 [ 6400/50000]\n",
            "loss: 1.458441 [12800/50000]\n",
            "loss: 1.611808 [19200/50000]\n",
            "loss: 1.796178 [25600/50000]\n",
            "loss: 1.769400 [32000/50000]\n",
            "loss: 1.805408 [38400/50000]\n",
            "loss: 1.629585 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.720700 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 94\n",
            "----------------------------\n",
            "loss: 1.700736 [    0/50000]\n",
            "loss: 1.627095 [ 6400/50000]\n",
            "loss: 1.458465 [12800/50000]\n",
            "loss: 1.610592 [19200/50000]\n",
            "loss: 1.795743 [25600/50000]\n",
            "loss: 1.768961 [32000/50000]\n",
            "loss: 1.805269 [38400/50000]\n",
            "loss: 1.628958 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.720480 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 95\n",
            "----------------------------\n",
            "loss: 1.700574 [    0/50000]\n",
            "loss: 1.626274 [ 6400/50000]\n",
            "loss: 1.458495 [12800/50000]\n",
            "loss: 1.609392 [19200/50000]\n",
            "loss: 1.795324 [25600/50000]\n",
            "loss: 1.768524 [32000/50000]\n",
            "loss: 1.805146 [38400/50000]\n",
            "loss: 1.628339 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 1.720267 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 96\n",
            "----------------------------\n",
            "loss: 1.700410 [    0/50000]\n",
            "loss: 1.625470 [ 6400/50000]\n",
            "loss: 1.458535 [12800/50000]\n",
            "loss: 1.608206 [19200/50000]\n",
            "loss: 1.794917 [25600/50000]\n",
            "loss: 1.768090 [32000/50000]\n",
            "loss: 1.805039 [38400/50000]\n",
            "loss: 1.627729 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.720061 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 97\n",
            "----------------------------\n",
            "loss: 1.700245 [    0/50000]\n",
            "loss: 1.624683 [ 6400/50000]\n",
            "loss: 1.458582 [12800/50000]\n",
            "loss: 1.607035 [19200/50000]\n",
            "loss: 1.794525 [25600/50000]\n",
            "loss: 1.767659 [32000/50000]\n",
            "loss: 1.804947 [38400/50000]\n",
            "loss: 1.627127 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.719863 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 98\n",
            "----------------------------\n",
            "loss: 1.700077 [    0/50000]\n",
            "loss: 1.623912 [ 6400/50000]\n",
            "loss: 1.458636 [12800/50000]\n",
            "loss: 1.605877 [19200/50000]\n",
            "loss: 1.794146 [25600/50000]\n",
            "loss: 1.767229 [32000/50000]\n",
            "loss: 1.804870 [38400/50000]\n",
            "loss: 1.626532 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.719671 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 99\n",
            "----------------------------\n",
            "loss: 1.699908 [    0/50000]\n",
            "loss: 1.623157 [ 6400/50000]\n",
            "loss: 1.458697 [12800/50000]\n",
            "loss: 1.604733 [19200/50000]\n",
            "loss: 1.793781 [25600/50000]\n",
            "loss: 1.766802 [32000/50000]\n",
            "loss: 1.804807 [38400/50000]\n",
            "loss: 1.625945 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.719487 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 100\n",
            "----------------------------\n",
            "loss: 1.699737 [    0/50000]\n",
            "loss: 1.622417 [ 6400/50000]\n",
            "loss: 1.458764 [12800/50000]\n",
            "loss: 1.603603 [19200/50000]\n",
            "loss: 1.793429 [25600/50000]\n",
            "loss: 1.766377 [32000/50000]\n",
            "loss: 1.804759 [38400/50000]\n",
            "loss: 1.625366 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.719309 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 101\n",
            "----------------------------\n",
            "loss: 1.699565 [    0/50000]\n",
            "loss: 1.621693 [ 6400/50000]\n",
            "loss: 1.458838 [12800/50000]\n",
            "loss: 1.602486 [19200/50000]\n",
            "loss: 1.793090 [25600/50000]\n",
            "loss: 1.765953 [32000/50000]\n",
            "loss: 1.804724 [38400/50000]\n",
            "loss: 1.624794 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.5%, Avg loss: 1.719138 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 102\n",
            "----------------------------\n",
            "loss: 1.699389 [    0/50000]\n",
            "loss: 1.620982 [ 6400/50000]\n",
            "loss: 1.458917 [12800/50000]\n",
            "loss: 1.601382 [19200/50000]\n",
            "loss: 1.792764 [25600/50000]\n",
            "loss: 1.765532 [32000/50000]\n",
            "loss: 1.804703 [38400/50000]\n",
            "loss: 1.624229 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.5%, Avg loss: 1.718974 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 103\n",
            "----------------------------\n",
            "loss: 1.699213 [    0/50000]\n",
            "loss: 1.620286 [ 6400/50000]\n",
            "loss: 1.459002 [12800/50000]\n",
            "loss: 1.600290 [19200/50000]\n",
            "loss: 1.792451 [25600/50000]\n",
            "loss: 1.765112 [32000/50000]\n",
            "loss: 1.804696 [38400/50000]\n",
            "loss: 1.623672 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.5%, Avg loss: 1.718816 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 104\n",
            "----------------------------\n",
            "loss: 1.699034 [    0/50000]\n",
            "loss: 1.619604 [ 6400/50000]\n",
            "loss: 1.459092 [12800/50000]\n",
            "loss: 1.599212 [19200/50000]\n",
            "loss: 1.792150 [25600/50000]\n",
            "loss: 1.764694 [32000/50000]\n",
            "loss: 1.804701 [38400/50000]\n",
            "loss: 1.623121 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.5%, Avg loss: 1.718665 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 105\n",
            "----------------------------\n",
            "loss: 1.698853 [    0/50000]\n",
            "loss: 1.618935 [ 6400/50000]\n",
            "loss: 1.459187 [12800/50000]\n",
            "loss: 1.598145 [19200/50000]\n",
            "loss: 1.791861 [25600/50000]\n",
            "loss: 1.764277 [32000/50000]\n",
            "loss: 1.804718 [38400/50000]\n",
            "loss: 1.622577 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.5%, Avg loss: 1.718520 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 106\n",
            "----------------------------\n",
            "loss: 1.698671 [    0/50000]\n",
            "loss: 1.618279 [ 6400/50000]\n",
            "loss: 1.459286 [12800/50000]\n",
            "loss: 1.597091 [19200/50000]\n",
            "loss: 1.791585 [25600/50000]\n",
            "loss: 1.763862 [32000/50000]\n",
            "loss: 1.804749 [38400/50000]\n",
            "loss: 1.622039 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.718381 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 107\n",
            "----------------------------\n",
            "loss: 1.698485 [    0/50000]\n",
            "loss: 1.617637 [ 6400/50000]\n",
            "loss: 1.459389 [12800/50000]\n",
            "loss: 1.596049 [19200/50000]\n",
            "loss: 1.791319 [25600/50000]\n",
            "loss: 1.763448 [32000/50000]\n",
            "loss: 1.804791 [38400/50000]\n",
            "loss: 1.621509 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.718249 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 108\n",
            "----------------------------\n",
            "loss: 1.698299 [    0/50000]\n",
            "loss: 1.617007 [ 6400/50000]\n",
            "loss: 1.459497 [12800/50000]\n",
            "loss: 1.595019 [19200/50000]\n",
            "loss: 1.791066 [25600/50000]\n",
            "loss: 1.763035 [32000/50000]\n",
            "loss: 1.804844 [38400/50000]\n",
            "loss: 1.620985 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.718122 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 109\n",
            "----------------------------\n",
            "loss: 1.698109 [    0/50000]\n",
            "loss: 1.616388 [ 6400/50000]\n",
            "loss: 1.459608 [12800/50000]\n",
            "loss: 1.594001 [19200/50000]\n",
            "loss: 1.790823 [25600/50000]\n",
            "loss: 1.762623 [32000/50000]\n",
            "loss: 1.804909 [38400/50000]\n",
            "loss: 1.620467 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.718002 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 110\n",
            "----------------------------\n",
            "loss: 1.697918 [    0/50000]\n",
            "loss: 1.615781 [ 6400/50000]\n",
            "loss: 1.459723 [12800/50000]\n",
            "loss: 1.592994 [19200/50000]\n",
            "loss: 1.790590 [25600/50000]\n",
            "loss: 1.762212 [32000/50000]\n",
            "loss: 1.804985 [38400/50000]\n",
            "loss: 1.619956 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.717888 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 111\n",
            "----------------------------\n",
            "loss: 1.697724 [    0/50000]\n",
            "loss: 1.615185 [ 6400/50000]\n",
            "loss: 1.459840 [12800/50000]\n",
            "loss: 1.592000 [19200/50000]\n",
            "loss: 1.790368 [25600/50000]\n",
            "loss: 1.761802 [32000/50000]\n",
            "loss: 1.805072 [38400/50000]\n",
            "loss: 1.619450 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.717779 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 112\n",
            "----------------------------\n",
            "loss: 1.697527 [    0/50000]\n",
            "loss: 1.614600 [ 6400/50000]\n",
            "loss: 1.459961 [12800/50000]\n",
            "loss: 1.591015 [19200/50000]\n",
            "loss: 1.790155 [25600/50000]\n",
            "loss: 1.761393 [32000/50000]\n",
            "loss: 1.805169 [38400/50000]\n",
            "loss: 1.618952 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.717676 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 113\n",
            "----------------------------\n",
            "loss: 1.697329 [    0/50000]\n",
            "loss: 1.614026 [ 6400/50000]\n",
            "loss: 1.460084 [12800/50000]\n",
            "loss: 1.590043 [19200/50000]\n",
            "loss: 1.789953 [25600/50000]\n",
            "loss: 1.760985 [32000/50000]\n",
            "loss: 1.805275 [38400/50000]\n",
            "loss: 1.618459 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.717579 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 114\n",
            "----------------------------\n",
            "loss: 1.697128 [    0/50000]\n",
            "loss: 1.613462 [ 6400/50000]\n",
            "loss: 1.460209 [12800/50000]\n",
            "loss: 1.589082 [19200/50000]\n",
            "loss: 1.789759 [25600/50000]\n",
            "loss: 1.760577 [32000/50000]\n",
            "loss: 1.805391 [38400/50000]\n",
            "loss: 1.617972 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.717488 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 115\n",
            "----------------------------\n",
            "loss: 1.696925 [    0/50000]\n",
            "loss: 1.612907 [ 6400/50000]\n",
            "loss: 1.460337 [12800/50000]\n",
            "loss: 1.588132 [19200/50000]\n",
            "loss: 1.789575 [25600/50000]\n",
            "loss: 1.760170 [32000/50000]\n",
            "loss: 1.805516 [38400/50000]\n",
            "loss: 1.617491 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.717402 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 116\n",
            "----------------------------\n",
            "loss: 1.696719 [    0/50000]\n",
            "loss: 1.612362 [ 6400/50000]\n",
            "loss: 1.460466 [12800/50000]\n",
            "loss: 1.587193 [19200/50000]\n",
            "loss: 1.789398 [25600/50000]\n",
            "loss: 1.759763 [32000/50000]\n",
            "loss: 1.805650 [38400/50000]\n",
            "loss: 1.617016 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.717322 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 117\n",
            "----------------------------\n",
            "loss: 1.696511 [    0/50000]\n",
            "loss: 1.611826 [ 6400/50000]\n",
            "loss: 1.460598 [12800/50000]\n",
            "loss: 1.586264 [19200/50000]\n",
            "loss: 1.789229 [25600/50000]\n",
            "loss: 1.759358 [32000/50000]\n",
            "loss: 1.805792 [38400/50000]\n",
            "loss: 1.616546 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.717247 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 118\n",
            "----------------------------\n",
            "loss: 1.696300 [    0/50000]\n",
            "loss: 1.611299 [ 6400/50000]\n",
            "loss: 1.460730 [12800/50000]\n",
            "loss: 1.585346 [19200/50000]\n",
            "loss: 1.789069 [25600/50000]\n",
            "loss: 1.758951 [32000/50000]\n",
            "loss: 1.805942 [38400/50000]\n",
            "loss: 1.616083 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.717177 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 119\n",
            "----------------------------\n",
            "loss: 1.696087 [    0/50000]\n",
            "loss: 1.610780 [ 6400/50000]\n",
            "loss: 1.460864 [12800/50000]\n",
            "loss: 1.584439 [19200/50000]\n",
            "loss: 1.788915 [25600/50000]\n",
            "loss: 1.758546 [32000/50000]\n",
            "loss: 1.806100 [38400/50000]\n",
            "loss: 1.615626 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.717112 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 120\n",
            "----------------------------\n",
            "loss: 1.695871 [    0/50000]\n",
            "loss: 1.610269 [ 6400/50000]\n",
            "loss: 1.460998 [12800/50000]\n",
            "loss: 1.583542 [19200/50000]\n",
            "loss: 1.788768 [25600/50000]\n",
            "loss: 1.758141 [32000/50000]\n",
            "loss: 1.806265 [38400/50000]\n",
            "loss: 1.615174 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.717052 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 121\n",
            "----------------------------\n",
            "loss: 1.695652 [    0/50000]\n",
            "loss: 1.609766 [ 6400/50000]\n",
            "loss: 1.461133 [12800/50000]\n",
            "loss: 1.582657 [19200/50000]\n",
            "loss: 1.788628 [25600/50000]\n",
            "loss: 1.757735 [32000/50000]\n",
            "loss: 1.806438 [38400/50000]\n",
            "loss: 1.614727 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716998 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 122\n",
            "----------------------------\n",
            "loss: 1.695431 [    0/50000]\n",
            "loss: 1.609269 [ 6400/50000]\n",
            "loss: 1.461269 [12800/50000]\n",
            "loss: 1.581780 [19200/50000]\n",
            "loss: 1.788493 [25600/50000]\n",
            "loss: 1.757331 [32000/50000]\n",
            "loss: 1.806617 [38400/50000]\n",
            "loss: 1.614287 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716948 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 123\n",
            "----------------------------\n",
            "loss: 1.695208 [    0/50000]\n",
            "loss: 1.608781 [ 6400/50000]\n",
            "loss: 1.461405 [12800/50000]\n",
            "loss: 1.580914 [19200/50000]\n",
            "loss: 1.788365 [25600/50000]\n",
            "loss: 1.756926 [32000/50000]\n",
            "loss: 1.806801 [38400/50000]\n",
            "loss: 1.613851 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.716904 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 124\n",
            "----------------------------\n",
            "loss: 1.694981 [    0/50000]\n",
            "loss: 1.608299 [ 6400/50000]\n",
            "loss: 1.461541 [12800/50000]\n",
            "loss: 1.580058 [19200/50000]\n",
            "loss: 1.788242 [25600/50000]\n",
            "loss: 1.756521 [32000/50000]\n",
            "loss: 1.806992 [38400/50000]\n",
            "loss: 1.613421 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.716864 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 125\n",
            "----------------------------\n",
            "loss: 1.694752 [    0/50000]\n",
            "loss: 1.607823 [ 6400/50000]\n",
            "loss: 1.461677 [12800/50000]\n",
            "loss: 1.579213 [19200/50000]\n",
            "loss: 1.788124 [25600/50000]\n",
            "loss: 1.756116 [32000/50000]\n",
            "loss: 1.807188 [38400/50000]\n",
            "loss: 1.612997 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.716829 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 126\n",
            "----------------------------\n",
            "loss: 1.694521 [    0/50000]\n",
            "loss: 1.607354 [ 6400/50000]\n",
            "loss: 1.461813 [12800/50000]\n",
            "loss: 1.578377 [19200/50000]\n",
            "loss: 1.788010 [25600/50000]\n",
            "loss: 1.755712 [32000/50000]\n",
            "loss: 1.807390 [38400/50000]\n",
            "loss: 1.612577 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.716798 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 127\n",
            "----------------------------\n",
            "loss: 1.694286 [    0/50000]\n",
            "loss: 1.606890 [ 6400/50000]\n",
            "loss: 1.461948 [12800/50000]\n",
            "loss: 1.577551 [19200/50000]\n",
            "loss: 1.787901 [25600/50000]\n",
            "loss: 1.755307 [32000/50000]\n",
            "loss: 1.807596 [38400/50000]\n",
            "loss: 1.612163 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.6%, Avg loss: 1.716772 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 128\n",
            "----------------------------\n",
            "loss: 1.694050 [    0/50000]\n",
            "loss: 1.606432 [ 6400/50000]\n",
            "loss: 1.462083 [12800/50000]\n",
            "loss: 1.576734 [19200/50000]\n",
            "loss: 1.787795 [25600/50000]\n",
            "loss: 1.754902 [32000/50000]\n",
            "loss: 1.807806 [38400/50000]\n",
            "loss: 1.611754 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716750 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 129\n",
            "----------------------------\n",
            "loss: 1.693810 [    0/50000]\n",
            "loss: 1.605979 [ 6400/50000]\n",
            "loss: 1.462216 [12800/50000]\n",
            "loss: 1.575928 [19200/50000]\n",
            "loss: 1.787694 [25600/50000]\n",
            "loss: 1.754497 [32000/50000]\n",
            "loss: 1.808021 [38400/50000]\n",
            "loss: 1.611350 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716733 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 130\n",
            "----------------------------\n",
            "loss: 1.693567 [    0/50000]\n",
            "loss: 1.605532 [ 6400/50000]\n",
            "loss: 1.462349 [12800/50000]\n",
            "loss: 1.575130 [19200/50000]\n",
            "loss: 1.787595 [25600/50000]\n",
            "loss: 1.754091 [32000/50000]\n",
            "loss: 1.808239 [38400/50000]\n",
            "loss: 1.610951 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716720 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 131\n",
            "----------------------------\n",
            "loss: 1.693322 [    0/50000]\n",
            "loss: 1.605089 [ 6400/50000]\n",
            "loss: 1.462480 [12800/50000]\n",
            "loss: 1.574342 [19200/50000]\n",
            "loss: 1.787499 [25600/50000]\n",
            "loss: 1.753686 [32000/50000]\n",
            "loss: 1.808461 [38400/50000]\n",
            "loss: 1.610557 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716711 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 132\n",
            "----------------------------\n",
            "loss: 1.693074 [    0/50000]\n",
            "loss: 1.604651 [ 6400/50000]\n",
            "loss: 1.462610 [12800/50000]\n",
            "loss: 1.573563 [19200/50000]\n",
            "loss: 1.787407 [25600/50000]\n",
            "loss: 1.753280 [32000/50000]\n",
            "loss: 1.808686 [38400/50000]\n",
            "loss: 1.610168 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716706 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 133\n",
            "----------------------------\n",
            "loss: 1.692823 [    0/50000]\n",
            "loss: 1.604217 [ 6400/50000]\n",
            "loss: 1.462738 [12800/50000]\n",
            "loss: 1.572793 [19200/50000]\n",
            "loss: 1.787316 [25600/50000]\n",
            "loss: 1.752875 [32000/50000]\n",
            "loss: 1.808914 [38400/50000]\n",
            "loss: 1.609783 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716706 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 134\n",
            "----------------------------\n",
            "loss: 1.692569 [    0/50000]\n",
            "loss: 1.603787 [ 6400/50000]\n",
            "loss: 1.462865 [12800/50000]\n",
            "loss: 1.572033 [19200/50000]\n",
            "loss: 1.787227 [25600/50000]\n",
            "loss: 1.752469 [32000/50000]\n",
            "loss: 1.809143 [38400/50000]\n",
            "loss: 1.609403 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716709 \n",
            "\n",
            "Patience counter: 1\n",
            "\n",
            "Epoch 135\n",
            "----------------------------\n",
            "loss: 1.692313 [    0/50000]\n",
            "loss: 1.603361 [ 6400/50000]\n",
            "loss: 1.462989 [12800/50000]\n",
            "loss: 1.571281 [19200/50000]\n",
            "loss: 1.787140 [25600/50000]\n",
            "loss: 1.752063 [32000/50000]\n",
            "loss: 1.809376 [38400/50000]\n",
            "loss: 1.609028 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716716 \n",
            "\n",
            "Patience counter: 2\n",
            "\n",
            "Epoch 136\n",
            "----------------------------\n",
            "loss: 1.692054 [    0/50000]\n",
            "loss: 1.602939 [ 6400/50000]\n",
            "loss: 1.463112 [12800/50000]\n",
            "loss: 1.570539 [19200/50000]\n",
            "loss: 1.787055 [25600/50000]\n",
            "loss: 1.751656 [32000/50000]\n",
            "loss: 1.809609 [38400/50000]\n",
            "loss: 1.608658 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716727 \n",
            "\n",
            "Patience counter: 3\n",
            "\n",
            "Epoch 137\n",
            "----------------------------\n",
            "loss: 1.691792 [    0/50000]\n",
            "loss: 1.602521 [ 6400/50000]\n",
            "loss: 1.463232 [12800/50000]\n",
            "loss: 1.569804 [19200/50000]\n",
            "loss: 1.786971 [25600/50000]\n",
            "loss: 1.751250 [32000/50000]\n",
            "loss: 1.809845 [38400/50000]\n",
            "loss: 1.608292 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716741 \n",
            "\n",
            "Patience counter: 4\n",
            "\n",
            "Epoch 138\n",
            "----------------------------\n",
            "loss: 1.691527 [    0/50000]\n",
            "loss: 1.602106 [ 6400/50000]\n",
            "loss: 1.463350 [12800/50000]\n",
            "loss: 1.569079 [19200/50000]\n",
            "loss: 1.786888 [25600/50000]\n",
            "loss: 1.750844 [32000/50000]\n",
            "loss: 1.810082 [38400/50000]\n",
            "loss: 1.607930 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716759 \n",
            "\n",
            "Patience counter: 5\n",
            "\n",
            "Epoch 139\n",
            "----------------------------\n",
            "loss: 1.691260 [    0/50000]\n",
            "loss: 1.601694 [ 6400/50000]\n",
            "loss: 1.463465 [12800/50000]\n",
            "loss: 1.568362 [19200/50000]\n",
            "loss: 1.786805 [25600/50000]\n",
            "loss: 1.750436 [32000/50000]\n",
            "loss: 1.810320 [38400/50000]\n",
            "loss: 1.607573 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716781 \n",
            "\n",
            "Patience counter: 6\n",
            "\n",
            "Epoch 140\n",
            "----------------------------\n",
            "loss: 1.690990 [    0/50000]\n",
            "loss: 1.601285 [ 6400/50000]\n",
            "loss: 1.463578 [12800/50000]\n",
            "loss: 1.567653 [19200/50000]\n",
            "loss: 1.786723 [25600/50000]\n",
            "loss: 1.750030 [32000/50000]\n",
            "loss: 1.810558 [38400/50000]\n",
            "loss: 1.607220 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716806 \n",
            "\n",
            "Patience counter: 7\n",
            "\n",
            "Epoch 141\n",
            "----------------------------\n",
            "loss: 1.690717 [    0/50000]\n",
            "loss: 1.600879 [ 6400/50000]\n",
            "loss: 1.463688 [12800/50000]\n",
            "loss: 1.566953 [19200/50000]\n",
            "loss: 1.786641 [25600/50000]\n",
            "loss: 1.749622 [32000/50000]\n",
            "loss: 1.810797 [38400/50000]\n",
            "loss: 1.606871 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.7%, Avg loss: 1.716835 \n",
            "\n",
            "Patience counter: 8\n",
            "\n",
            "Epoch 142\n",
            "----------------------------\n",
            "loss: 1.690441 [    0/50000]\n",
            "loss: 1.600476 [ 6400/50000]\n",
            "loss: 1.463795 [12800/50000]\n",
            "loss: 1.566261 [19200/50000]\n",
            "loss: 1.786560 [25600/50000]\n",
            "loss: 1.749215 [32000/50000]\n",
            "loss: 1.811036 [38400/50000]\n",
            "loss: 1.606527 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716867 \n",
            "\n",
            "Patience counter: 9\n",
            "\n",
            "Epoch 143\n",
            "----------------------------\n",
            "loss: 1.690163 [    0/50000]\n",
            "loss: 1.600075 [ 6400/50000]\n",
            "loss: 1.463899 [12800/50000]\n",
            "loss: 1.565577 [19200/50000]\n",
            "loss: 1.786478 [25600/50000]\n",
            "loss: 1.748807 [32000/50000]\n",
            "loss: 1.811275 [38400/50000]\n",
            "loss: 1.606187 [44800/50000]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 1.716902 \n",
            "\n",
            "Finished due to early stopping.\n",
            "Saving best model: model_100-epoch:133\n",
            "Saving best model: model_100-epoch:133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "262-Gta2aIUD"
      },
      "source": [
        "training_loop(n_epochs, model_500, train_dataloader, test_dataloader,\n",
        "              loss_fn, optimizer_500, early_stopping=True, patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EARFi7nyCjOP"
      },
      "source": [
        "training_loop(n_epochs, model_1000, train_dataloader, test_dataloader,\n",
        "              loss_fn, optimizer_1000, early_stopping=True, patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5Iif5xCjtx"
      },
      "source": [
        "training_loop(n_epochs, model_5000, train_dataloader, test_dataloader,\n",
        "              loss_fn, optimizer_5000, early_stopping=True, patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}