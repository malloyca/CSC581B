{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg",
      "provenance": [],
      "authorship_tag": "ABX9TyOs5A8oW1OgtCUESWmSy5Qt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malloyca/CSC581B/blob/main/Final%20Project/vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y9MWjA9YVw5"
      },
      "source": [
        "# CSC581B - Deep Learning for Image Classification\n",
        "\n",
        "# VGG-16 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iAhFImeYPyE"
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import numpy as np\n",
        "import random\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejjwUFB-lUvq"
      },
      "source": [
        "expansion_coef = 1"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuAKwZPWYeyE"
      },
      "source": [
        "data_augmentation_transform = transforms.Compose([\n",
        "  transforms.RandomHorizontalFlip(p=0.5),\n",
        "  transforms.RandomRotation(degrees=30),\n",
        "  transforms.RandomCrop(32, padding=2),\n",
        "  transforms.ColorJitter(brightness=0.25, contrast=0.5, saturation=0.25, hue = 0.15),\n",
        "  transforms.RandomGrayscale(p=0.2),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(\n",
        "      mean = [0.5071, 0.4867, 0.4408],\n",
        "      std = [0.2675, 0.2565, 0.2761]\n",
        "  ),\n",
        "  transforms.RandomErasing(p=.35),\n",
        "])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ajaxZliYf2P"
      },
      "source": [
        "normalize_transform = transforms.Compose([\n",
        "  transforms.Resize(size=32 * expansion_coef),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(\n",
        "      mean = [0.5071, 0.4867, 0.4408],\n",
        "      std = [0.2675, 0.2565, 0.2761]\n",
        "  ),\n",
        "])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg-FecrqYq68"
      },
      "source": [
        "## Load CIFAR-100\n",
        "\n",
        "Load the dataset and split into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpOB75WQYhKk",
        "outputId": "54659066-cb37-469a-cdab-04ef78a00f84"
      },
      "source": [
        "# Load the training data (CIFAR10 to start)\n",
        "training_data = CIFAR100(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    #transform = data_augmentation_transform,\n",
        "    transform = normalize_transform,\n",
        ")\n",
        "\n",
        "# this is necessary to prevent the data augmentation transforms from being applied to the validation set\n",
        "validation_data = CIFAR100(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = normalize_transform,\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = CIFAR100(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transforms.ToTensor()\n",
        ")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn8wlKHTYjJN"
      },
      "source": [
        "training_targets = training_data.targets"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1p_hdNUYme9"
      },
      "source": [
        "train_split_index, valid_split_index = train_test_split(\n",
        "    np.arange(len(training_targets)), test_size=0.2, stratify=training_targets\n",
        ")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cznB2QEeYm5U"
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size,\n",
        "                              sampler=SubsetRandomSampler(train_split_index))\n",
        "valid_dataloader = DataLoader(validation_data, batch_size=batch_size,\n",
        "                              sampler=SubsetRandomSampler(valid_split_index))\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chwr-WY-YoMT",
        "outputId": "563bd79e-8ee8-45d6-dbd4-b3ff39d7be80"
      },
      "source": [
        "# Check that it is splitting the data properly\n",
        "train_length = 0\n",
        "for _, y in train_dataloader:\n",
        "  train_length += len(y)\n",
        "print(f\"Length of training split: {train_length}\")\n",
        "\n",
        "valid_length = 0\n",
        "for _, y in valid_dataloader:\n",
        "  valid_length += len(y)\n",
        "print(f\"Length of validation split: {valid_length}\")\n",
        "\n",
        "test_length = 0\n",
        "for _, y in test_dataloader:\n",
        "  test_length += len(y)\n",
        "print(f\"Length of test split: {test_length}\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training split: 40000\n",
            "Length of validation split: 10000\n",
            "Length of test split: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu5x8T3CYpx5",
        "outputId": "7aa12d39-d7b0-47b0-82cd-4d5348413641"
      },
      "source": [
        "# Check that there are 100 instances of a random class in the validation set\n",
        "count = 0\n",
        "test_class = random.randint(0,99)\n",
        "for _, y in valid_dataloader:\n",
        "  for target in y:\n",
        "    if int(target.numpy()) == test_class:\n",
        "      count += 1\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J0mD58CZIWl"
      },
      "source": [
        "# Building VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CcZnZufY3-Y",
        "outputId": "f732d528-a114-4376-f85e-255606fb4a03"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBTCFJU0ZkNx"
      },
      "source": [
        "## The architecture (from the paper https://arxiv.org/pdf/1409.1556.pdf)\n",
        "\n",
        "Notes:\n",
        "- conv3 = 3x3 convolutional layer\n",
        "  - stride = 1\n",
        "  - pad = 1\n",
        "- maxpool 2x2\n",
        "  - stride = 2\n",
        "- weight decay (L2 reg) = 5e-4\n",
        "- Dropout on first two FC layers\n",
        "  - ratio = 0.5\n",
        "- LR = 1e-2\n",
        "  - decreased by factor of ten on plateau\n",
        "- batch size = 256\n",
        "\n",
        "The architecture:\n",
        "- Input: 224 x 224 RGB (32x32 for CIFAR100  or can resize CIFAR images to 224x224)\n",
        "- Block 1\n",
        "  - conv3-64\n",
        "  - conv3-64\n",
        "  - maxpool\n",
        "- block 2\n",
        "  - conv3-128\n",
        "  - conv3-128\n",
        "  - maxpool\n",
        "- block 3\n",
        "  - conv3-256\n",
        "  - conv3-256\n",
        "  - conv3-256\n",
        "  - maxpool\n",
        "- block 4\n",
        "  - conv3-512\n",
        "  - conv3-512\n",
        "  - conv3-512\n",
        "  - maxpool\n",
        "- block 5\n",
        "  - conv3-512\n",
        "  - conv3-512\n",
        "  - conv3-512\n",
        "  - maxpool\n",
        "- fully connected - 4096\n",
        "- fully connected - 4096\n",
        "- fully connected - 1000 (1000 is for ImageNet, we would need 100 for CIFAR)\n",
        "- softmax\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiifErmTZPQX"
      },
      "source": [
        "# Define the model\n",
        "class VGG16(nn.Module):\n",
        "  def __init__(self, expansion_coef):\n",
        "    super(VGG16, self).__init__()\n",
        "    self.name = 'VGG-16'\n",
        "    self.expansion_coef = expansion_coef\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "        # Block 1 shape: 224x224\n",
        "        nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        # Block 2 shape: 112x112\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        # Block 3 shape: 56x56\n",
        "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        # Block 4 shape: 28x28\n",
        "        nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        # Block 5 shape: 14x14\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        # Block 6 shape: 7x7\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(512* self.expansion_coef * self.expansion_coef,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096,4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(4096, 100)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    return x"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZZNFEGqpcuy"
      },
      "source": [
        "def initialize_weights(layer):\n",
        "  if isinstance(layer, nn.Conv2d):\n",
        "    nn.init.xavier_uniform_(layer.weight)\n",
        "    layer.bias.data.fill_(0.01)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3aQ8cBag3Ki"
      },
      "source": [
        "# Training loop\n",
        "def train(dataloader, batch_size, model, loss_fn, optimizer):\n",
        "  num_batches = len(dataloader)\n",
        "  size = num_batches * batch_size\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3upNoHIiLZo"
      },
      "source": [
        "# Test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "  return test_loss"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw_9E3WwiNk2"
      },
      "source": [
        "# Validation function\n",
        "def validation(dataloader, batch_size, model, loss_fn):\n",
        "  num_batches = len(dataloader)\n",
        "  size = num_batches * batch_size\n",
        "  model.eval()\n",
        "  val_loss, num_correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      val_loss += loss_fn(pred, y).item()\n",
        "      num_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  val_loss /= num_batches\n",
        "  accuracy = num_correct / size\n",
        "  print(f\"Validation Error: \\n Validation accuracy: {(100 * accuracy):>0.1f}%, Validation loss: {val_loss:>8f} \\n\")\n",
        "  return val_loss"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rulNsltiPr3"
      },
      "source": [
        "def training_loop(n_epochs, model, train_data, valid_data, batch_size,\n",
        "                  loss_function, optimizer, scheduler=None,\n",
        "                  early_stopping=False, patience=10):\n",
        "  current_epoch = 0\n",
        "  best_epoch = 0\n",
        "  best_loss = float('inf')\n",
        "  patience_counter = 0\n",
        "\n",
        "  for e in range(n_epochs):\n",
        "    print(f\"\\nEpoch {e+1}\\n----------------------------\")\n",
        "    # Iterate epoch counter\n",
        "    current_epoch += 1\n",
        "\n",
        "    train(train_data, batch_size, model, loss_function, optimizer)\n",
        "    val_loss = validation(valid_data, batch_size, model, loss_function)\n",
        "\n",
        "    # Iterate scheduler (this is set up for ReduceLROnPlateau)\n",
        "    if scheduler is not None:\n",
        "      scheduler.step(val_loss)\n",
        "\n",
        "    # If early_stopping check test_loss\n",
        "    if early_stopping:\n",
        "      # case: test loss beats the current best loss\n",
        "      if val_loss < best_loss:\n",
        "        # store loss\n",
        "        best_loss = val_loss\n",
        "\n",
        "        # reset patience counter\n",
        "        patience_counter = 0\n",
        "\n",
        "        # store model and epoch number\n",
        "        print(\"Storing new best model.\")\n",
        "        best_model_state_dict = copy.deepcopy(model.state_dict)\n",
        "        best_epoch = current_epoch\n",
        "\n",
        "      # Case: patience limit not yet reached => iterate patience counter\n",
        "      elif patience_counter < patience - 1:\n",
        "        patience_counter += 1\n",
        "        print(f\"Patience count: {patience_counter}\")\n",
        "\n",
        "      # Case: patience limit reached\n",
        "      else:\n",
        "        print(\"Finished due to early stopping.\")\n",
        "        print(f\"Saving best model: {model.name}_epoch-{best_epoch:03d}\")\n",
        "        torch.save(best_model_state_dict, f'{model.name}_epoch-{best_epoch:03d}')\n",
        "        break\n",
        "\n",
        "  # If we get here, we did not stop early - save best model\n",
        "  if early_stopping:\n",
        "    print(f\"Saving best model: {model.name}_epoch-{best_epoch:03d}\")\n",
        "    torch.save(best_model_state_dict, f'{model.name}_epoch-{best_epoch:03d}')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McAz5qfHmmrI"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYuXODQCiTfK"
      },
      "source": [
        "n_epochs = 3"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYZjwb3hiW4y"
      },
      "source": [
        "model = VGG16(expansion_coef).to(device)\n",
        "num_param = sum(p.numel() for p in model.parameters())\n",
        "num_param_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9o6wzlUp2me",
        "outputId": "71288ac7-fb0b-408b-dc8c-ee15b0d27ee0"
      },
      "source": [
        "# Apply initialization\n",
        "model.apply(initialize_weights)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (layers): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU()\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU()\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU()\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU()\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU()\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU()\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU()\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (31): Flatten(start_dim=1, end_dim=-1)\n",
              "    (32): Linear(in_features=512, out_features=4096, bias=True)\n",
              "    (33): ReLU()\n",
              "    (34): Dropout(p=0.5, inplace=False)\n",
              "    (35): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (36): ReLU()\n",
              "    (37): Dropout(p=0.5, inplace=False)\n",
              "    (38): Linear(in_features=4096, out_features=100, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y0Q7QYxilV2"
      },
      "source": [
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', patience=5)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq_I8SBrix5M",
        "outputId": "3301cf32-0671-4e9b-d9dd-a186eef90c0f"
      },
      "source": [
        "training_loop(n_epochs, model, train_dataloader, valid_dataloader, batch_size,\n",
        "              loss_fn, optimizer, early_stopping=True, patience=10)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "----------------------------\n",
            "loss: 4.605896 [    0/40000]\n",
            "loss: 4.613282 [10000/40000]\n",
            "loss: 4.505758 [20000/40000]\n",
            "loss: 4.431888 [30000/40000]\n",
            "Validation Error: \n",
            " Validation accuracy: 2.9%, Validation loss: 4.246157 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 2\n",
            "----------------------------\n",
            "loss: 4.128386 [    0/40000]\n",
            "loss: 4.395105 [10000/40000]\n",
            "loss: 3.985777 [20000/40000]\n",
            "loss: 4.077597 [30000/40000]\n",
            "Validation Error: \n",
            " Validation accuracy: 5.3%, Validation loss: 4.000291 \n",
            "\n",
            "Storing new best model.\n",
            "\n",
            "Epoch 3\n",
            "----------------------------\n",
            "loss: 4.065510 [    0/40000]\n",
            "loss: 4.002787 [10000/40000]\n",
            "loss: 3.850573 [20000/40000]\n",
            "loss: 3.979860 [30000/40000]\n",
            "Validation Error: \n",
            " Validation accuracy: 8.1%, Validation loss: 3.826275 \n",
            "\n",
            "Storing new best model.\n",
            "Saving best model: VGG-16_epoch-003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE2p7Rcci_Aa"
      },
      "source": [
        ""
      ],
      "execution_count": 78,
      "outputs": []
    }
  ]
}